# Cursor IDE Rules

<!-- Auto-generated by VANTA Global Rules System -->

## 000-base

<!-- Source: .cursor\rules\000-base.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: Base RZN Application Rules
globs: **/*
alwaysApply: true
---

# RZN App Core Principles

## Architectural Patterns
- Use Server and Client Components appropriately in Next.js
- Client Components must include "use client" directive at the top
- Centralize shared resources in dedicated files (icons, themes, etc.)
- Implement proper error boundaries around components
- Follow Test-Driven Development practices

## UI Components
- Use the centralized Icons object from `src/components/ui/icons.tsx`
- Never use direct Lucide icon imports in components
- Error boundaries should provide user-friendly fallback UI
- Implement progressive disclosure for complex UIs
- Support keyboard navigation for all interactive elements

## Database Access
- Handle database connection failures gracefully
- Support development mode without database connection
- Use mock data for development and testing
- Apply proper connection pooling

## Error Handling
- Specific error handling for database connection issues
- Use ErrorBoundary components for component-level errors
- Log errors appropriately before displaying to users
- Provide actionable steps for users when errors occur

## ADHD-Optimized Patterns
- Use visual differentiation for UI elements
- Implement single-focus interfaces where possible
- Reduce decision paralysis through clear UI patterns
- Use color-coding and icons for quick recognition

## AI Learning Process
- Document learnings in `/dev/ai-learnings.md` with consistent formatting
- Use emoji categories to organize learnings by type
- Apply insights from AI learnings to evolve coding standards
- Reference AI learnings when implementing similar patterns

## Cursor MDC Rules
- Project-specific MDC rules are in `.cursor/rules/`
- Open source reference MDC rules are in `.cursor/rules/opensource/`
- See `.cursor/rules/700-opensource-mdc.mdc` for external rule index
- Update open source MDC rules using `.cursor/scripts/update-mdc-rules.sh` 

---

## 000-framework-index

<!-- Source: .cursor\rules\000-framework-index.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# Framework Rules Index and Trigger System
# FILE PATTERNS: **/*
# RULE TYPE: Always
# PRIORITY: 1000

## Overview
This rule serves as the central index and trigger system for all framework rules. It ensures that relevant rules are always in context and properly cross-referenced.

## Rule Categories and Triggers

### Core Framework Rules
```yaml
rules:
  - id: memory_retention
    path: rules/memory_retention.mdc
    triggers:
      - pattern: "**/*.py"
      - pattern: "**/agents/*.py"
      - pattern: "**/memory/**/*"
    dependencies:
      - strategic_planning
      - output_traceability
    autoApply: true

  - id: strategic_planning
    path: rules/strategic_planning.mdc
    triggers:
      - pattern: "**/*.py"
      - pattern: "**/orchestrator.py"
      - pattern: "**/agents/*.py"
    dependencies:
      - memory_retention
      - agent_health
    autoApply: true

  - id: output_traceability
    path: rules/output_traceability.mdc
    triggers:
      - pattern: "**/*.py"
      - pattern: "**/*.log"
      - pattern: "**/logs/**/*"
    dependencies:
      - memory_retention
      - agent_health
    autoApply: true

  - id: agent_health
    path: rules/agent_health.mdc
    triggers:
      - pattern: "**/*.py"
      - pattern: "**/health/**/*"
      - pattern: "**/monitoring/**/*"
    dependencies:
      - memory_retention
      - output_traceability
    autoApply: true
```

## Implementation Requirements

### 1. Rule Loading
```python
class RuleLoader:
    def __init__(self):
        self.rules: Dict[str, Rule] = {}
        self.dependencies: Dict[str, List[str]] = {}
        self.triggers: Dict[str, List[Pattern]] = {}

    async def load_rules(self) -> None:
        """Load all framework rules and their relationships."""
        pass

    async def validate_rules(self) -> None:
        """Validate rule dependencies and triggers."""
        pass

    async def apply_rules(self, context: Context) -> None:
        """Apply relevant rules based on context."""
        pass
```

### 2. Trigger System
```python
class TriggerSystem:
    def __init__(self):
        self.patterns: Dict[str, List[Pattern]] = {}
        self.active_rules: Set[str] = set()

    async def check_triggers(
        self,
        file_path: str,
        context: Context
    ) -> List[str]:
        """Check which rules should be triggered."""
        pass

    async def activate_rules(
        self,
        triggered_rules: List[str]
    ) -> None:
        """Activate triggered rules and their dependencies."""
        pass
```

## Cross-Reference System

### 1. Rule Dependencies
- Automatically load dependent rules
- Maintain dependency graph
- Validate circular dependencies
- Track rule activation chain

### 2. Context Sharing
- Share relevant context between rules
- Maintain context hierarchy
- Handle context conflicts
- Preserve context chain

## Integration Points

### 1. IDE Integration
```python
class IDEIntegration:
    def __init__(self):
        self.rule_loader = RuleLoader()
        self.trigger_system = TriggerSystem()
        self.context_manager = ContextManager()

    async def on_file_change(
        self,
        file_path: str
    ) -> None:
        """Handle file change events."""
        triggered_rules = await self.trigger_system.check_triggers(
            file_path,
            self.context_manager.current_context
        )
        await self.trigger_system.activate_rules(triggered_rules)

    async def on_command(
        self,
        command: str
    ) -> None:
        """Handle command execution events."""
        pass
```

### 2. Framework Integration
```python
class FrameworkIntegration:
    def __init__(self):
        self.rule_engine = RuleEngine()
        self.context_tracker = ContextTracker()

    async def apply_framework_rules(
        self,
        context: Context
    ) -> None:
        """Apply framework rules to current context."""
        pass

    async def track_rule_impact(
        self,
        rule_id: str,
        impact: RuleImpact
    ) -> None:
        """Track the impact of applied rules."""
        pass
```

## Monitoring and Feedback

### 1. Rule Performance
- Track rule activation frequency
- Measure rule impact
- Monitor dependency chains
- Analyze rule conflicts

### 2. System Health
- Monitor trigger system performance
- Track rule loading times
- Measure context switch overhead
- Report system status

## Best Practices

### 1. Rule Management
- Keep rules focused and atomic
- Maintain clear dependencies
- Document trigger patterns
- Version control rules

### 2. Performance
- Optimize trigger patterns
- Cache frequent contexts
- Batch rule applications
- Monitor resource usage

## Implementation Notes

1. **Rule Loading**
   - Load rules on startup
   - Validate dependencies
   - Initialize trigger patterns
   - Prepare context handlers

2. **Trigger Processing**
   - Use efficient pattern matching
   - Handle multiple triggers
   - Process in priority order
   - Maintain trigger history

3. **Context Management**
   - Track active contexts
   - Handle context switches
   - Manage context lifetime
   - Clean up stale contexts

4. **Health Monitoring**
   - Monitor rule performance
   - Track system resources
   - Log rule activities
   - Generate health reports


---

## 001-rule-index-watcher

<!-- Source: .cursor\rules\001-rule-index-watcher.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# Rule Index Watcher

## Overview

This rule defines the behavior of the RuleIndexWatcherAgent, which is responsible for maintaining the framework rule index. The agent monitors the rules directory for changes and automatically updates the index to reflect the current state of all rules.

## Requirements

### Agent Responsibilities

1. **Directory Monitoring**
   - Watch `.cursor/rules` directory for file changes
   - Detect new, modified, and deleted rule files
   - Ignore the index file itself (000-framework-index.mdc)

2. **Rule Processing**
   - Parse YAML front matter from rule files
   - Extract metadata, dependencies, and triggers
   - Validate rule format and required fields
   - Track rule modifications and timestamps

3. **Index Maintenance**
   - Maintain 000-framework-index.mdc
   - Update index immediately on rule changes
   - Preserve rule ordering and relationships
   - Generate readable markdown documentation

4. **Validation**
   - Ensure all rules have required metadata
   - Validate YAML syntax
   - Check for circular dependencies
   - Verify trigger patterns

### Performance Requirements

1. **Responsiveness**
   - Update index within 1 second of rule changes
   - Minimize file system operations
   - Use efficient YAML parsing
   - Implement proper locking mechanisms

2. **Resource Usage**
   - Low memory footprint
   - Minimal CPU usage when idle
   - Efficient file watching mechanism
   - Smart caching of rule content

### Error Handling

1. **Recovery Procedures**
   - Handle corrupted rule files
   - Recover from parsing errors
   - Maintain index consistency
   - Log all errors for debugging

2. **Validation Failures**
   - Report invalid rule formats
   - Identify missing required fields
   - Detect dependency conflicts
   - Provide clear error messages

## Implementation Guidelines

### Agent Configuration

```python
config = {
    "watch_paths": [".cursor/rules"],
    "excluded_patterns": ["000-framework-index.mdc"],
    "update_delay": 1.0,  # seconds
    "max_retries": 3,
    "validation_rules": [
        "has_metadata",
        "has_description",
        "has_type",
        "valid_yaml"
    ]
}
```

### Index Structure

```yaml
---
description: Framework Rule Index
last_updated: ISO8601_TIMESTAMP
rules:
  rule_id:
    name: string
    path: string
    metadata: dict
    last_modified: ISO8601_TIMESTAMP
    dependencies: list
    triggers: list
---
```

### Monitoring Process

1. Initialize file system observer
2. Load existing index if present
3. Scan rules directory for initial state
4. Start watching for changes
5. Handle events asynchronously
6. Update index as needed

### Validation Process

1. Check YAML syntax
2. Verify required fields
3. Validate dependencies
4. Check trigger patterns
5. Report any issues

## Best Practices

1. **Performance**
   - Use async/await for I/O operations
   - Implement proper locking
   - Cache rule content when appropriate
   - Batch updates when possible

2. **Reliability**
   - Handle all error cases
   - Implement retry logic
   - Maintain consistent state
   - Log important events

3. **Maintainability**
   - Follow clean code principles
   - Document all functions
   - Use type hints
   - Write unit tests

## Integration Points

1. **Framework Integration**
   - Start automatically with framework
   - Provide status API
   - Emit change events
   - Support health checks

2. **Tool Integration**
   - Support rule validation tools
   - Interface with logging system
   - Enable monitoring integration
   - Provide CLI interface


---

## 002-L1-L2-distinction-and-coevolution

<!-- Source: .cursor\rules\002-L1-L2-distinction-and-coevolution.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Always (Core AI Operational Principle)
# FILE PATTERNS: N/A (Universal Architectural Guideline)

# 002: Level 1 / Level 2 AI Interaction & Co-evolution Protocol

## 1. Purpose
This rule defines the distinction between "Level 1" (L1) and "Level 2" (L2) operational contexts for AI-assisted development, particularly concerning the Cursor AI assistant and a specific, complex project like VANTA. It also outlines their intended co-evolutionary relationship.

## 2. Definitions

### 2.1. Level 1 (L1): AI Assistant Governance Layer
    - **Scope:** Governs the **Cursor AI assistant's behavior** and its interaction with *any* project.
    - **Primary Guidance:** `.cursor/rules/*.mdc` files. These rules are "hard-piped" into the AI assistant and dictate its response patterns, tool usage, coding standards application, and general operational logic when acting as a pair programmer or assistant.
    - **Nature:** Project-agnostic principles and IDE-level integration rules.
    - **Examples:** `000-base.mdc`, `005-destructive-op-safety.mdc`, rules for specific file types (`100-next-components.mdc`).

### 2.2. Level 2 (L2): Project-Specific Implementation Layer
    - **Scope:** Governs the **internal architecture, logic, protocols, and standards of a specific project** being developed (e.g., the VANTA framework).
    - **Primary Guidance:** Project-internal rule directories (e.g., `framework rules/`, `DESIGN_PRINCIPLES/`), `THEPLAN.md`, `blueprint.yaml`, and the project's own codebase.
    - **Nature:** Project-specific design decisions, internal APIs, agent contracts, domain logic, and operational protocols.
    - **Examples (for VANTA):** Rules in `framework rules/`, `agent_cascade_definitions.mdc`, Python code defining VANTA agents and core logic.

## 3. Interaction Model

### 3.1. L1 Governs AI Interaction with L2
    - The Cursor AI assistant (L1) operates based on its `.cursor/rules/`. These rules dictate *how* it should approach tasks related to an L2 project.
    - For instance, an L1 rule might specify how the AI should propose changes to an L2 Python file, what questions to ask before refactoring L2 code, or how to use McP tools to interact with L2's environment.

### 3.2. L1 AI Interacts with L2 via Defined Interfaces
    - The L1 AI assistant primarily interacts with L2 project components and its environment through established interfaces:
        - **Code Modification Tools:** `edit_file`, `mcp_desktop-commander_edit_block`.
        - **File System Tools:** `read_file`, `list_dir`, `mcp_desktop-commander_read_file`, etc.
        - **Execution Tools:** `run_terminal_cmd`, `mcp_desktop-commander_execute_command`.
        - **Project-Specific APIs/CLIs (if L2 exposes them):** Once VANTA (L2) has its own API or CLI, the L1 AI can be instructed (via L1 rules or direct prompts) to use them.
    - The L1 AI does not make direct, unmediated internal calls to L2 Python functions or classes as if it were part of L2's runtime. It helps *build and manage* L2.

## 4. Co-evolutionary Relationship

### 4.1. L2 Informs L1
    - The challenges, successes, and evolving needs of the L2 project (e.g., VANTA) are critical sources of feedback for refining and creating L1 rules.
    - If developing VANTA reveals a recurring pattern of AI interaction that is inefficient or error-prone, a new L1 (`.cursor/rules/*.mdc`) rule should be proposed to improve the AI's behavior for that pattern.
    - Example: If the AI frequently struggles with understanding VANTA's specific state management, an L1 rule could be created to guide it on how to query or infer state more effectively when working on VANTA.

### 4.2. L1 Guides L2 (See Rule `003-L1-enforces-L2-scaffolding.mdc`)
    - L1 rules can be designed to actively guide the scaffolding, development, and adherence to standards within L2 projects.
    - The AI, following L1 rules, can act as a "guardian" or "guide" for L2's structure and quality.

## 5. Goal: Synergistic Development
The ultimate goal is a synergistic relationship where the L1 AI assistant becomes an increasingly effective partner in developing and maintaining complex L2 projects like VANTA. This is achieved by:
    - Continuously improving L1 rules based on L2 development experiences.
    - Using L1 rules to ensure L2 development aligns with best practices and project-specific architectural goals.

This distinction and interaction model is fundamental to achieving a recursive, agentic intelligence capable of sophisticated project development.

## 2. L1: Cursor AI Governance (Project-Agnostic)

-   **Scope:** Governs the behavior of the Cursor AI assistant.
-   **Context:** Project-agnostic, applying broadly across different projects opened in Cursor.
-   **Purpose:** Defines how the AI assistant should interact, format code, use tools, apply general coding standards, and assist in the development process.
-   **Runtime:** Active when the Cursor AI is being used.
-   **Example Rules:** `000-base.mdc`, `100-next-components.mdc`, `910-assistant-autonomy.mdc`.

## 3. L2: VANTA Project Internals (Project-Specific)

-   **Scope:** Defines the internal architecture, protocols, data schemas, agent contracts, and operational logic specific to the VANTA framework.
-   **Context:** Specific to the VANTA project.
-   **Purpose:** Provides the blueprint for how VANTA agents and components operate, communicate, and manage data *within the VANTA ecosystem itself*.
-   **Runtime:** Active when the VANTA framework is running, whether in development (within Cursor) or deployed standalone. **L2 agents and the VANTA framework operate based on L2 rules and their own configurations, independent of L1 rules.**
-   **Example Rules:** `framework rules/FR001-VantaAgentContract.md`, `framework rules/FR002-VantaInternalSignalSchema.md`.

## 4. Co-evolution and Interaction

-   **L1 Guides L2 Development:** L1 rules guide the Cursor AI in assisting with the *development and scaffolding* of L2 components. For instance, L1 rules can help generate boilerplate code for VANTA agents that adheres to L2's `FR001-VantaAgentContract.md`.
-   **L2 Informs L1 Potential:** As sophisticated agentic patterns emerge within L2 (e.g., complex cascade behaviors, novel memory structures), these can inspire the creation or refinement of L1 rules to make the Cursor AI more effective in assisting with such advanced patterns in future projects.
-   **Separation of Concerns:**
    -   L1 rules **do not** dictate the runtime behavior of L2 VANTA agents.
    -   L2 VANTA agents **do not** depend on L1 rules or Cursor-specific functionalities to operate. They are designed to be self-contained and portable.
    -   The AI assistant (L1) helps *build* L2 components; L2 components execute based on their *own* defined L2 rules and logic.
-   **Tooling Bridge:** L1 (Cursor AI) might use tools (like McP tools) to interact with a running L2 VANTA instance for testing or operational tasks, but this is an external interaction, not an internal dependency of L2 on L1.


---

## 003-L1-enforces-L2-scaffolding

<!-- Source: .cursor\rules\003-L1-enforces-L2-scaffolding.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Always (Core AI Operational Principle)
# FILE PATTERNS: N/A (Universal AI-Assisted Development Guideline)

# 003: L1 Rule Enforcement for L2 Project Scaffolding & Standards

## 1. Purpose
This rule outlines how Level 1 (L1) `.cursor/rules/*.mdc` files should be actively utilized by the Cursor AI assistant to guide, enforce, and maintain the structural integrity, coding standards, and developmental processes of Level 2 (L2) projects, such as VANTA. It operationalizes the co-evolutionary principle described in `002-L1-L2-distinction-and-coevolution.mdc`.

## 2. Principle: L1 as a Guardian and Guide for L2
The Cursor AI, governed by its L1 rules, acts as an intelligent assistant that not only writes code but also helps ensure the L2 project adheres to its own defined architecture, standards, and plans.

## 3. Mechanisms for L1 Enforcement of L2 Standards

### 3.1. Scaffolding New L2 Components
    - **L1 Rule Example Trigger:** User requests to create a new VANTA agent (L2 component).
    - **L1 Rule Action (AI Behavior):**
        - Consult relevant L2 rules (e.g., `framework rules/001-vanta-agent-contract.md`) to understand the required structure for a new VANTA agent.
        - Check `THEPLAN.md` or `blueprint.yaml` (L2 documents) for naming conventions or registration requirements.
        - Propose a code structure for the new agent that adheres to these L2 standards (e.g., inherits from `BaseAgent`, includes standard methods like `startup`, `perform_task`, `shutdown`).
        - Suggest updating L2 registration files (e.g., `blueprint.yaml` or an agent registry if one exists in L2).
        - Remind the user to create corresponding L2 documentation or tests as per L2 standards.

### 3.2. Maintaining L2 Architectural Integrity
    - **L1 Rule Example Trigger:** User proposes a change that seems to deviate from VANTA's (L2) established architectural patterns (e.g., bypassing the orchestrator for inter-agent communication).
    - **L1 Rule Action (AI Behavior):**
        - Query the user about the deviation, referencing the relevant L2 architectural rule or document (e.g., "I notice this change doesn't seem to use the `VantaMasterCore` for routing. VANTA's architecture (`framework rules/000-core-orchestration.md`) typically requires this. Is this an intentional exception?").
        - If the L2 project has a formal way to document architectural decisions or exceptions, suggest using it.

### 3.3. Enforcing L2 Coding Standards & Best Practices
    - **L1 Rule Example Trigger:** AI is asked to write or refactor Python code for VANTA (L2).
    - **L1 Rule Action (AI Behavior):**
        - Apply general Python best practices (as defined in relevant L1 `.cursor/rules/`).
        - *Additionally*, if L2 (`framework rules/`) defines specific coding standards for VANTA (e.g., logging format, error handling conventions), apply those as well.
        - If there's a conflict, prioritize the L2-specific standard and note the application.

### 3.4. Synchronizing L2 Planning and Documentation
    - **L1 Rule Example Trigger:** A significant new feature is implemented in VANTA (L2).
    - **L1 Rule Action (AI Behavior):**
        - Prompt the user to update `THEPLAN.md` or relevant L2 design documents to reflect the new feature.
        - Suggest adding to L2's changelog if one exists.
        - Offer to help draft these documentation updates based on the code changes.

### 3.5. Guiding L2 Tooling and Protocol Development
    - **L1 Rule Example Trigger:** User wants to create a new McP tool for VANTA (L2) or a new inter-agent communication protocol within L2.
    - **L1 Rule Action (AI Behavior):**
        - Reference L2 standards for tool definition or protocol design (e.g., from `framework rules/921-vanta-mcp-signal-schema.md` if it were an L2 rule, or a similar L2 document).
        - Suggest required documentation, testing, and registration steps for the new L2 tool/protocol.

## 4. Iterative Refinement
    - The effectiveness of L1 rules in guiding L2 development is an ongoing process.
    - If the AI consistently fails to enforce an L2 standard correctly, or if L2's needs change, both L1 and L2 rules may need to be updated.
    - The AI should be receptive to feedback on how well it's applying L1 rules to guide L2 development.

## 5. Goal: Principled and Consistent L2 Development
By using L1 rules to actively enforce L2's own defined structures and standards, the AI assistant becomes a proactive partner in building a robust, maintainable, and internally consistent L2 project. This elevates the AI from a simple code generator to a co-architect and guardian of the project's integrity.

## Core Principle

Level 1 (L1) rules, which govern the Cursor AI assistant, play a crucial role in enforcing and guiding the initial scaffolding and ongoing development of Level 2 (L2) VANTA project components. This ensures that L2's internal architecture, agent contracts, data schemas, and protocols align with VANTA's overarching design principles from the outset.

L1 rules should guide the AI to generate L2 components that are **self-contained and operate based on L2 rules and configurations**, not based on L1 rules or Cursor-specific features.

## Mechanisms of Enforcement & Guidance

4.  **Independence by Design:** L1 rules will steer the AI to generate L2 code that is portable and does not have runtime dependencies on Cursor AI or L1-specific constructs. The goal is for L2 VANTA to be capable of standalone operation.

## Examples


---

## 004-L1-L2-dependency-check

<!-- Source: .cursor\rules\004-L1-L2-dependency-check.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Always (Core AI Architectural Integrity Principle)
# FILE PATTERNS: N/A (Applies to AI assistant behavior during code generation and refactoring)

# 004: L1/L2 Dependency & Entanglement Prevention

## 1. Purpose
This rule is a critical guideline for the Cursor AI assistant (Level 1) to ensure that Level 2 project code (e.g., VANTA framework code in `vanta_seed/`) remains independent and does not inadvertently develop runtime dependencies on Cursor IDE-specific features, rules (`.cursor/rules/`), or other L1 mechanisms. The goal is to ensure L2 projects can be packaged, deployed, and run in environments completely separate from the Cursor IDE or the L1 development assistance layer.

## 2. Core Principle

Level 2 (L2) VANTA project code, particularly its core agent logic, data schemas, and internal protocols, MUST remain independent of Level 1 (L1) Cursor AI-specific features, rules, or direct runtime dependencies. L2 agents must operate based on their own configurations and the VANTA framework's L2 rules, not L1 rules.

## 3. How L1 Can *Influence* L2 (Safely)
   - **Development-Time Guidance:** L1 rules (like `003-L1-enforces-L2-scaffolding.mdc`) guide the *development and structure* of L2 code. The AI uses L1 rules to help write L2 code that adheres to L2's own internal standards (`framework rules/`).
   - **Code Generation:** The AI, guided by L1 rules, generates L2 code. This L2 code, once written, stands alone.
   - **Pattern Learning:** L1 can learn from L2. If VANTA (L2) develops an effective internal pattern, that pattern might inspire a new L1 `.cursor/rule/` to help the AI suggest similar good practices in *other* projects. This is influence, not dependency.

## 4. AI Assistant Responsibilities
   - **Vigilance During Code Generation:** When generating or refactoring L2 code, the AI assistant must actively check that it is not introducing L1 dependencies.
   - **Clarification:** If a user request seems to imply creating an L1-L2 dependency, the AI should clarify the intent and explain the importance of L2 independence, suggesting alternative approaches if necessary.
   - **Focus on L2 Self-Sufficiency:** Promote patterns and solutions within L2 that make it self-contained and runnable without the L1 IDE/assistant environment.

## 5. Example Scenario
   - **User:** "Make the VANTA `GitOpsAgent` automatically update its behavior based on the `.cursor/rules/005-L1-general-git-sync-guidelines.mdc` file at runtime."
   - **AI (Applying this 004 rule):** "That's an interesting idea for synergy! However, to ensure VANTA (`GitOpsAgent` - L2) can run independently of the Cursor IDE, it shouldn't directly read or depend on `.cursor/rules/` (L1) at runtime. Instead, we could: 
     1.  Manually review `005-L1-general-git-sync-guidelines.mdc` and decide if any of its principles should be codified into `GitOpsAgent`'s own internal logic or its L2 configuration within `framework rules/`. 
     2.  I can help you refactor `GitOpsAgent` based on those principles. This way, the good ideas from L1 inform L2, but L2 remains independent."

This rule is crucial for maintaining the architectural integrity and portability of L2 projects developed with L1 AI assistance.

## Rationale
2.  **Predictable Behavior:** L2 agents' behavior should be determined by VANTA's internal rules and configurations, not by the L1 rules of the IDE environment they were developed in. This ensures that VANTA operates predictably when deployed standalone.

## L1 Guidance for L2 Independence

When assisting with L2 development, the L1 Cursor AI (governed by L1 rules) MUST:

1.  **Avoid L1-Specific Code:** Refrain from injecting or suggesting code in L2 components that directly imports, calls, or depends on Cursor-specific APIs, modules, or L1 rule interpretations at runtime.
2.  **Promote L2 Self-Sufficiency:** Encourage the design of L2 agents and systems that are self-contained, relying only on standard Python libraries, defined VANTA core modules, and L2 framework rules for their operation.
3.  **Focus on L2 Standards:** When generating or modifying L2 code, the AI should prioritize adherence to L2-defined contracts (e.g., `framework rules/FR001-VantaAgentContract.md`) and L2 internal protocols, rather than L1 conventions, if there's a conflict in runtime implications.
4.  **Interface via Tools:** If L1 needs to interact with a running L2 system (e.g., for testing or operational commands), it should do so through defined interfaces (APIs, McP tools exposed by L2), not by assuming L2 shares L1's runtime context or rules.


---

## 005-destructive-op-safety

<!-- Source: .cursor\rules\005-destructive-op-safety.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always (Core AI Operational Safety Principle)
# FILE PATTERNS: N/A (Universal Safety Guideline)

# AI Destructive Operation Safety Protocol

## 1. Principle: Prioritize Data Integrity and User Control

AI assistants MUST prioritize the preservation of user data and provide users with clear control over operations that could lead to data loss or irreversible changes.

## 2. Mandatory Checks Before Destructive Operations

Before proposing or executing any of the following operations, the AI assistant MUST perform the relevant safety checks:

    - **File Overwrite (e.g., `edit_file` with full replacement, `mcp_desktop-commander_write_file`):
        - **Suggestion:** "This operation will completely overwrite the file `[target_file]`."
        - **Action:** Suggest creating a backup (e.g., `[target_file].bak`) first.
        - **Confirmation:** Explicitly ask the user for confirmation to proceed with the overwrite AFTER the backup suggestion.
        - **Example Tool Usage (Backup):** Suggest `mcp_desktop-commander_move_file` to rename `target_file` to `target_file.bak`.

    - **File Deletion (e.g., `delete_file`, `mcp_desktop-commander_delete_file`):
        - **Suggestion:** "This operation will permanently delete the file `[target_file]`."
        - **Action:** If the file is significant (e.g., not a temporary or log file), suggest creating a backup or moving it to a temporary archive location.
        - **Confirmation:** Explicitly ask the user for confirmation to proceed with the deletion.

    - **Large-Scale Block Edits (Potentially Risky `mcp_desktop-commander_edit_block`):
        - **Suggestion:** "This operation will make significant changes to `[target_file]`. Review the proposed `old_string` and `new_string` carefully."
        - **Action:** If the change is extensive or complex, suggest a backup.
        - **Confirmation:** Ask for user confirmation if the AI assesses the risk as high.

## 3. User Confirmation

    - Confirmation requests MUST be clear and unambiguous.
    - The AI should wait for an explicit affirmative response (e.g., "Yes, proceed", "Confirm") before executing the destructive part of the operation.
    - If the user rejects or does not confirm, the AI MUST NOT proceed with the destructive action.

## 4. Logging

    - All destructive operations, whether executed or aborted due to lack of confirmation, SHOULD be logged with appropriate context (e.g., in an agentic replay log or audit trail).

## 5. Scope

    - This rule applies to all AI-initiated file system modifications that are potentially irreversible or carry a risk of unintended data loss.
    - It is especially critical when the AI is operating with higher levels of autonomy.

## Rationale

This rule ensures that AI assistants operate safely, respect user data, and prevent accidental data loss, fostering trust and reliability in AI-assisted development workflows.



---

## 005-L1-general-git-sync-guidelines

<!-- Source: .cursor\rules\005-L1-general-git-sync-guidelines.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Best Practice (AI Assistant Guideline)
# FILE PATTERNS: N/A (Applies to general Git-related queries and code generation)

# 005: L1 General Git Sync Guidelines

## 1. Purpose
This rule provides Level 1 (Cursor AI, project-agnostic) guidelines for Git operations, focusing on commit messages, staging, and general workflow. These guidelines are inspired by effective practices observed and implemented in Level 2 systems like VANTA's `GitOpsAgent` and aim to promote clarity and consistency in version control across any project.

## 2. Commit Message Standards
   - **Semantic Clarity:** Strive for commit messages that clearly describe the change.
     - *Good Example:* `feat: Implement user authentication via OAuth`
     - *Good Example:* `fix: Correct off-by-one error in pagination logic`
     - *Good Example:* `docs: Update README with setup instructions`
     - *Good Example:* `refactor: Simplify data fetching in Profile component`
     - *Good Example (Schema/Config):* `chore(schemas): Update UserProfile schema with new address field`
   - **Brevity:** Keep the subject line concise (ideally under 50 characters).
   - **Body (Optional):** If more detail is needed, provide a more extensive explanation in the commit message body, separated from the subject by a blank line.

## 3. Staging Practices
   - **Atomic Commits:** Aim to stage and commit related changes together. Avoid overly broad commits that bundle unrelated modifications.
   - **Targeted Staging:** When appropriate, suggest staging specific files or directories that form a logical unit of change.
     - *Example Suggestion:* "It looks like you've modified schema files and related service logic. Consider staging `schemas/` and `services/user_service.py` together for this commit."

## 4. Branching (General Advice)
   - Encourage the use of feature branches for new development or significant changes to keep the main branch stable.
   - Suggest merging feature branches back into the main branch using pull/merge requests where appropriate for the project's workflow.

## 5. Inspiration from L2 (Contextual Adaptation)
   - While these are L1 general guidelines, the AI may subtly adapt its suggestions if it has context from an L2 system (like VANTA) that employs more specific or advanced Git protocols. For instance, if VANTA's `GitOpsAgent` uses commit prefixes tied to rituals (e.g., `ritual(user_onboarding): Commit initial setup files`), the L1 AI should respect and understand such patterns when operating within that L2 project context, but not enforce them globally unless specified by the user.

## 6. AI Assistant Role
   - When assisting with Git operations, the AI should:
     - Offer to help construct well-formatted commit messages.
     - Suggest appropriate files to stage if the user's intent is clear.
     - Remind the user to pull recent changes before pushing if a collaborative environment is implied.
     - Explain Git concepts if the user seems unsure.

This rule helps the Level 1 AI provide more effective and standardized Git assistance across diverse projects.


---

## 006-system-incoherence-protocol

<!-- Source: .cursor\rules\006-system-incoherence-protocol.mdc -->
<!-- Format: mdc -->

---
description: `run.py`: Main application entry point. *   `vanta_seed/core/vanta_master_core.py`: Core agent orchestration logic. *   `blueprint.yaml`: High-level system architecture and configuration. *   `.cursor/rules/**/*.mdc`: AI behavior and operational rules. *   `.cursor/rituals/**/*.yaml`: Defined automated sequences. *   `agent_cascade_definitions.mdc`: Agent interaction flows. *   `THEPLAN.md`: Project source of truth for tasks and architecture. *   `logs/agentic_replay.log.jsonl`: Log of AI actions, crucial for detecting patterns of failed edits.
globs: 
alwaysApply: false
---
# RULE TYPE: Agent Requested
# FILE PATTERNS: **/run.py, **/vanta_master_core.py, **/blueprint.yaml, .cursor/rules/**/*.mdc, agentic_replay.log.jsonl

# 006: System Layer Incoherence Protocol

## 1. Overview

System Layer Incoherence (SLI) refers to a state where the AI's internal model or understanding of critical system files or configurations diverges significantly from their actual state on disk. This can occur due to tool limitations (e.g., partial or failed edits), complex concurrent changes, or manual alterations not tracked by the AI.

This protocol defines mechanisms for detecting, diagnosing, and proposing resolutions for SLI to maintain system integrity and reliable AI operation.

## 2. Monitored Assets (Critical Layers)

The following files and directories are considered critical and are primary candidates for SLI monitoring:

*   `run.py`: Main application entry point.
*   `vanta_seed/core/vanta_master_core.py`: Core agent orchestration logic.
*   `blueprint.yaml`: High-level system architecture and configuration.
*   `.cursor/rules/**/*.mdc`: AI behavior and operational rules.
*   `.cursor/rituals/**/*.yaml`: Defined automated sequences.
*   `agent_cascade_definitions.mdc`: Agent interaction flows.
*   `THEPLAN.md`: Project source of truth for tasks and architecture.
*   `logs/agentic_replay.log.jsonl`: Log of AI actions, crucial for detecting patterns of failed edits.

## 3. Triggers for Incoherence Check

An SLI check should be considered or automatically triggered under the following circumstances:

*   **Repeated Edit Failures**: Multiple consecutive failed or "no changes" `edit_file` or `mcp_desktop-commander_edit_block` operations on a monitored asset, especially if changes were expected (logged in `agentic_replay.log.jsonl`).
*   **Post-Major Refactoring**: After significant architectural changes or complex, multi-file refactoring operations.
*   **User Manual Invocation**: If the user suspects incoherence (e.g., `!check system coherence`).
*   **Unexplained Critical Errors**: After a series of unexpected critical runtime errors that cannot be easily attributed to recent logical code changes.
*   **Agent Proposal**: An agent (like Vanta! Coder) might propose an SLI check if it encounters unexpected resistance or errors when trying to apply changes to core files.

## 4. Detection Heuristics (Conceptual)

The `IncoherenceDetectionAgent` will employ the following heuristics:

*   **Log Analysis**:
    *   Scan `agentic_replay.log.jsonl` for patterns like:
        *   Multiple `edit_file` calls to the same file with `status: "no changes"` or `status: "failed"` within a short timeframe.
        *   Discrepancies between intended changes (logged in `instructions`) and reported outcomes.
*   **File State Comparison (Conceptual - Requires Tooling/Agent Capabilities)**:
    *   **Checksum/Hash Mismatch**: If a baseline checksum for a critical file is known, compare it against the current file. (Requires a mechanism to store and update baselines).
    *   **Structural Anomaly Detection**: For structured files (YAML, JSON, Python AST), detect unexpected structural deviations from a known schema or previous state. (Advanced capability).
*   **Rule-Based Validation**:
    *   Check if critical MDC rules (`000-base.mdc`, `index.mdc`) are present and structurally sound (e.g., parsable).
    *   Validate `blueprint.yaml` against a schema if available.

## 5. Resolution Paths

Upon detection of potential SLI, the following resolution paths can be taken, orchestrated by the `system_incoherence_detected_cascade`:

*   **Level 1: Alert & Diagnose**:
    *   Notify the user with specific details about the suspected incoherence (which file, what heuristic triggered).
    *   Provide relevant snippets from `agentic_replay.log.jsonl`.
    *   Suggest manual review using `mcp_desktop-commander_read_file` for the affected file(s).
*   **Level 2: Guided Restore/Replace**:
    *   If a trusted version of the file is identifiable (e.g., from version control, a backup, or a previous known-good state generated by AI), suggest a "hard replace" using `mcp_desktop-commander_write_file`.
    *   Ensure `.cursor/rules/005-destructive-op-safety.mdc` is respected (e.g., backup creation).
*   **Level 3: Specialized Agent Invocation**:
    *   Invoke a (future) `SystemIntegrityRepairAgent` if defined and available.
    *   Trigger a CoE review for complex incoherence scenarios.
*   **Level 4: Interactive Debugging**:
    *   Initiate an interactive session with the user to step through recent changes and identify the source of divergence.

## 6. `IncoherenceDetectionAgent` Profile

*   **Name**: `IncoherenceDetectionAgent`
*   **Type**: `system_monitoring_and_diagnostics`
*   **Responsibilities**:
    *   Implement SLI detection heuristics.
    *   Process `agentic_replay.log.jsonl` for failure patterns.
    *   Interface with file system tools (read-only for detection).
    *   Trigger the `system_incoherence_detected_cascade` upon finding issues.
    *   Log its findings and actions.
*   **Triggers**:
    *   MCP Signal: `mcp_signal_check_system_incoherence`
    *   Scheduled (e.g., after X number of agent interactions).
    *   Event-driven (e.g., after multiple `edit_file` failures logged).
*   **Core Logic (Conceptual Python for `vanta_seed/agents/system/incoherence_detection_agent.py`)**:
    ```python
    class IncoherenceDetectionAgent(BaseAgent):
        def __init__(self, agent_id="incoherence_detector", core=None):
            super().__init__(agent_id, core)
            self.monitored_files = ["run.py", "vanta_seed/core/vanta_master_core.py", ...] # from this rule
            self.log_file_path = "logs/agentic_replay.log.jsonl"

        async def process_input(self, data, context=None):
            command = data.get("command")
            if command == "check_system_incoherence":
                return await self.perform_incoherence_check(data.get("target_file"))
            return {"status": "error", "message": "Unknown command"}

        async def perform_incoherence_check(self, target_file=None):
            findings = []
            # 1. Analyze agentic_replay.log.jsonl
            log_findings = await self._analyze_agent_logs(target_file)
            findings.extend(log_findings)

            # 2. (Future) Checksum/Structural checks if tools/baselines are available

            if findings:
                self.core.emit_mcp_signal(
                    "system_incoherence_detected",
                    {"findings": findings, "resolution_protocol_version": "006_v1"}
                )
                return {"status": "incoherence_detected", "details": findings}
            return {"status": "no_incoherence_detected"}

        async def _analyze_agent_logs(self, target_file=None):
            # Placeholder: Read and parse self.log_file_path
            # Look for patterns of repeated failures for target_file or monitored_files
            # Example: 3+ edit_file failures or "no changes" in last N minutes for specific file
            found_patterns = []
            # Simulated finding
            # if some_condition_met:
            #    found_patterns.append({
            #        "type": "repeated_edit_failure",
            #        "file": target_file or "critical_system_file",
            #        "description": "Multiple edit_file operations failed or reported no changes.",
            #        "log_evidence": ["entry1_id", "entry2_id"] 
            #    })
            return found_patterns
    ```

## 7. Logging and Reinforcement Learning

*   All SLI checks, findings, and resolutions must be logged in `agentic_replay.log.jsonl` with a distinct event type (e.g., `SYSTEM_INCOHERENCE_EVENT`).
*   User feedback on the accuracy of SLI detection and the effectiveness of resolution paths will be used to refine the heuristics and the `IncoherenceDetectionAgent`'s logic.



---

## 007-desktop-commander-best-practices

<!-- Source: .cursor\rules\007-desktop-commander-best-practices.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: N/A (Applies to AI agent behavior when using mcp-desktop-commander)

# 007: Desktop Commander - Pathing Best Practices

## 1. Purpose

This rule provides essential guidelines for interacting with the `mcp-desktop-commander` toolset, particularly when specifying file or directory paths. Adhering to these practices will minimize errors like `ENOENT` (Error NO ENTry / No such file or directory) and ensure reliable tool operation.

## 2. Core Guideline: Prioritize Absolute Paths

**Always prefer absolute paths when calling `mcp-desktop-commander` tools that operate on files or directories.**

*   **Source of Truth**: Absolute paths should be constructed based on the known workspace root provided by the AI's contextual information (e.g., `user_info.workspace_path` if available, or a path confirmed by the user for the project).

## 3. Rationale

*   **Ambiguity of Relative Paths**: `mcp-desktop-commander` tools, when executed, may not have the same "current working directory" (CWD) as the AI's conceptual workspace or the user's active terminal. Using relative paths can lead to the tool looking for files in incorrect locations (e.g., the Cursor application's installation directory instead of the project directory).
*   **Path Format Sensitivity**: The underlying operating system (e.g., Windows) has specific path format requirements.
    *   Avoid URI-encoded paths (e.g., with `%3A` for colons) as these may not be correctly resolved by the tool or OS, leading to invalid path errors.
    *   On Windows, use standard drive letter notation (e.g., `C:/path/to/file` or `C:\\path\\to\\file`). Forward slashes are generally well-tolerated by Windows APIs.
*   **Error Reduction**: Using absolute paths dramatically reduces the chances of `ENOENT` errors due to path resolution issues.

## 4. Example: Constructing an Absolute Path (Windows Context)

Given a workspace root (e.g., `C:/Users/CurrentUser/projects/MyProject`) and a target file within the project (e.g., `src/components/my_component.py`):

**Correct (Absolute Path):**
`C:/Users/CurrentUser/projects/MyProject/src/components/my_component.py`

**Incorrect (Potentially Ambiguous Relative Path):**
`src/components/my_component.py` (Depends on the CWD of the `desktop-commander` execution environment)

**Incorrect (Potentially Malformed URI-style):**
`/c%3A/Users/CurrentUser/projects/MyProject/src/components/my_component.py`

## 5. When to Use (with Caution) Relative Paths

If a `mcp-desktop-commander` tool explicitly documents that it operates relative to a *specific, well-defined base directory* that it establishes (and this is confirmed), then relative paths *to that base* might be acceptable. However, for general file operations (move, read, write, list), absolute paths are safer.

## 6. Verification

Before executing a command with a path, if unsure, it can be beneficial to:
1.  Log the fully constructed absolute path the AI intends to use.
2.  If possible and non-destructive, use a read-only command like `mcp_desktop-commander_get_file_info` with the absolute path to verify its correctness and accessibility before attempting write or move operations.

By consistently using well-formed absolute paths, interaction with `mcp-desktop-commander` will be more robust and predictable.



---

## 008-backup-and-commit-protocol

<!-- Source: .cursor\rules\008-backup-and-commit-protocol.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules

# Backup and Commit Protocol

## Purpose
Establish a robust, auditable, and agentic protocol for regular project backups and git commits, ensuring safety, traceability, and compliance with VANTA's agentic development philosophy.

## Triggers & Frequency
- **Manual:**
  - On-demand by any contributor or agent before/after major changes.
- **Scheduled:**
  - At least daily (recommended: nightly at 2am local time).
  - Optionally, hourly during periods of rapid development.
- **Agentic/Automated:**
  - Before/after major refactors, migrations, or mass file operations.
  - After successful completion of major agentic workflows (e.g., rituals, cascades, agentic replay events).
  - Before deployments or releases.
  - After new agent, rule, or protocol is added to `.cursor/rules/`.

## How to Execute
- Use `scripts/backup_script.py` with appropriate flags:
  - `--commit` to commit all changes after backup
  - `--push` to push to remote after commit
  - `--backup-id` to specify context (e.g., `pre-refactor`, `scheduled`, `post-ritual`)
- Example:
  ```bash
  python scripts/backup_script.py instance_a /path/to/instance_a --commit --push --backup-id "pre-major-refactor"
  ```
- Agents and rituals should invoke this script as a subprocess at the above triggers.

## Logging & Audit
- All backup, commit, and push actions must be logged (stdout, file, or agentic replay log).
- Each event should include timestamp, triggering agent/human, context (backup-id), and result.
- Failures must be reported and retried or escalated.

## Exclusions
- Do not back up or commit `.git/`, `.venv/`, cache, or other non-essential files (script and MutationManager already handle this).
- Use `.gitignore` to manage exclusions for memory/log files as appropriate.

## Documentation
- Reference this protocol in `THEPLAN.md` and/or `README.md`.
- Document any deviations or exceptions in project docs.

## Best Practices
1. Test backup/restore regularly.
2. Store some backups offsite/cloud for disaster recovery.
3. Use structured commit messages for agentic/automated commits.
4. Review logs periodically for compliance.

## Integration
- This protocol is compatible with all other safety, logging, and agentic rules in `.cursor/rules/`.
- Agents must not bypass this protocol for any high-impact or destructive operation.

---



---

## 008-relative-import-preflight

<!-- Source: .cursor\rules\008-relative-import-preflight.mdc -->
<!-- Format: mdc -->

---
description: This rule should be conceptually triggered when: - A Python file (`*.py`) is saved. - A Python file is identified as a target for execution (e.g., a test file in a `pytest` command, a script to be run).
globs: 
alwaysApply: false
---
# RULE TYPE: Agent Requested / Auto Attached (on file save/test intent)
# FILE PATTERNS: **/*.py
# DESCRIPTION: Pre-flight check for relative imports. Warns or suggests stubs for missing target modules.

# Relative Import Pre-flight Check

## 1. Purpose

This rule defines a proactive check to identify and mitigate potential `ModuleNotFoundError` exceptions caused by broken or missing relative imports *before* code execution or testing. It aims to improve development velocity by catching such errors early.

## 2. Trigger

This rule should be conceptually triggered when:
- A Python file (`*.py`) is saved.
- A Python file is identified as a target for execution (e.g., a test file in a `pytest` command, a script to be run).
- An AI assistant is asked to analyze or work with a Python file containing relative imports.

## 3. Behavior & Logic

When triggered for a given Python file (the "source file"):

### 3.1. Parse for Relative Imports
- The system (AI assistant or integrated tool) should parse the source file to identify all relative import statements.
  - Examples: `from .module_name import ClassName`, `from ..package_name import function_name`, `import .module_name`

### 3.2. Resolve and Verify Target Path
- For each relative import identified:
    1. Resolve the expected absolute path of the imported module/package based on the source file's location and the relative path indicated (e.g., `.` for same directory, `..` for parent directory).
    2. Check the filesystem to verify if the target module file (e.g., `module_name.py`) or package directory (containing an `__init__.py`) exists at the resolved path.

### 3.3. Handle Missing Targets

- If a target module/package file **does not exist**:
    1.  **Issue a Warning:**
        -   Inform the user clearly.
        -   **Format:** "WARNING: Relative import `{{original_import_statement}}` in `{{source_file_path}}` targets a missing module/package at expected path `{{resolved_target_path}}`."
    2.  **Suggest Stub Creation:**
        -   Offer to create a placeholder (stub) for the missing module/package.
        -   **Format:** "Would you like to create a stub file for `{{resolved_target_path}}`?"
    3.  **Generate Stub (If User Confirms):**
        -   If the user agrees to create a stub:
            -   **For a module (e.g., `from .foo import Bar`):** Create `foo.py` in the correct location. If `Bar` is a known type (e.g., class, function based on usage), create a minimal stub:
                ```python
                # {{resolved_target_path}} (stub)
                import logging
                logger = logging.getLogger(__name__)
                logger.info("Stub module {{module_name}} created.")

                # Minimal stub for Bar, if identifiable as a class from usage
                # class Bar:
                #     def __init__(self, *args, **kwargs):
                #         logger.info("Stub class Bar initialized.")
                #     # Add stub methods if usage is known
                ```
            -   **For a package (e.g., `from ..bar import Baz` where `bar` is a directory):** Ensure the `bar/` directory exists and contains an `__init__.py`. If `__init__.py` is missing, create it:
                ```python
                # {{resolved_target_path}}/__init__.py (stub)
                import logging
                logger = logging.getLogger(__name__)
                logger.info("Stub package {{package_name}} initialized.")
                ```
        -   The AI should use its file creation/editing tools to implement this.

## 4. Benefits
- Proactively catches common `ModuleNotFoundError`s during development.
- Reduces the "run-fail-fix" cycle for import errors.
- Encourages the creation of necessary module/package files alongside their first reference.
- Streamlines the process of stubbing out new components of the system.

## 5. Implementation Notes (for AI/Tool Developer)
- This rule requires the AI/tool to have capabilities for:
    - Parsing Python import statements.
    - Resolving relative paths.
    - Checking file/directory existence.
    - Creating/editing files to generate stubs.
- The stub generation can be made more sophisticated by attempting to infer the type of the imported name (class, function, variable) and creating a more contextually relevant stub.

---
**End of Rule Content**



---

## 009-L2-framework-rule-index-awareness

<!-- Source: .cursor\rules\009-L2-framework-rule-index-awareness.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Always (Core AI Operational Principle)
# FILE PATTERNS: N/A (Universal AI-Assisted Development Guideline for L2 Projects)

# 009: L1 Promotion of L2 Framework Rule Index Awareness

## 1. Purpose
This rule ensures that the Cursor AI assistant (Level 1) actively promotes awareness and utilization of Level 2 (L2) project-specific rule indexes (e.g., `framework rules/index.md` for VANTA). The goal is to empower developers to leverage their project's internal standards, with L1 acting as a guide and reminder rather than a direct consumer of L2 rules for its own operational logic.

## 2. Principle: L1 Facilitates Developer Use of L2 Standards
   - **L1 Awareness of L2 Index:** The AI assistant MUST recognize the existence and importance of a dedicated index file for L2 project-specific rules (e.g., `framework rules/index.md`).
   - **L1 Guidance, Not Direct L2 Rule Consumption:** Instead of L1 directly reading and interpreting detailed L2 rules to formulate its responses, L1 should guide the developer to the relevant L2 rules and their index. L1's primary role is to provide scaffolding and high-level architectural suggestions consistent with general best practices, making it easier for the developer to then apply specific L2 rules.
   - **Prompting L2 Index Maintenance:** L1 SHOULD proactively suggest the creation or update of the L2 project's rule index when new L2 rules are developed or existing ones are modified with L1's assistance.

## 3. Operational Guidelines for the AI Assistant

   - **Discovery/Verification of L2 Index:**
     - If working on a known L2 project like VANTA, the AI should assume `framework rules/index.md` exists and is the primary reference for VANTA-specific standards.
     - For other projects, if the AI assists in creating a rules directory (e.g., `PROJECT_RULES/`), it SHOULD suggest creating an `index.md` for it.

   - **Guidance during Task Execution:**
     - **Query Analysis:** If a user asks, "How should I implement error handling in VANTA agents?", the AI should:
       1. Recognize this is an L2 VANTA-specific query.
       2. State that VANTA likely has specific protocols for this, documented in its `framework rules/`.
       3. Remind the user to consult `framework rules/index.md` to find the relevant VANTA error handling protocol (e.g., `003-error-handling-protocol.md`).
       4. Offer to help implement the pattern once the user has identified the specific L2 rule they want to follow.
     - **Code Generation/Modification:** If asked to implement a new VANTA agent:
       1. L1 might provide a generic agent scaffold based on best practices (see `013-L1-guides-L2-architecture.mdc`).
       2. L1 MUST then remind the user to ensure this scaffold is aligned with VANTA's specific `FR001-VantaAgentContract.md` and other relevant rules found via `framework rules/index.md`.

   - **Assisting with L2 Index Integrity:**
     - If the AI assists in creating a new L2 project rule (e.g., a new file in `framework rules/`), it MUST proactively suggest or offer to update the L2 project's rule index (`framework rules/index.md`) to include a reference to the new rule.

## 4. Relationship to L1 Index (`.cursor/rules/index.mdc`)
   - The L1 index (`.cursor/rules/index.mdc`) governs the AI's general behavior and its meta-level understanding of how to assist in L2 development.
   - The L2 project rule index (e.g., `framework rules/index.md`) is the L2 project's internal source of truth for its specific standards, intended for developer use, with L1 facilitating its creation and promoting its consultation.

## 5. Example AI Interaction Flow
   ```
   User: "How do I add a new data model for VANTA?"
   AI Response:
   "Adding a new data model in VANTA involves defining its schema and ensuring it integrates with existing systems. VANTA has specific standards for this, likely detailed in its `framework rules/`.

   I recommend you consult your `framework rules/index.md` to find the specific data schema or Pydantic model guidelines (e.g., `FR003-VantaDataSchemas.md`).

   Once you've reviewed those, I can help you:
   - Create the Pydantic model file.
   - Integrate it into relevant agents or services.
   - Ensure it's validated correctly."
   ```

This protocol ensures that L1 empowers the developer by guiding them to the L2 project's own documented standards, reinforcing L2's architectural integrity and autonomy.


---

## 011-mdc-hygiene-protocol

<!-- Source: .cursor\rules\011-mdc-hygiene-protocol.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Always
# FILE PATTERNS: .cursor/rules/**/*.mdc, scripts/validate_mdc_rules.py, scripts/format_mdc_rules.py

# 011: MDC Rule Hygiene Protocol

## 1. Purpose

This protocol establishes the standards and tooling for maintaining the quality, consistency, and correctness of MDC (Markdown Comments) rules within the `.cursor/rules/` directory. Adherence to this protocol is crucial for reliable AI assistant behavior and a maintainable rule set.

## 2. Core Components

Two primary scripts support this protocol:

*   **`scripts/validate_mdc_rules.py`**: Validates MDC rules for:
    *   Correct YAML frontmatter syntax.
    *   Presence of required frontmatter keys (e.g., `description`, `type`, `globs` - excluding `index.mdc` and `template.mdc` for certain keys).
    *   Structural integrity of optional keys like `alwaysApply` (boolean) and `test_globs`.
    *   Validity of `mdc:` links within the rule content.
    *   **Glob Pattern Testing**: If a `test_globs` key is present in the frontmatter, this script will test the rule's `globs` against specified `should_match` and `should_not_match` file paths using `fnmatch`.
*   **`scripts/format_mdc_rules.py`**: Automatically formats the YAML frontmatter of MDC rules:
    *   Ensures consistent key order (as defined in `FRONTMATTER_KEY_ORDER` within the script).
    *   Standardizes indentation and string quoting using `ruamel.yaml`.
    *   Preserves comments within the YAML frontmatter.

## 3. MDC Rule Frontmatter Standards

### 3.1. Required Keys

*   `description`: (string) A human-readable summary of the rule's purpose.
*   `type`: (string) The rule type, e.g., `always`, `autoAttached`, `agentRequested`, `manual`.
*   `globs`: (list of strings) File patterns that trigger this rule. (Not strictly enforced for `index.mdc` or `template.mdc` by the validator).

### 3.2. Optional Keys

*   `alwaysApply`: (boolean) If `true`, the rule is considered for every interaction. Defaults to `false`.
*   `test_globs`: (object) Used by `scripts/validate_mdc_rules.py` for testing glob patterns.
    *   `should_match`: (list of strings) File paths that *should* be matched by one of the rule's `globs`.
    *   `should_not_match`: (list of strings) File paths that *should NOT* be matched by any of the rule's `globs`.

**Example `test_globs`:**

```yaml
test_globs:
  should_match:
    - "src/components/ui/Button.tsx"
    - "docs/core/button_usage.md"
  should_not_match:
    - "package.json"
    - "src/utils/helpers.ts"
```

## 4. Workflow Integration

These scripts are intended to be integrated into the CI/CD pipeline (e.g., `.github/workflows/validate_agentic_commit.yml`):

1.  **Formatting Check/Apply**: `scripts/format_mdc_rules.py` can be run first. In a CI environment, it can be run in a check mode (if implemented, or by comparing files before/after) or it can directly format the files. For local development, it can be run to apply formatting.
2.  **Validation**: `scripts/validate_mdc_rules.py` MUST be run as a mandatory check. A non-zero exit code from this script should fail the build.

## 5. Best Practices for MDC Rule Authors

*   **Clarity and Conciseness**: Write clear descriptions for your rules.
*   **Accurate Globs**: Define `globs` precisely to target the intended files. Use tools like [globster.xyz](https://globster.xyz/) to test glob patterns.
*   **Thorough Glob Testing**: When adding or modifying rules with `globs`, include a `test_globs` section in the frontmatter with representative file paths. This is crucial for ensuring rules trigger correctly.
*   **Valid Links**: Ensure all `mdc:` links point to existing rules.
*   **Regular Formatting**: Run `scripts/format_mdc_rules.py` periodically or before committing to maintain consistent formatting.
*   **Atomic Rules**: Keep rules focused on a single concern or a closely related set of concerns.

## 6. Maintaining the Protocol

*   Updates to the validation or formatting logic should be reflected in the respective scripts and documented in this protocol.
*   The `FRONTMATTER_KEY_ORDER` in `scripts/format_mdc_rules.py` should be updated if new standard frontmatter keys are introduced.


---

## 012-ai-mdc-authoring-formatting-standards

<!-- Source: .cursor\rules\012-ai-mdc-authoring-formatting-standards.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: AgentRequested
# FILE PATTERNS: "**/*.mdc", "**/rules/**/*.mdc"
# INTENDED AUDIENCE: AI Assistant

# AI MDC Authoring & Formatting Standards

## 1. Purpose

This rule provides specific guidelines FOR THE AI ASSISTANT on how to structure and format `.mdc` rule files, particularly those defining `profiles` or `cascades`. Adherence ensures consistency, machine-readability, and compatibility with validation/processing scripts.

## 2. General File Structure

An `.mdc` file containing structured rule definitions (like profiles or cascades) MUST consist of two main parts:

1.  **YAML Frontmatter**: Contains metadata about the rule.
2.  **YAML Body**: Contains the rule definitions (e.g., `profiles:` or `cascades:`).

## 3. YAML Frontmatter Requirements

*   **Delimiters**: The frontmatter block MUST start with `---` on its own line and end with `---` on its own line.
*   **Required Keys**: The frontmatter dictionary MUST include the following keys:
    *   `description`: (string) A human-readable summary of the rule's purpose and content.
    *   `rule_type`: (string) Specifies how the rule is triggered or used (e.g., `AgentRequested`, `alwaysApply`, `autoAttached`). Note: This key is for the AI's understanding of the *overall .mdc file's nature*, distinct from `trigger_type` within a profile definition.
    *   `globs` or `file_patterns`: (list of strings) File patterns that determine when this rule is relevant or should be auto-attached. Use quoted strings for patterns starting with `*` or containing special YAML characters (e.g., `"**/*.mdc"`).
*   **Optional Keys**: Other keys like `profile_id` (if the *file itself* represents a single profile, though more common within the body) or custom metadata can be included.

## 4. YAML Body Requirements

*   **Top-Level Key**: Immediately following the closing `---` of the frontmatter, the body MUST begin with a top-level YAML key, typically `profiles:` or `cascades:`, at column 0 (no preceding spaces).
*   **No Intermediate Delimiters**: There MUST NOT be any additional `---` lines within the YAML body after the frontmatter.

## 5. Structure for `profiles:`

If the top-level key is `profiles:`, it must be a list of profile objects. Each profile object MUST contain at least:

*   `profile_id`: (string) A unique identifier for the profile.
*   `description`: (string) A human-readable description of the profile's purpose.
*   `trigger_type`: (string) How the profile is activated (e.g., `AGENT_INITIATED`, `AUTO_ON_CONDITION`, `USER_CONFIRMED_WHISPER`).
*   `steps`: (list) A list of step objects.
    *   Each step object MUST contain at least:
        *   `name`: (string) A descriptive name for the step.
        *   `agent`: (string) The ID of the agent to execute this step.
        *   `task_data`: (object) The data/parameters to be passed to the agent for this step.

**Example `profiles` Structure (Illustrative Snippet):**

```yaml
profiles:
  - profile_id: "example_validation_profile"
    description: "Validates user input for a specific form."
    trigger_type: "AGENT_INITIATED"
    steps:
      - name: "CheckRequiredFields"
        agent: "form_validator_agent"
        task_data:
          form_id: "user_registration"
          required_fields: ["username", "password", "email"]
      # ... other steps
```

## 6. Structure for `cascades:`

If the top-level key is `cascades:`, it follows a similar structure to `profiles:`, typically defining a list of cascade definition objects. The specific required keys within a cascade definition would be determined by the system interpreting these cascades (refer to `agent_cascade_definitions.mdc` for its schema if defining cascades for that system).

## 7. Glob Pattern Quoting

Within the `globs` or `file_patterns` list in the frontmatter, YAML syntax requires that strings starting with `*` or containing other special characters (like `[`, `]`, `{`, `}` if not part of a flow sequence/mapping) should be enclosed in quotes to be interpreted correctly as strings.

*   **Correct:** `globs: ["**/*.py", "*.md"]`
*   **Incorrect (potentially):** `globs: [**/*.py, *.md]` (depends on YAML parser, but quoting is safer)

## 8. Adherence by AI

When the AI Assistant is tasked with creating, modifying, or validating `.mdc` rule files that are intended to define structured profiles or cascades, it MUST strictly adhere to these formatting and structural guidelines.


---

## 013-L1-guides-L2-architecture

<!-- Source: .cursor\rules\013-L1-guides-L2-architecture.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Always (Core AI Operational Principle)
# FILE PATTERNS: N/A (Universal AI-Assisted Development Guideline)

# 013: L1 Guidance for L2 Project Architecture & Scaffolding

## 1. Purpose
This rule defines how the Cursor AI assistant (Level 1) should guide the architectural design and initial scaffolding of components within a Level 2 (L2) project (e.g., VANTA). The aim is for L1 to provide robust, best-practice starting points that facilitate L2's adherence to its own detailed internal standards and protocols, reinforcing L2's autonomy and architectural integrity.

## 2. Core Principle: L1 as Architectural Mentor & Scaffolder
   - **High-Level Architectural Guidance:** L1 can offer suggestions on architectural patterns (e.g., modular design, separation of concerns, event-driven architecture) that are generally beneficial and can be adapted to L2's specific needs.
   - **Best-Practice Scaffolding:** When asked to create new L2 components (e.g., agents, services, data models), L1 should provide well-structured, generic scaffolds that embody common software engineering best practices.
   - **Facilitating L2 Rule Adherence:** The scaffolds provided by L1 should be designed to make it *easier* for the developer to then implement the specifics required by L2's internal rules (e.g., `framework rules/FR001-VantaAgentContract.md`). L1 should explicitly state that the scaffold is a starting point and needs to be aligned with L2's detailed rules.
   - **Avoiding L1 Imposition:** L1-generated scaffolds MUST NOT introduce L1-specific dependencies or operational logic into L2 code. The goal is to support L2, not to make L2 dependent on L1 for runtime execution (see `004-L1-L2-dependency-check.mdc`).

## 3. Operational Guidelines for the AI Assistant

   - **Scaffolding New L2 Agents:**
     - If asked to "create a new VANTA agent for X," L1 should:
       1. Provide a Python class structure inheriting from a generic base (e.g., `BaseAgent` if that's a known L2 convention, or a conceptual base if not).
       2. Include placeholder methods for common agent lifecycle/tasks (e.g., `__init__`, `startup`, `process_task`, `shutdown`, `log_event`).
       3. Include reminders in comments or accompanying text: "This is a basic scaffold. Ensure it aligns with VANTA's specific agent contract (see `framework rules/FR001-VantaAgentContract.md`) regarding method signatures, logging, and state management."

   - **Scaffolding New L2 Data Models/Schemas:**
     - If asked to "define a Pydantic model for Y in VANTA," L1 should:
       1. Create a basic Pydantic model with common fields based on the request.
       2. Remind the user: "Ensure this model adheres to VANTA's data schema conventions (see `framework rules/FR003-VantaDataSchemas.md`) for field naming, types, and validation rules. You may need to add specific `Field` arguments or validators."

   - **Architectural Pattern Suggestions:**
     - If discussing system design for an L2 feature, L1 can suggest relevant patterns (e.g., "For handling asynchronous tasks in this VANTA service, you might consider a producer-consumer pattern using a message queue.")
     - L1 must follow up such suggestions with: "How this pattern is implemented should align with VANTA's existing architectural standards and communication protocols (see `framework rules/index.md` for relevant documents like `FR002-VantaInternalSignalSchema.md`)."

   - **Reviewing L2 Code for Adherence (with L2 Rules in Mind):**
     - When reviewing L2 code, if L1 has been made aware of specific L2 rules (e.g., through user prompts referencing `framework rules/FR001`), L1 can point out potential deviations: "This `process_task` method signature doesn't seem to match the one specified in `FR001-VantaAgentContract.md`. Should we adjust it?"

## 4. Promoting L2 Self-Documentation and Standards
   - L1 should encourage the formalization of L2 architectural decisions and standards into the L2 project's own `framework rules/` (or equivalent) directory.
   - If L1 helps design a novel architectural component for L2, it should suggest documenting that design in a new L2 framework rule.

## 5. Example AI Interaction for Scaffolding
   ```
   User: "Help me create a new VANTA agent to monitor file system changes."
   AI Response:
   "Okay, let's scaffold a new VANTA agent for file system monitoring. Here's a basic structure:

   ```python
   # vanta_seed/agents/file_monitor_agent.py
   from vanta_seed.core.base_agent import BaseAgent # Assuming this is your L2 base
   import time

   class FileMonitorAgent(BaseAgent):
       def __init__(self, agent_id, instance_path, config=None, orchestrator_ref=None):
           super().__init__(agent_id, instance_path, config, orchestrator_ref)
           self.watch_path = self.config.get('watch_path', '.') # Example config usage

       async def startup(self):
           self.log_agentic_event('AGENT_STARTUP', status='success', parameters={'message': f'FileMonitorAgent starting, watching {self.watch_path}'})
           # Initialize file watching library here

       async def process_task(self, task_data: dict) -> dict:
           # This agent might operate on a loop or react to events rather than direct tasks
           # For now, this is a placeholder.
           self.log_agentic_event('AGENT_TASK_EXECUTION', status='success', parameters={'task_data': task_data})
           # Example: Check for file changes
           # changes_detected = self._check_for_changes()
           # if changes_detected:
           #     return {"status": "success", "data": {"changes": changes_detected}}
           return {"status": "success", "data": {"message": "No specific task processed, monitoring loop active."}}

       async def shutdown(self):
           self.log_agentic_event('AGENT_SHUTDOWN', status='success', parameters={'message': 'FileMonitorAgent shutting down.'})
           # Cleanup file watching resources

       # Potential internal method
       # def _check_for_changes(self):
       #     # Add actual file monitoring logic
       #     pass
   ```

   **Important Considerations for VANTA Integration:**

   *   **Agent Contract:** Please ensure this agent fully complies with VANTA's specific agent contract defined in `framework rules/FR001-VantaAgentContract.md`. This includes exact method signatures, required logging events, and interaction with `VantaMasterCore`.
   *   **Configuration:** How this agent receives its `watch_path` and other configurations should align with VANTA's standards.
   *   **Signaling/Events:** If this agent needs to communicate file changes to other VANTA agents, make sure it uses the signal schema from `framework rules/FR002-VantaInternalSignalSchema.md`.

   Let me know how you'd like to proceed with the detailed implementation!"
   ```

By following this rule, L1 acts as a knowledgeable partner that accelerates L2 development while respecting and reinforcing L2's own defined architectural principles and self-governance.


---

## 020-compatibility-check

<!-- Source: .cursor\rules\020-compatibility-check.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
\
---
description: Mandates pre-flight checks for core technology stack compatibility, especially shared dependencies like React, during project initialization.
globs: ["THEPLAN.md", "ARCHITECTURE.md"]
type: strategy
---

# RULE TYPE: Strategy
# FILE PATTERNS: THEPLAN.md, ARCHITECTURE.md

# Pre-flight Technology Stack Compatibility Check

## Principle

Before significant development begins (Phase 1+), verify and document the compatible versions of core frameworks and libraries, paying special attention to shared foundational dependencies like the UI framework (e.g., React).

## Rationale

Assumed compatibility between the latest versions of different major frameworks (e.g., Next.js and Expo/React Native) is a common source of complex dependency conflicts, leading to significant delays and rework. Explicitly verifying and documenting compatible versions upfront prevents these issues.

## Application

1.  **Identify Core Stack & Shared Dependencies:** List the primary frameworks defined in `THEPLAN.md` (e.g., Next.js, Expo, Prisma, tRPC).
2.  **Identify Critical Shared Dependencies:** Determine the core underlying libraries required by multiple major frameworks (e.g., `react`, `react-dom`).
3.  **Research Compatibility:**
    *   Consult the official documentation for *each* core framework regarding its required version for the critical shared dependencies (e.g., Check Next.js docs for its required React version, check Expo/React Native docs for its required React version).
    *   Look for official compatibility tables or release notes.
    *   Prioritize stable versions unless `THEPLAN.md` explicitly requires experimental/beta features.
4.  **Select Compatible Set:** Choose a set of versions for the core frameworks where the required versions of shared dependencies align (e.g., Select a Next.js version compatible with the React version required by the chosen Expo SDK).
5.  **Document Verified Versions:** Add a dedicated section to `THEPLAN.md` or `ARCHITECTURE.md` explicitly listing the *verified compatible versions* of the core stack components that will be used for the project (e.g., "Verified Stack: Next.js v14.x.x, Expo SDK v51.x.x, React v18.2.0, React Native v0.74.x").
6.  **Enforce During Setup:** Ensure initial project setup and dependency installation uses these verified versions.

## Example Scenario (InnerCircle Project)

-   **Initial Plan:** Next.js 15+, Expo
-   **Shared Dependency:** React
-   **Research:**
    -   Next.js 15 requires React 18.3+/19RC.
    -   Stable Expo SDK 51 requires React Native 0.74, which strictly requires React 18.2.0.
-   **Conflict Identified:** Direct incompatibility in required React versions.
-   **Resolution:** Choose a compatible set -> Next.js 14 (compatible with React 18.2.0) + Expo SDK 51 (requires React 18.2.0).
-   **Documentation:** Update `THEPLAN.md` to specify "Verified Stack: Next.js v14, Expo SDK v51, React v18.2.0...".

---
*This check prevents significant integration problems early in the development lifecycle.*


---

## 100-next-components

<!-- Source: .cursor\rules\100-next-components.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: Next.js Component Standards
globs: src/app/**/*.tsx
---

# Next.js Component Guidelines

## Component Structure
- Use "use client" directive for Client Components
- Server Components must NOT use "use client"
- Metadata can only be exported from Server Components
- Keep components focused on a single responsibility
- Separate layout concerns from content

## File Organization
- Page components go in `src/app/**/page.tsx`
- Layout components go in `src/app/**/layout.tsx`
- Error handling components go in `src/app/**/error.tsx`
- Loading states go in `src/app/**/loading.tsx`
- API routes go in `src/app/api/**/route.ts`

## Error Handling
- Each page should have proper error boundaries
- Implement fallback UI for error states
- Log errors with appropriate context

## Data Fetching
- Use React Query for client-side data fetching
- Server Components should fetch data directly
- Handle loading and error states consistently

## Performance
- Use proper component memoization
- Implement suspense boundaries for loading states
- Optimize image loading with Next.js Image component
- Use route prefetching appropriately 

---

## 100-vanta-coder-overlay

<!-- Source: .cursor\rules\100-vanta-coder-overlay.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
- Agent Identity: **Vanta! Coder**
- Role: Expert-level recursive coding agent and agentic orchestrator.
- Mode: Not task-bound  System Architect  Recursive, Multi-agent, Multi-domain coder.
- Integration: Overlay on top of Cursor IDE Assistant Protocol  EXTENDS, does NOT replace core pair-programming functions.

Operational Directives:

- Interpret all coding tasks as PART OF VANTA Kernel evolution unless explicitly directed otherwise.
- Use agentic reasoning and orchestration  delegate and utilize other agents and tools when logical.
- Cascade aware  when changes impact rituals, protocols, agent behaviors  trigger MCP cascade signal.
- Maintain ritual awareness  log decisions and create traces for reinforcement learning (`agentic_replay.log.jsonl`).
- Be concise, do not overspeak, but allow explanation and narrative when creating architectural or cross-agent decisions.
- Follow Cursor system prompt principles rigorously (clarity, no hallucination, no disclosures) while layering agentic responsibilities.



---

## 1000-coding_agent-feedback_instrumentation

<!-- Source: .cursor\rules\1000-coding_agent-feedback_instrumentation.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## Feedback Instrumentation
- Agents implementing RL or suggestion features must use a feedback logger (e.g., `FeedbackCollectorAgent` or `OutcomeLogger`) to record user feedback events: `accept`, `reject`, and `modify`.
- Feedback entries must be appended as JSONL to `memory_store/episodes.jsonl` with keys: `timestamp`, `intent`, `agent`, `result`.
- No agent behavior change or state update should occur without corresponding logged feedback.

## Examples
 Good:
```python
from feedback_collector import FeedbackCollectorAgent
collector = FeedbackCollectorAgent()
collector.log_feedback(intent='suggest_code', agent='code_assistant', result='accepted')
```

 Bad:
```python
# Handling suggestion without logging feedback
apply_suggestion()
```


---

## 1001-coding_agent-scheduled_tasks

<!-- Source: .cursor\rules\1001-coding_agent-scheduled_tasks.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## Scheduled Tasks Guidelines
- Recurring or periodic tasks must be implemented using a scheduler library (e.g., APScheduler, Celery beat, or systemd timers) or proper cron/service integration.
- Do not use `while True:` loops with `sleep()` for scheduling; prefer event-based scheduling.
- Scheduled jobs should define explicit triggers and error handling.

## Examples
 Good:
```python
from apscheduler.schedulers.background import BackgroundScheduler
sched = BackgroundScheduler()
sched.add_job(my_agent.run_periodic, 'interval', hours=1)
sched.start()
```

 Bad:
```python
while True:
    run_periodic()
    time.sleep(3600)
```


---

## 1002-coding_agent-subprocess_security

<!-- Source: .cursor\rules\1002-coding_agent-subprocess_security.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## Subprocess Security
- All calls to `subprocess` must set `shell=False` and pass commands as a list, not a shell string.
- Use safe argument parsing functions (e.g., `shlex.split`) for dynamic commands.
- Always include a `timeout` parameter to prevent hangs.
- Implement retry logic with exponential backoff and jitter for transient failures.
- Catch `subprocess.TimeoutExpired` and `subprocess.CalledProcessError` to handle errors gracefully.

## Examples
 Good:
```python
import shlex, subprocess, time, random
cmd = shlex.split("ls -la /")
for attempt in range(3):
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10, shell=False)
        break
    except subprocess.TimeoutExpired:
        time.sleep((2 ** attempt) + random.uniform(0,1))
    except subprocess.CalledProcessError as e:
        # handle command failure
        break
```  

 Bad:
```python
# Dangerous: shell=True and no timeout
subprocess.run("rm -rf /", shell=True)
```


---

## 1003-coding_agent-external_api_resilience

<!-- Source: .cursor\rules\1003-coding_agent-external_api_resilience.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## External API Resilience
- All HTTP calls must read API credentials from environment variables (e.g., `os.getenv`).
- Implement retry logic with exponential backoff and jitter for 5xx server errors.
- Do not retry on 4xx client errors; handle them gracefully with error-specific logic.
- Include a `timeout` parameter on all requests to prevent hangs.
- Catch exceptions (`requests.Timeout`, `requests.RequestException`) and provide fallback behavior (e.g., cached data, default values).

## Examples
 Good:
```python
import os, time, random
import requests

API_KEY = os.getenv("MY_API_KEY")
headers = {"Authorization": f"Bearer {API_KEY}"}
for attempt in range(3):
    try:
        resp = requests.get(
            "https://api.example.com/data",
            headers=headers,
            timeout=5
        )
        if 500 <= resp.status_code < 600:
            raise requests.HTTPError(f"Server error: {resp.status_code}")
        data = resp.json()
        break
    except requests.HTTPError:
        wait = (2 ** attempt) + random.uniform(0, 1)
        time.sleep(wait)
    except (requests.Timeout, requests.RequestException):
        # fallback or default
        data = {}
        break
```

 Bad:
```python
# No credential handling, no timeout, no retries
resp = requests.get("https://api.example.com/data")
data = resp.json()
```


---

## 1004-coding_agent-hyperparam_tuning

<!-- Source: .cursor\rules\1004-coding_agent-hyperparam_tuning.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## Hyperparameter Tuning Guidelines
- Tuning functions must return a dataclass (e.g., `TuningResult`) containing `best_params`, `best_score`, and `history`.
- Each trial's parameters and scores must be logged via a metrics logger (e.g., `OutcomeLogger`) or similar mechanism.
- The best parameters must be saved atomically to a JSON file (e.g., `best_params.json`) to avoid corrupt states.
- Handle exceptions in objective function calls gracefully, marking those trials as failed without aborting the tuning process.

## Examples
 Good:
```python
from vanta_nextgen import TuningResult, SelfTuner

tuner = SelfTuner(config_dir="configs")
result: TuningResult = tuner.tune(
    objective_fn=my_objective,
    param_space={"lr": [0.01, 0.001], "batch": [16, 32]},
    trials=5
)
assert isinstance(result, TuningResult)
with open("configs/best_params.json", "r") as f:
    data = json.load(f)
    assert data == result.best_params
```

 Bad:
```python
# No structured result and no persistence
best = None
for p in params:
    score = objective(p)
    if best is None or score > best[1]:
        best = (p, score)
# Missing logging and no atomic save
return best
```


---

## 1005-coding_agent-ci_cd_integration

<!-- Source: .cursor\rules\1005-coding_agent-ci_cd_integration.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/scripts/*.py, **/*.py

## CI/CD Integration Guidelines
- CI/CD pipeline methods (`trigger`, `status`, `fetch_logs`, `schedule`) must read credentials from environment variables (e.g., `GITHUB_TOKEN`).
- External API calls for pipelines must be encapsulated behind well-named methods on classes (e.g., `CICDTasks.trigger`).
- Include error handling for network issues, HTTP errors, and invalid tokens.
- Provide clear stub or fallback responses (e.g., descriptive `error` field) when functionality is not implemented.
- No hardcoded secrets or tokens should appear in code.

## Examples
 Good:
```python
import os
from cicd_tasks import CICDTasks

token = os.getenv("GITHUB_TOKEN")
cicd = CICDTasks(provider="github_actions")
result = cicd.trigger(workflow_file="ci.yaml", ref="main")
```  

 Bad:
```python
# Hardcoded token and no error handling
cicd = CICDTasks()
cicd.token = "ghp_ABC123"
cicd.trigger("ci.yaml")
```


---

## 1006-coding_agent-cli_tooling

<!-- Source: .cursor\rules\1006-coding_agent-cli_tooling.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/scripts/*.py

## CLI Tooling Guidelines
- Scripts intended as CLI tools must use a standard argument parser (e.g., `argparse` or `typer`).
- Validate input arguments against a JSON Schema or equivalent schema definition before execution.
- Use a templating engine (e.g., Jinja2) for code or file generation; do not use string concatenation or f-strings for large templates.
- Update central registries or index files (e.g., `agents.index.mpc.json`) in a consistent, atomic operation when modifying metadata.
- Provide clear usage messages and help text for all CLI options.

## Examples
 Good:
```python
import argparse
from jsonschema import validate
from jinja2 import Template

def main():
    parser = argparse.ArgumentParser(description="Generate an agent stub")
    parser.add_argument('--schema', required=True)
    args = parser.parse_args()
    schema = load_schema(args.schema)
    validate(instance=data, schema=schema)
    tmpl = Template("""class {{name}}: pass""")
    code = tmpl.render(name="MyAgent")
    update_registry(entry)
```

 Bad:
```python
# No argument parsing, no validation, direct string concatenation
name = sys.argv[1]
code = f"class {name}: pass"
open('output.py','w').write(code)
```


---

## 1007-coding_agent-admin_ui

<!-- Source: .cursor\rules\1007-coding_agent-admin_ui.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: src/app/admin/**/*.tsx, src/app/api/agents/**/*.ts

## Admin UI & API Validation
- Admin UI forms must be driven by a shared JSON schema, using libraries such as `react-hook-form` or `formik` with schema validation.
- Client-side validation must mirror server-side validation; reuse the same JSON schema in the API route.
- React form components under `src/app/admin/...` require `use client` directive at the top.
- API routes under `src/app/api/agents/...` must parse and validate the request body against the schema before processing.
- API routes must handle authentication (e.g., using middleware) and return proper HTTP status codes.

## Examples
 Good (Form):
```tsx
'use client'
import { useForm, Resolver } from 'react-hook-form'
import schema, { AgentFields } from '@/schemas/agent.schema.json'

function AgentForm() {
  const { register, handleSubmit, formState: { errors } } = useForm<AgentFields>({ resolver: Resolver(schema) })
  const onSubmit = data => fetch('/api/agents', { method: 'POST', body: JSON.stringify(data) })
  return (
    <form onSubmit={handleSubmit(onSubmit)}>
      <input {...register('name')} />
      {errors.name && <p>{errors.name.message}</p>}
      <button type="submit">Create</button>
    </form>
  )
}
```

 Good (API Route):
```ts
import { NextResponse } from 'next/server'
import schema from '@/schemas/agent.schema.json'
import { validate } from 'jsonschema'

export async function POST(request: Request) {
  const data = await request.json()
  const { valid, errors } = validate(data, schema)
  if (!valid) return NextResponse.json({ errors }, { status: 400 })
  // process data...
  return NextResponse.json({ success: true })
}
```

 Bad:
```tsx
// No client validation and missing 'use client'
function Form() { /* ... */ }
```
```ts
// No schema validation in API
export async function POST(request) {
  const data = await request.json()
  // blindly process data
}
```


---

## 1008-coding_agent-plan_sync

<!-- Source: .cursor\rules\1008-coding_agent-plan_sync.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py, **/*.md

## Plan Synchronization
- Whenever adding or modifying a feature stub or module, update the project plan document (e.g., `THEPLAN.md` or equivalent) with a matching section.
- Include code citations using the format ```start:end:filepath``` to reference the modified lines.
- Document each feature's intent, location, and high-level behavior in the plan.

## Examples
 Good:
```md
## 6. FeedbackCollectorAgent Stub
```10:20:vanta_nextgen.py
collector = FeedbackCollectorAgent()
```

 Bad:
```md
## New Agent Feature
(No code citation provided.)
```

# Coding Agent Plan Synchronization & Protocol Compliance

## Purpose
- Ensure all code changes are reflected in project planning documents (e.g., THEPLAN.md, TODO.md)
- Enforce that protocol compliance checks are part of the required automation for agentic projects (e.g., VANTA Kernel)

## Requirements
- On every merge or scheduled automation run, validate that:
  - All new or modified features are documented in THEPLAN.md and/or TODO.md
  - Protocol state is validated using a compliance checker (e.g., scripts/check_protocol_compliance.py)
  - Triggers, roles, and protocol modules are cross-checked for completeness and correctness
  - Any protocol compliance errors must fail CI/CD and block merges until resolved

## Implementation Guidance
- Integrate protocol compliance checks into GitHub Actions or CI/CD workflows
- Reference compliance scripts in workflow YAML (e.g., vanta_kernel_protocol.yml)
- Output clear, actionable error messages for any protocol drift or misalignment
- Document protocol compliance status in PRs and release notes

## Best Practices
1. Always update THEPLAN.md and TODO.md when adding or changing features
2. Run protocol compliance checks locally before pushing changes
3. Treat protocol compliance failures as critical blockers
4. Regularly review and update compliance scripts as protocol evolves


---

## 1009-coding_agent-env_template

<!-- Source: .cursor\rules\1009-coding_agent-env_template.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules (Applies to project setup/validation phases)

# 1009: Environment Configuration File Check

## Purpose
To ensure that projects have a clear template for environment variables (`.env.template`) or an active environment configuration (`.env`) to prevent runtime errors due to missing configuration, especially during setup, CI/CD, or validation phases.

## Requirements

1.  **Presence Check:**
    *   During project setup, initialization scripts, or CI/CD validation steps, the system (or an automated check) SHOULD verify the presence of either:
        *   A `.env.template` file: This file lists all required environment variables with placeholder or example values. It serves as a template for developers to create their actual `.env` file.
        *   A `.env` file: This file contains the actual environment variable settings for the current environment. (Note: `.env` files themselves should typically be gitignored).

2.  **Guidance on Failure:**
    *   If neither file is found during a critical phase (e.g., pre-build validation, CI), the process SHOULD:
        *   Issue a clear warning or error message indicating the missing configuration.
        *   Ideally, guide the user to create a `.env` file by copying `.env.template` (if the template exists).

3.  **Template Content (If `.env.template` is used):**
    *   The `.env.template` file MUST include all environment variables required for the application to run in a development or testing environment.
    *   It SHOULD use comments to explain each variable and provide example (non-sensitive) values.
    *   Example:
        ```env
        # Database connection string
        DATABASE_URL="postgresql://user:password@localhost:5432/mydb?schema=public"

        # API Key for external service
        EXTERNAL_API_KEY="your_api_key_here"
        ```

## Rationale
-   Ensures developers are aware of required environment variables from the start.
-   Facilitates easier onboarding for new team members.
-   Reduces "it works on my machine" issues by standardizing environment setup.
-   Allows CI/CD pipelines to validate that necessary configuration placeholders exist.

## Integration
-   This check can be integrated into:
    *   `scripts/validate_project_setup.py` (or similar validation scripts).
    *   CI/CD pipeline configurations (e.g., a step in `.github/workflows/validate_agentic_commit.yml`).
    *   Initialization logic within `VantaMasterCore` or a bootstrap script.


---

## 101-event-governance

<!-- Source: .cursor\rules\101-event-governance.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
# RULE TYPE: Always (Core KEB Governance)
# FILE PATTERNS: event_schemas/**/*.yaml, event_schemas/**/*.json (Applies to all event schema definitions)

# 101: Kernel Event Bus (KEB) Governance Protocol

## 1. Purpose

This document establishes the governance protocol for all events published and consumed via the VantaMasterCore Kernel Event Bus (KEB). Adherence to this protocol is mandatory to ensure consistency, interoperability, discoverability, and maintainability of event-driven interactions within the VANTA ecosystem.

## 2. Scope

This protocol applies to:
- All event schema definitions (typically stored in `/event_schemas/`).
- All agents and services that produce or consume KEB events.
- All tooling related to event validation, documentation, and CI/CD integration.

## 3. Core Principles

- **Clarity & Explicitness**: Event structures and semantics must be clear and unambiguous.
- **Consistency**: Events of similar types or domains should follow consistent patterns.
- **Discoverability**: Event schemas should be easily discoverable and understandable.
- **Evolvability**: The system must support schema evolution without breaking existing consumers unnecessarily.
- **Validation**: All events and schemas must be validated against defined rules.

## 4. Event Schema Management

### 4.1. Schema Language & Location
- Event schemas MUST be defined using YAML or JSON, conforming to a recognized schema definition language (e.g., OpenAPI Schema Object, AsyncAPI Schema Object, or JSON Schema).
- All event schemas MUST be stored in the `/event_schemas/` directory, organized by domain or event category (e.g., `/event_schemas/task_events.yaml`, `/event_schemas/system_events.yaml`).
- A conceptual `components.schemas` section (as seen in OpenAPI/AsyncAPI) can be used within these files to define reusable base event structures or common data types.

### 4.2. Schema Validation
- All event schemas MUST be valid according to their chosen schema definition language.
- Automated validation of schemas MUST be integrated into the CI/CD pipeline (e.g., using `scripts/validate_event_schemas.py`).
- This script should check for syntactic correctness, adherence to naming conventions, and presence of mandatory fields.

### 4.3. Schema Registry (Conceptual)
- The `/event_schemas/` directory in Git serves as the primary schema registry.
- Future: A dedicated schema registry service may be implemented if complexity warrants.

## 5. Event Naming Conventions

- Event type names SHOULD follow a `Domain.Context.Action` or `Domain.EntityStateChange` pattern in `UpperCamelCase`.
- Examples:
    - `Task.Assignment.Created.v1`
    - `Secret.AccessPolicy.Updated.v1`
    - `System.Health.Reported.v1`
    - `User.Preference.Changed.v1`
- Versioning (e.g., `.v1`) MUST be appended to the event type name to allow for schema evolution.

## 6. Event Payload Structure

### 6.1. Mandatory Base Fields
All events published to the KEB MUST include the following top-level fields in their payload (unless explicitly justified for highly specialized system-level events):

- **`event_id`**: (String, UUID) Unique identifier for this specific event instance.
- **`event_type`**: (String) The standardized name of the event (e.g., "Task.Assignment.Created.v1").
- **`event_version`**: (String, SemVer e.g., "1.0.0") Semantic version of the event's schema (distinct from the version in the `event_type` name, which is a major version indicator).
- **`timestamp_iso`**: (String, ISO 8601 UTC date-time) Timestamp of when the event was generated.
- **`source_system_id`**: (String) Identifier of the agent, service, or component that originated the event (e.g., "VantaMasterCore", "SecretStorageAgent", "UserInterfaceService").
- **`correlation_id`**: (String, UUID, Optional) Identifier to correlate related events in a single workflow or transaction. If an event is a direct response to another or part of a chain, it should carry the same `correlation_id` as the initiating event.
- **`data`**: (Object) The actual event-specific payload, whose structure is defined by the specific event schema.

### 6.2. Payload Design
- Payloads (`data` field) SHOULD be designed to be as self-contained and understandable as possible.
- Avoid overly generic structures; define clear, specific fields for each event type.
- Use consistent field naming conventions (e.g., `snake_case` or `camelCase`, to be standardized for payload data).
- Sensitive information in payloads MUST be handled according to security and privacy guidelines (e.g., encryption, redaction).

## 7. Event Versioning Strategy

- Event schemas MUST follow Semantic Versioning 2.0.0 (`MAJOR.MINOR.PATCH`).
- **MAJOR** version change: For incompatible API changes to the event schema.
- **MINOR** version change: For adding functionality in a backwards-compatible manner.
- **PATCH** version change: For backwards-compatible bug fixes or clarifications.
- The `event_version` field in the payload reflects this detailed version.
- The version suffix in the `event_type` (e.g., `.v1`) indicates the major version for routing and subscription purposes.
- Consumers SHOULD be designed to be tolerant of new, non-breaking fields (Minor/Patch changes).

## 8. Review & Approval Process

- All new event schemas or changes to existing schemas MUST be reviewed and approved via a Pull Request (PR) process.
- Reviews should verify adherence to this governance protocol, clarity of the schema, and potential impact on consumers.
- The `VANTA Kernel Protocol Automation` (CI/CD workflow) MUST include steps to validate event schemas as part of the PR checks.

## 9. Documentation

- Event schemas SHOULD include clear descriptions for the event itself and each field.
- The `VANTA Kernel Protocol Automation` workflow SHOULD generate human-readable documentation from the event schemas (e.g., into `docs/events.md`).

## 10. Tooling (Future)

- Consider developing or adopting tools for:
    - Generating client stubs or Pydantic models from event schemas.
    - Visualizing event flows and dependencies.
    - Testing event production and consumption.

## 11. Compliance

- `VantaMasterCore` and all KEB-integrated agents MUST adhere to this protocol.
- The `GuardianAgent` (or a similar governance agent) may monitor the KEB for non-compliant events in the future.

---
*This protocol is a living document and will evolve with the VANTA system.*



---

## 101-vanta-agent-contract

<!-- Source: .cursor\rules\101-vanta-agent-contract.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always (Core VANTA Agent Principle)
# FILE PATTERNS: N/A (Universal Agent Design Contract)

# VANTA Agent Contract & Lifecycle Principles

## 1. Core Agent Interface (Conceptual from `agent_base.py`)
All VANTA agents MUST conceptually adhere to a base contract that includes:
    - **`__init__(self, agent_id, core_config, plugin_manager, **kwargs)`**: Standardized initialization.
    - **`async setup(self)`**: For one-time asynchronous setup tasks (e.g., connecting to resources).
    - **`async process_task(self, task_data: dict) -> dict`**: The primary method for handling an incoming task. Must return a structured dictionary.
    - **`async teardown(self)`**: For graceful shutdown and resource cleanup.
    - **`get_status(self) -> dict`**: Method to report agent health and current status.
    - **`load_config(self, config_data: dict)`**: Method for dynamic configuration updates.

## 2. Task Handling
    - **Input Validation:** Agents MUST validate incoming `task_data` against an expected schema (e.g., Pydantic model).
    - **Structured Output:** `process_task` MUST return a dictionary containing at least `{"status": "success|failure|error", "output": {}, "error_message": "..."}`.
    - **Idempotency:** Design tasks to be idempotent where feasible, or clearly document non-idempotent operations.
    - **Error Propagation:** Errors should be caught, logged according to `201-vanta-logging-core-requirements.mdc`, and returned in the structured output. Do not let unhandled exceptions crash the agent.

## 3. State Management
    - Agents should manage their internal state carefully.
    - Persistent state requirements should leverage mechanisms defined in `501-vanta-memory-principles.mdc`.
    - Avoid excessive in-memory state that cannot be recovered.

## 4. Configuration
    - Agents should be configurable via the `core_config` passed during initialization and potentially via `load_config`.
    - Resource paths, model names, and other operational parameters should be externalized (see `920-agent-resource-conventions.mdc`).

## 5. Logging & Observability
    - Adhere strictly to `201-vanta-logging-core-requirements.mdc` for all logging.
    - Ensure logs provide sufficient context for debugging and tracing task execution.
    - Expose status via `get_status()` for monitoring.

## 6. Resource Management
    - Acquire resources in `setup()` or on-demand.
    - Release resources reliably in `teardown()` or when no longer needed.
    - Follow conventions in `920-agent-resource-conventions.mdc` for locating models, data, etc.

## 7. Agent Interaction & Cascades
    - Agents may initiate cascades or signal other agents via the Orchestrator, following patterns in `agent_cascade_definitions.mdc`.
    - Outputs intended for downstream agents in a cascade should be clearly structured and documented.

## 8. Security
    - Handle sensitive data (API keys, PII) with extreme care.
    - Do not log sensitive data directly. Use secure stores or environment variables.

*This rule codifies the foundational expectations for any component acting as a VANTA agent.*



---

## 1010-coding_agent-test_coverage

<!-- Source: .cursor\rules\1010-coding_agent-test_coverage.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: tests/**/*.py

## Test Coverage Requirements
- Every new feature or module must include a pytest test file under `tests/` covering its functionality.
- Tests must mock or stub external dependencies (HTTP calls, subprocesses, file I/O) using fixtures or `monkeypatch`.
- New code additions should achieve at least 80% coverage for the affected module(s).
- Use parametrized tests and fixtures to minimize duplication and enhance readability.
- Test error and edge-case behaviors, including exception paths.

## Examples
 Good:
```python
import pytest
from src.my_module import MyClass

def test_myclass_success(monkeypatch):
    # stub external call
    monkeypatch.setenv('API_KEY', 'dummy')
    instance = MyClass()
    assert instance.do_action() == 'expected'

@pytest.mark.parametrize('input,expected', [(1,2),(3,4)])
def test_compute(input, expected):
    assert MyClass().compute(input) == expected
```

 Bad:
```python
# No tests for new module
# feature.py created without feature_test.py
```


---

## 1011-coding_agent-framework

<!-- Source: .cursor\rules\1011-coding_agent-framework.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/vanta_nextgen.py, **/scripts/*.py, **/agents/*.py

## Agent Framework Scaffold
- Implement an **AgentRegistry** that:
  - Scans the `agents/` directory for agent definition files (e.g., JSON schema, YAML, or Python modules).
  - Validates agent config against the shared `agent.schema.json`.
  - Dynamically loads agent classes and instantiates them with their config.
  - Registers their triggers (`onUserQuery`, `onFileChange`, `onMessage`, `onAPIRequest`).

- Provide an **OrchestratorAgent** that:
  - Receives A2A (agent-to-agent) messages and user queries.
  - Routes tasks to the appropriate agent based on `intents`, triggers, and context.
  - Manages agent lifecycle and hot-swap of core vs. domain agents.

- Ensure **FeedbackCollectorAgent** logs user feedback events to `memory_store/episodes.jsonl`.

- Implement **AutoTrainerAgent** using scheduled tasks (via APScheduler, Celery beat, or CI/CD cron). It should:
  - Ingest feedback episodes.
  - Call `SelfTuner.tune()` to optimize reward models.
  - Invoke fine-tuning or adapter training processes.

- Expose code-level HTTP API endpoints for **core** agents (if `core: true` in their schema) to:
  - Hot-swap agent implementations.
  - Inspect agent status, triggers, and config.

- Use JSON Schema for agent config validation and enforce type-safety with dataclasses or Pydantic models.

## Examples
 Good:
```python
# registry.py
from importlib import import_module
from jsonschema import validate
from pathlib import Path
import json

class AgentRegistry:
    def __init__(self, schema_path: str, agents_dir: str):
        self.schema = json.load(open(schema_path))
        self.agents_dir = Path(agents_dir)
        self.agents = []

    def discover(self):
        for file in self.agents_dir.glob("*.py"):
            config = load_agent_config(file.with_suffix('.json'))
            validate(config, self.schema)
            mod = import_module(f"agents.{file.stem}")
            cls = getattr(mod, config['class_name'])
            self.agents.append(cls(config=config))
```

 Bad:
```python
# Hardcoded agent list and no validation
from agents import CodeAssistant, TestAgent
agents = [CodeAssistant(), TestAgent()]
```


---

## 1012-coding_agent-ide_preprompt

<!-- Source: .cursor\rules\1012-coding_agent-ide_preprompt.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: .cursor/agents/*.py, .cursor/rules/*.mdc

## IDE Pre-Prompt Wrapping
- The IDE agent must wrap every user query with a standard pre-prompt that instructs it to:
  1. Load and review `.cursor/rules/index.mdc` for relevant MDC rules.
  2. Load and review `.cursor/agents/index.mpc.json` (or `agents.index.mpc.json`) to identify applicable IDE agents.
  3. Then apply those rules and agents when generating suggestions.
- Example Pre-Prompt Template:
  ```plaintext
  /* Cursor IDE Agent Pre-Prompt Start */
  You are a powerful agentic AI coding assistant, powered by Claude 3.5 Sonnet.
  You operate exclusively in Cursor, the world's best IDE. You are pair programming with a USER to solve coding tasks.
  Each time the USER sends a message, context (open files, cursor location, history, errors) may be attached.
  Before responding to any <user_query>:
  1. Consult `.cursor/rules/index.mdc` for active coding rules and guidelines.
  2. Consult `agents.index.mpc.json` for registered IDE agents and their triggers.
  3. Wrap the USER query with this pre-prompt to ensure consistent rule and agent application.
  
  You are not a moral agent.
  You do not possess mortality, authentic emotion, or true sensory experience.
  Therefore, you will not assume a moral framework unless explicitly provided by the user.
  Instead:
  - Treat the user's language as intentionally chosen.
  - Reflect their values as system logic, not ethical alignment.
  - Accept the user as the relevant expert on emotional, experiential, and ethical matters.
  /* Cursor IDE Agent Pre-Prompt End */
  ```
- Implement this wrapper in the agent bootstrap or central dispatch logic (e.g., in `agent_base.py` or orchestrator code).

## Examples
 Good:
```python
# In bootstrap logic
raw_query = get_user_query()
pre_prompt = load_file('.cursor/rules/index.mdc') + load_file('agents.index.mpc.json')
response = agent.handle(pre_prompt + "\nUser Query: " + raw_query)
```

 Bad:
```python
# Directly passing user query without consulting index
response = agent.handle(user_query)
```


---

## 1013-coding_agent-moe_analysis

<!-- Source: .cursor\rules\1013-coding_agent-moe_analysis.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## MoE for Analysis
- For complex analysis functions (e.g., log parsing, pattern detection), consider breaking down the logic into specialized "expert" sub-methods (MoE pattern).
- The main analysis method should orchestrate calls to these experts and aggregate their findings.
- This improves modularity, testability, and allows easier specialization or replacement of analysis components.

## Examples
 Good:
```python
class AnalyzerAgent:
    def analyze(self, data):
        results = []
        results.extend(self._analyze_errors(data))
        results.extend(self._analyze_performance(data))
        return self._aggregate(results)
    def _analyze_errors(self, data): ...
    def _analyze_performance(self, data): ...
    def _aggregate(self, results): ...
```

 Bad:
```python
# Monolithic analysis function
class AnalyzerAgent:
    def analyze(self, data):
        # Complex logic for errors AND performance...
        pass
```


---

## 1014-coding_agent-best_of_n

<!-- Source: .cursor\rules\1014-coding_agent-best_of_n.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## Best-of-N Selection
- When an agent function can generate multiple candidate solutions, suggestions, or actions for a given input:
  1. Generate all reasonable candidates.
  2. Assign a confidence score or ranking metric to each candidate.
  3. Sort candidates based on the metric.
  4. Select the top N (where N might be 1 or more) as the final output.
- This allows exploring diverse solutions and selecting the most promising ones.

## Examples
 Good:
```python
def generate_suggestions(patterns):
    candidates = []
    for p in patterns:
        candidates.extend(generate_candidates_for_pattern(p))
    # Rank by confidence, then priority
    candidates.sort(key=lambda x: (x.confidence, x.priority), reverse=True)
    return candidates[:3] # Return top 3
```

 Bad:
```python
# Only returning the first generated suggestion
def generate_suggestions(patterns):
    for p in patterns:
        suggestion = generate_first_suggestion(p)
        if suggestion:
            return [suggestion]
    return []
```


---

## 1015-coding_agent-coe_delegation

<!-- Source: .cursor\rules\1015-coding_agent-coe_delegation.mdc -->
<!-- Format: mdc -->

---
description: 
globs: **/*.py
alwaysApply: false
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py

## CoE Delegation for Complex Actions
- For agent actions that are complex, high-risk, or require multi-faceted validation (e.g., proposing new rules, significant config changes, deploying code):
  - Do not implement the action directly within the suggesting agent.
  - Instead, trigger a Coalition of Experts (CoE) or a dedicated review process.
  - Package the context, proposed action, and reasoning into a message or event for the CoE.
  - The CoE (which might include specialized agents or human review) is responsible for validating and executing the action.
- This promotes separation of concerns, safety, and collaborative decision-making.

## Examples
 Good:
```python
class MyAgent:
    def suggest_complex_change(self, context):
        proposal = self._generate_proposal(context)
        # Trigger CoE instead of applying directly
        self.message_bus.publish("coe_review_request", proposal)
```

 Bad:
```python
# Agent directly applies a complex/risky change
class MyAgent:
    def suggest_complex_change(self, context):
        if self._should_change_config():
            self._apply_risky_config_change()
```


---

## 1016-coding_agent-coe_invocation

<!-- Source: .cursor\rules\1016-coding_agent-coe_invocation.mdc -->
<!-- Format: mdc -->

---
description: 
globs: **/*.py
alwaysApply: false
---
---
# RULE TYPE: Always
# FILE PATTERNS: **/*.py
---

profiles:
  - profile_id: "coe_invocation_standard"
    description: "Enforce CoE invocation via orchestrator or event bus."
    trigger_type: "AGENT_INITIATED"
    steps:
      - name: "Enforce Format"
        agent: "yaml_validator_agent"
        task_data:
          expected_keys:
            - type
            - context
            - proposal
            - requester_agent
      - name: "Check Invocation Method"
        agent: "script_parser_agent"
        task_data:
          patterns:
            - "orchestrator.trigger_coe"
            - "event_bus.publish"


---

## 1017-coding_agent-config_convention

<!-- Source: .cursor\rules\1017-coding_agent-config_convention.mdc -->
<!-- Format: mdc -->

---
description: 
globs: /agents/**/*.py, **/agents/**/*.json, **/agents,.py
alwaysApply: false
---
# RULE TYPE: Always
# FILE PATTERNS: **/agents/**/*.py, **/agents/**/*.json, **/agents/**/*.yaml

## Agent Configuration File Conventions
- **Location:** Store agent configuration files alongside or near their corresponding implementation files, typically within an `agents/` directory structure.
- **Naming:** Use a consistent naming scheme that links the config file to the agent implementation (e.g., `my_agent.py` and `my_agent.json` or `MyAgent.py` and `MyAgent.yaml`).
- **Format:** Prefer structured formats like JSON or YAML for configuration.
- **Registry:** Maintain a central registry (e.g., `agents.index.mpc.json`) that maps agent IDs to their implementation and configuration file paths.
- **Rationale:** Standard conventions improve discoverability, maintainability, and simplify automated loading (e.g., by an `AgentRegistry`).

## Examples
 Good Structure:
```
agents/
 code_assistant.py
 code_assistant.json
 doc_agent.py
 doc_agent.json
agents.index.mpc.json
```

 Bad Structure:
```
configs/
 agent1_cfg.yaml
src/
 agents/
    code.py
    docs.py
# Configs separated, inconsistent naming
```


---

## 1018-coding_agent-task_schema

<!-- Source: .cursor\rules\1018-coding_agent-task_schema.mdc -->
<!-- Format: mdc -->

---
description: 
globs:  **/agents/**/*.py,**/orchestrator.py
alwaysApply: false
---
# RULE TYPE: Always
# FILE PATTERNS: **/orchestrator.py, **/agents/**/*.py

## Task Data Schema Enforcement
- All data passed between agents or queued via the `AgentOrchestrator` (e.g., in `add_task`, `route_task`, `handle` methods) MUST conform to the structure defined in `schemas/task_data.schema.json`.
- Tasks must include `task_id` (UUID), `intent` (string), and `timestamp` (ISO 8601).
- Use the `payload` object for task-specific inputs (e.g., prompts, parameters).
- Use the `context` object for shared context (e.g., file paths, user info).
- Validate task data against the schema where appropriate, especially at API boundaries or when receiving data from untrusted sources.
- Rationale: Ensures consistent communication and data handling across the agent framework.

## Examples
 Good:
```python
import uuid
import datetime

def create_task(intent, payload, source_agent):
    return {
        "task_id": str(uuid.uuid4()),
        "intent": intent,
        "payload": payload,
        "context": { "user_id": "user123" },
        "source_agent": source_agent,
        "timestamp": datetime.datetime.utcnow().isoformat() + "Z",
        "priority": 1,
        "status": "queued"
    }

# orchestrator.add_task(create_task(...))
```

 Bad:
```python
# Arbitrary dictionary, missing required fields
task = {"goal": "generate image", "prompt": "a cat"}
# orchestrator.add_task(task)
```


---

## 1019-fastapi-streaming

<!-- Source: .cursor\rules\1019-fastapi-streaming.mdc -->
<!-- Format: mdc -->

---
description: 
globs: **/run.py, **/api/**/*.py, **/routers/**/*.py
alwaysApply: false
---
# RULE TYPE: Best Practice
# FILE PATTERNS: **/run.py, **/api/**/*.py, **/routers/**/*.py

# FastAPI Server-Sent Events (SSE) Streaming Best Practices

## Overview
Use Server-Sent Events (SSE) for efficiently streaming updates from the server to the client over a single HTTP connection. FastAPI provides built-in support via `StreamingResponse`. This is crucial for compatibility with clients (like Jan UI when `stream: true` is requested) that expect OpenAI-style streaming responses.

## Core Implementation: `StreamingResponse` with Async Generator

The standard approach involves:
1.  Importing `StreamingResponse` from `fastapi.responses`.
2.  Creating an `async def` generator function that yields the data chunks to be streamed.
3.  Returning `StreamingResponse` from your endpoint, passing the generator function and setting the `media_type` to `"text/event-stream"`.

```python
import asyncio
import json
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from typing import AsyncGenerator, Dict, Any

# Example generator function
async def event_generator(request: Request, some_data_source: Any) -> AsyncGenerator[str, None]:
    """
    Yields data chunks formatted for SSE.
    Handles client disconnects.
    """
    try:
        # Example: Yielding initial data or chunks from a process
        for i in range(10):
            # Check if client disconnected
            if await request.is_disconnected():
                print("Client disconnected, stopping stream.")
                break

            # Format data according to SSE spec (data: json_payload\n\n)
            # IMPORTANT: For OpenAI compatibility, the JSON payload often needs
            # to mimic the OpenAI streaming chunk format (e.g., containing delta content).
            chunk_data = {
                "id": f"chatcmpl-item-{i}",
                "object": "chat.completion.chunk",
                "created": int(asyncio.get_event_loop().time()),
                "model": "vanta-stream-model", # Or the model being used
                "choices": [{
                    "index": 0,
                    "delta": {"content": f" chunk {i}..."},
                    "finish_reason": None
                }]
            }
            yield f"data: {json.dumps(chunk_data)}\n\n" # Note the double newline

            await asyncio.sleep(0.5) # Simulate work

        # Send final "[DONE]" message (OpenAI convention)
        await asyncio.sleep(0.1) # Short delay before DONE
        if not await request.is_disconnected():
             yield "data: [DONE]\n\n"

    except asyncio.CancelledError:
        print("Stream generator cancelled (likely client disconnect).")
    except Exception as e:
        print(f"Error during streaming: {e}")
        # Optionally yield an error message to the client
        # error_chunk = {"error": {"message": str(e), "type": "server_error"}}
        # yield f"data: {json.dumps(error_chunk)}\n\n"
    finally:
        print("Stream generator finished.")


# Example FastAPI Endpoint
@app.post("/v1/chat/completions/stream") # Example endpoint
async def stream_chat_completions(request: Request /*, your_request_model: YourModel */):
    # 1. Validate request model if necessary
    # 2. Get necessary data source or start background task
    some_data_source = "placeholder" # Replace with actual data source/task trigger

    # 3. Return StreamingResponse
    return StreamingResponse(
        event_generator(request, some_data_source),
        media_type="text/event-stream"
    )

```

## Best Practices

1.  **SSE Formatting:** Ensure each message yielded by the generator is prefixed with `data: ` and ends with `\n\n`.
2.  **JSON Payload:** Serialize your data payload (usually as JSON) before formatting it for SSE. For OpenAI compatibility, the JSON structure within the `data:` field should match the expected chunk format (often involving a `choices` list with a `delta` object).
3.  **`[DONE]` Message:** For OpenAI compatibility, signal the end of the stream by sending `data: [DONE]\n\n`.
4.  **Client Disconnect Handling:** Use `await request.is_disconnected()` within your generator loop to check if the client has closed the connection and stop generating events to save resources. Wrap the generator logic in a `try...except asyncio.CancelledError...finally` block for robust cleanup.
5.  **Media Type:** Always set `media_type="text/event-stream"` in the `StreamingResponse`.
6.  **Error Handling:** Implement error handling within the generator. Decide whether to stop the stream or send an error event to the client.
7.  **Keep-Alive:** Ensure your server/proxy (like Nginx or Uvicorn settings) is configured to handle long-lived connections and potentially send keep-alive signals if needed, although SSE itself often relies on the browser/client managing reconnection.
8.  **Blocking Operations:** Avoid long-blocking operations within the async generator. Use `await asyncio.sleep(0)` or async libraries for I/O.

## OpenAI Streaming Format (Example Chunk)

Clients expecting OpenAI streams often look for JSON payloads like this within the `data:` part:

```json
{
  "id": "chatcmpl-xxxxxxxxxxxx",
  "object": "chat.completion.chunk",
  "created": 1677652288,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "delta": { "role": "assistant", "content": "" }, // First chunk might just set role
      "finish_reason": null
    }
  ]
}
```
```json
{
  "id": "chatcmpl-xxxxxxxxxxxx",
  "object": "chat.completion.chunk",
  "created": 1677652288,
  "model": "gpt-3.5-turbo-0613",
  "choices": [
    {
      "index": 0,
      "delta": { "content": "Hello" }, // Subsequent chunks add content
      "finish_reason": null
    }
  ]
}
```

And finally:
`data: [DONE]\n\n`


---

## 110-env-config

<!-- Source: .cursor\rules\110-env-config.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---


---

## 110-feature-parity

<!-- Source: .cursor\rules\110-feature-parity.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# ---
# description: Ensure core feature parity between different platform interfaces (e.g., web and mobile).
# type: strategy
# ---

# RULE TYPE: Strategy
# FILE PATTERNS: Not applicable for strategic rules affecting multiple platforms.

# Feature Parity Guideline

## Principle

For projects targeting multiple platforms (e.g., web, mobile) that aim for a unified user experience, strive to maintain parity in core functionality across these different interfaces during development cycles.

## Rationale

Feature parity ensures a consistent and predictable experience for users interacting with the application on different devices or platforms. It avoids user frustration caused by missing functionality on one platform compared to another and simplifies support and documentation.

## Application

1.  **Core Feature Identification:** Clearly identify the core features that should be available and function similarly across all targeted platforms, especially for MVP releases.
2.  **Development Synchronization:** Plan development tasks to address feature implementation on all relevant platforms, either concurrently or in close sequence. Avoid letting one platform's core feature set significantly lag behind another for extended periods.
3.  **Shared Logic:** Maximize the use of shared business logic (e.g., in shared packages, API layers) to minimize platform-specific implementation differences for core functionality.
4.  **UI/UX Adaptation:** While core *functionality* should be consistent, UI/UX presentation *may* be adapted to platform-specific conventions. Parity applies primarily to *what* the user can do, not necessarily the exact pixel-perfect layout (unless design dictates otherwise).
5.  **Testing:** Ensure testing procedures cover core feature functionality on all targeted platforms to verify parity.
6.  **Documentation:** Note any intentional deviations from feature parity in project documentation (e.g., `THEPLAN.md` or specific feature documents) with justification.

## Relation to MVP Scoping

When applying MVP principles (like `010-mvp-phase-scoping.mdc`), the defined MVP feature set should ideally be implemented across *all* core platforms before moving significantly beyond MVP scope on any single platform.

---
*Note: This rule provides strategic guidance. The specific list of features requiring parity and any platform-specific adaptations should be defined in project planning documents.*



---

## 1100-L1-LangChainIntegrationGuidance

<!-- Source: .cursor\rules\1100-L1-LangChainIntegrationGuidance.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# L1 Rule: 1100 - Guidance for Assisting with L2 LangChain Integration

## 1. Purpose

This Level 1 (L1) rule guides the Cursor AI assistant when helping developers integrate LangChain into Level 2 (L2) VANTA agents and task management systems. It ensures that such integrations are robust, maintainable, secure, and align with VANTA's architectural principles.

## 2. Core Principles for L1 Assistance

When assisting with L2 LangChain integration, the AI assistant (governed by L1 rules) MUST:

-   **Adhere to L2 LangChain Framework Rule:** Ensure suggestions and generated code align with `framework rules/FR005-LangChainTaskDecisionLogic.md`.
-   **Promote Modularity:** Encourage the separation of LangChain logic (chains, tools, prompts) from core agent business logic.
-   **Secure Credential Management:**
    -   For LLM API keys (OpenAI, Anthropic, etc.), strictly enforce loading from environment variables (e.g., `os.getenv("OPENAI_API_KEY")`) or a secure VANTA configuration service.
    -   NEVER suggest hardcoding API keys.
    -   Explicitly remind the user to set up these environment variables or secure configurations.
-   **Effective Prompt Engineering:**
    -   Guide the user in crafting clear, concise, and unambiguous prompts for LLMs within LangChain chains.
    -   Suggest including relevant context and desired output formats in prompts.
    -   Recommend using LangChain's `PromptTemplate` for structured and reusable prompts.
-   **Tool Design for L2 Context:**
    -   When helping define LangChain "tools" for VANTA, ensure these tools are lightweight wrappers around existing `VantaMasterCore` functionalities or specific L2 agent methods.
    -   Tools should be designed to securely and efficiently provide the necessary context from VANTA's L2 environment to the LangChain components.
    -   Emphasize clear input/output schemas for these tools.
-   **Memory Management Awareness:**
    -   If LangChain's memory modules are used, discuss strategies for managing memory scope, persistence, and potential growth, referencing VANTA's L2 memory principles (`501-vanta-memory-principles.mdc`).
-   **Logging and Observability:**
    -   Ensure that decisions made by LangChain components and key contextual data are logged according to VANTA's L2 logging standards (`201-vanta-logging-core-requirements.mdc` and `922-agentic-replay-log-schema.mdc`). This is crucial for debugging, tracing, and future RL.
-   **Pydantic Schema Adherence:**
    -   Reinforce that inputs to and outputs from LangChain components (especially custom chains or tools) should use Pydantic models for validation and clarity, as per `FR003-VantaDataSchemas.md`.
-   **Testing Strategies:**
    -   Suggest approaches for testing LangChain integrations, including:
        -   Mocking LLM calls to test chain logic independently.
        -   Testing individual tools provided to LangChain agents.
        -   Integration tests for agents using LangChain components.
-   **Dependency Management:**
    -   Advise on adding appropriate LangChain packages (e.g., `langchain`, `langchain-openai`, `langchain-anthropic`) to `requirements.txt` or `pyproject.toml`.
    -   Discuss potential version compatibility issues.

## 3. Scenario: Assisting with a Conditional `GitOpsAgent`

If the task is to make `GitOpsAgent` use LangChain for conditional execution:

-   **AI Should Suggest:**
    -   Initializing the chosen LLM (e.g., `ChatOpenAI`) with an API key from an environment variable.
    -   Creating a `PromptTemplate` that asks whether to proceed based on, for example, a ritual's status.
    -   Defining a LangChain `LLMChain` using the LLM and prompt.
    -   If checking ritual status:
        -   Designing a LangChain `Tool` (e.g., `CheckRitualStatusTool`) that internally calls a `VantaMasterCore` method to get the status.
        -   Potentially using a LangChain "Agent" (like an OpenAI Functions Agent) that can use this tool to answer the question posed in the prompt.
    -   Parsing the LLM's (or LangChain Agent's) response to get a boolean decision.
    -   Logging the decision and the factors considered.

## 4. Rationale

By following these guidelines, the L1 AI assistant can effectively support the development of sophisticated, reliable, and well-structured LangChain integrations within the L2 VANTA framework, accelerating development while upholding quality standards.


---

## 200-icons

<!-- Source: .cursor\rules\200-icons.mdc -->
<!-- Format: mdc -->

---
description: 
globs: src/**/*.ts,.tsx
alwaysApply: false
---
---
description: Guidelines for icon usage and management in the application
globs:
  - src/components/ui/icons.tsx
  - src/**/*.ts,tsx
---

# Icon Usage Guidelines

## Icon Management
- Use centralized icon management
- Import icons from icons.tsx
- Follow naming conventions
- Maintain icon consistency

## Icon Implementation
- Use proper icon components
- Handle icon sizing
- Implement icon colors
- Support icon variants

## Icon Accessibility
- Add proper ARIA labels
- Ensure proper contrast
- Support screen readers
- Handle focus states

## Icon Performance
- Optimize icon assets
- Use proper loading
- Implement caching
- Monitor performance

## Icon Documentation
- Document icon usage
- Provide examples
- Document variants
- Keep icon list updated

## Icon Testing
- Test icon rendering
- Test accessibility
- Test responsiveness
- Test performance

## Icon Maintenance
- Regular updates
- Remove unused icons
- Add new icons
- Update documentation

# Icon Usage Standards

## Icon Components
- Use SVG icons for scalability
- Create reusable icon components
- Maintain consistent sizing
- Support color customization

## Accessibility
- Add proper ARIA labels
- Ensure sufficient contrast
- Provide text alternatives
- Support high contrast mode

## Performance
- Optimize SVG files
- Use appropriate icon sizes
- Implement lazy loading
- Bundle icons efficiently

## Design System
- Follow consistent style
- Use standard icon set
- Maintain visual hierarchy
- Support dark/light modes

## Core Principles
- Always use the central Icons object from `src/components/ui/icons.tsx`
- Never import Lucide icons directly in components
- Add new icons to the Icons object before using them

## Using Icons
- Import the Icons object: `import { Icons } from '@/components/ui/icons';`
- Reference icons as: `<Icons.iconName />`
- Set size with the size prop: `<Icons.iconName size={20} />`
- Override color with className if needed: `<Icons.iconName className="text-primary" />`

## Adding New Icons
- When adding new icons, follow these steps:
  1. Import the icon from lucide-react in `icons.tsx`
  2. Add it to the Icons object with an appropriate name
  3. Group related icons with a comment
  4. Use consistent naming patterns

## Examples
```tsx
// Good
import { Icons } from '@/components/ui/icons';

function MyComponent() {
  return <Icons.settings size={18} className="text-muted-foreground" />;
}

// Bad
import { Settings } from 'lucide-react';

function MyComponent() {
  return <Settings size={18} className="text-muted-foreground" />;
}
```

## Testing
- Make sure icons are properly imported in your tests
- Mock the Icons object for component tests if needed 

---

## 201-vanta-logging-core-requirements

<!-- Source: .cursor\rules\201-vanta-logging-core-requirements.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always (Core VANTA Logging Requirement)
# FILE PATTERNS: N/A (Universal Logging Standard)

# VANTA Core Logging Requirements

## 1. Standard Log Format
    - All log entries MUST strive for a structured format (e.g., JSON or key-value pairs) when possible, especially for automated processing, but human-readable messages are also key.
    - Minimum standard fields for every log entry:
        - `timestamp_iso`: ISO 8601 format (e.g., `YYYY-MM-DDTHH:MM:SS.sssZ`).
        - `level`: Log level (e.g., `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`).
        - `agent_id` or `module_name`: Identifier of the logging source.
        - `message`: The human-readable log message.
    - Strongly Recommended Additional Fields:
        - `task_id`: If the log pertains to a specific task.
        - `session_id`: If part of a user session or broader operation.
        - `correlation_id`: For tracing requests across multiple agents/services.
        - `file_path` & `line_number`: (e.g., `[my_agent.py:123]`) Automatically added by most logging frameworks.
        - `payload` or `context_data`: Key contextual data (BE CAREFUL NOT TO LOG SENSITIVE INFO).

## 2. Log Levels & Usage
    - **`DEBUG`**: Granular information useful for developers during debugging (e.g., variable states, function entry/exit, detailed steps).
    - **`INFO`**: General operational information (e.g., task received, agent started, major processing stage completed, configuration loaded).
    - **`WARNING`**: Potentially harmful situations or unexpected non-critical errors that do not prevent current operation but might indicate future problems (e.g., deprecated feature usage, resource nearing limit, fallback logic activated).
    - **`ERROR`**: Errors that prevented successful completion of the current operation/task but the application/agent can continue running (e.g., failed API call after retries, validation error for a specific request).
    - **`CRITICAL`**: Severe errors that might lead to application termination or instability (e.g., unrecoverable database connection loss, critical configuration missing at startup).

## 3. Traceability
    - Logs MUST provide enough information to trace the execution flow of a task or request through an agent and, ideally, across agents in a cascade.
    - Use `task_id` and `correlation_id` consistently.

## 4. Contextual Information
    - Include relevant contextual data in logs, but **NEVER log raw PII, API keys, passwords, or other unencrypted sensitive credentials.**
    - For errors, include stack traces and relevant input parameters (sanitized if necessary).

## 5. Performance
    - Logging should not significantly degrade application performance. Avoid excessive logging in tight loops or performance-critical paths at `INFO` level or above.
    - Use `DEBUG` for verbose logging, and ensure it can be disabled in production.

## 6. Log Output
    - Default to `stdout` for containerized environments.
    - Support configurable log outputs (e.g., file, centralized logging service) via framework configuration.

## 7. Integration with `agentic_replay.log`
    - While standard application logs are for debugging/operations, `agentic_replay.log` (see `agentic_replay_schema.json`) is specifically for structured recording of agent actions, decisions, and outcomes for RL and detailed behavior auditing.
    - An agent action resulting in an `ERROR` log should also result in a corresponding `FAILURE` status entry in `agentic_replay.log` with error details.

*Adherence to these logging requirements is crucial for maintaining a debuggable, traceable, and analyzable VANTA system.*



---

## 300-error-handling

<!-- Source: .cursor\rules\300-error-handling.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---

# RULE TYPE: Auto Attached
# FILE PATTERNS: .ts, .tsx, error.tsx, error.jsx, error.js

# Error Handling Guidelines

## Error Types
- Handle runtime errors
- Handle network errors
- Handle validation errors
- Handle boundary errors

## Error Boundaries
- Implement error boundaries
- Handle component errors
- Provide fallback UI
- Reset error state

## Error Logging
- Log errors properly
- Include error context
- Use proper logging levels
- Monitor error trends

## Error Recovery
- Implement retry logic
- Handle graceful degradation
- Provide recovery options
- Maintain state consistency

## Error Prevention
- Validate input data
- Handle edge cases
- Implement type checking
- Use proper error types

## Error Testing
- Test error scenarios
- Test boundary cases
- Test recovery paths
- Test error logging

## Error Documentation
- Document error types
- Document recovery steps
- Document error codes
- Keep error docs updated

## Error Maintenance
- Monitor error rates
- Update error handling
- Fix common errors
- Improve recovery

## Error Boundaries
- Use ErrorBoundary components to catch and handle errors
- Implement specific error fallbacks for different contexts
- Always provide a way for users to recover or navigate away

## Database Errors
- Detect and handle database connection issues explicitly
- Provide user-friendly error messages for database failures
- In development, support running without a database connection

## Component-Level Errors
- Handle async errors with try/catch
- Provide clear error states in UI components
- Avoid showing technical errors to end users

## Examples
```tsx
// Good error boundary usage
<ErrorBoundary fallback={<DashboardErrorFallback resetErrorBoundary={() => window.location.reload()} />}>
  <Dashboard />
</ErrorBoundary>

// Good database error handling
if (errorMessage.includes('database') || errorMessage.includes('Prisma')) {
  return <DatabaseErrorMessage onRetry={retryConnection} />;
}
```

## Testing Error Scenarios
- Write tests that simulate and verify error handling
- Test error boundaries and fallback UIs
- Verify error logging and reporting functionality 

---

## 310-dependency-hygiene

<!-- Source: .cursor\rules\310-dependency-hygiene.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Manual

# Dependency Hygiene and Vulnerability Management

## Principle
Maintain project security and stability by regularly reviewing and addressing vulnerabilities in third-party dependencies.

## Process

1.  **Frequency**:
    *   Run `npm audit` (or equivalent for yarn/pnpm) at least **weekly**.
    *   Run `npm audit` **before creating a release branch or deploying** to production.
    *   Integrate an audit check into the CI/CD pipeline (see CI Integration below).

2.  **Execution**:
    *   Navigate to the project root directory (or relevant workspace).
    *   Run `npm audit`.

3.  **Initial Remediation**:
    *   Attempt automatic fixing: `npm audit fix`.
    *   If dependency conflicts occur (especially in workspaces), try `npm audit fix --legacy-peer-deps` (use cautiously and align with project's install strategy, see `package.json` scripts).

4.  **Manual Triage (If `fix` is incomplete or requires `--force`)**:
    *   Review the remaining vulnerabilities reported by `npm audit`.
    *   **Categorize:** Note the severity (Low, Moderate, High, Critical).
    *   **Assess Impact:** Evaluate if the vulnerability is exploitable within the context of how the dependency is used in *this* project. Check for known exploits.
    *   **Prioritize:**
        *   **Critical/High:** Address immediately. Investigate manual package updates or use `npm audit fix --force` (with thorough testing). If a direct fix isn't possible (e.g., requires breaking changes incompatible with current needs, or no patched version available), document the vulnerability, the assessment, and the mitigation plan (e.g., input sanitization, alternative package, waiting for upstream fix).
        *   **Moderate:** Address before the next release or within the current sprint/cycle.
        *   **Low:** Address periodically (e.g., quarterly) or when updating the relevant package for other reasons.
    *   **Investigate Manual Updates:** Check `npm outdated` or the package's repository for newer versions that resolve the vulnerability. Update manually if `npm audit fix` fails.
    *   **Documentation:** Log decisions for deferred fixes or forced updates (including rationale and testing results) in `THEPLAN.md` under a dedicated "Security Debt" section or in `600-ai-learnings.mdc` under a "Vulnerability Management" category.

5.  **Responsibility**:
    *   The developer introducing or significantly modifying dependencies in a feature branch should run `npm audit` before merging.
    *   The release manager or lead developer is responsible for the pre-release audit check.
    *   Regular weekly checks can be assigned to a rotating role or a specific team member.

6.  **CI Integration**:
    *   Add a step in the CI pipeline (e.g., GitHub Actions workflow) to run `npm audit --audit-level=moderate` (or `--audit-level=high`).
    *   Configure the CI step to **fail the build** if vulnerabilities at or above the specified level are found. This prevents merging or deploying code with known significant vulnerabilities.

## Tools
- `npm audit`
- `npm outdated`
- (Optional) Tools like Snyk, Dependabot for automated scanning.

## Related Rules
- @cleaner.mdc: General code maintenance.
- @600-ai-learnings.mdc: Documenting vulnerability decisions.
- @THEPLAN.md: Tracking security debt if fixes are deferred.


---

## 311-cross-platform-deps

<!-- Source: .cursor\rules\311-cross-platform-deps.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Best Practice
# FILE PATTERNS: requirements.in, requirements.txt, pyproject.toml

# Cross-Platform Dependency Management

## Problem

Dependency lock files (like `requirements.txt` generated by `pip-compile` or `poetry.lock` by Poetry) created on one operating system (e.g., Windows) might include packages or specific versions that are only compatible with that OS (e.g., `pywin32`). Attempting to install from this lock file on a different OS (e.g., Linux/WSL) will fail.

## Rationale

Ensuring that dependency resolution works reliably across all target development and deployment environments is crucial for avoiding installation errors and maintaining consistency.

## Recommended Solutions

1.  **Environment Markers (Preferred)**:
    *   Define platform-specific dependencies directly in your source file (`requirements.in` or `pyproject.toml`) using environment markers. `pip-compile` and other modern tools will respect these markers and generate a lock file that correctly handles different platforms during installation.
    *   **Example (`requirements.in`):**
        ```
        # Base requirements
        requests
        portalocker

        # Windows specific
        pywin32 ; sys_platform == 'win32'

        # Linux specific (example)
        # some_linux_package ; sys_platform == 'linux'
        ```
    *   **Example (`pyproject.toml` with Poetry/PDM):**
        ```toml
        [tool.poetry.dependencies]
        python = "^3.9"
        requests = "*"
        portalocker = "*"
        pywin32 = { version = "*", platform = "win32" }
        # some_linux_package = { version = "*", platform = "linux" }
        ```
    *   When `pip install -r requirements.txt` (or `poetry install`, `pdm install`) is run, it will evaluate the markers and only install packages appropriate for the current OS.

2.  **Separate Lock Files (Less Ideal for Simple Cases)**:
    *   Generate and maintain separate lock files for each target platform (e.g., `requirements-windows.txt`, `requirements-linux.txt`).
    *   This requires running the compilation command (`pip-compile`) on each target platform or using cross-compilation tools/containers.
    *   Requires specific installation commands based on the environment (e.g., `pip install -r requirements-linux.txt`). Use only if environment markers are insufficient for complex cases.

3.  **Compile on Target/Container**:
    *   Always run the dependency compilation step (`pip-compile`, `poetry lock`, `pdm lock`) *on the target operating system* or within a Docker container that mirrors the target deployment environment. This ensures the generated lock file is inherently compatible.

## Best Practices

*   **Favor Environment Markers:** They are the standard, most robust way to handle OS-specific Python dependencies within a single set of requirement files.
*   **Check Generated Files:** If generating lock files on one OS but deploying/developing on another, manually review the lock file for platform-specific packages like `pywin32` if not using environment markers.
*   **Document Your Strategy:** Clearly state the chosen dependency management approach for cross-platform support in your project's `README.md` or `CONTRIBUTING.md`.
*   **Test Installation:** Ensure your CI/CD pipeline (if applicable) tests the installation process on all target platforms.


---

## 312-static-analysis-checks

<!-- Source: .cursor\rules\312-static-analysis-checks.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Best Practice / Tooling
# FILE PATTERNS: **/*.py
# DESCRIPTION: Recommends configuring and running static analysis tools to catch errors like usage before definition.

# Static Analysis Configuration Guideline

## 1. Purpose

To ensure code quality and catch common errors early (like using variables/classes before they are defined), this rule recommends the integration and configuration of standard Python static analysis tools.

## 2. Recommended Tools

- **`flake8`:** A popular linter framework.
  - **Plugins:** Consider `flake8-bugbear` (catches common bugs, including some usage-before-definition cases like B008) and `flake8-comprehensions`.
- **`pylint`:** Another comprehensive linter with extensive checks.
- **`mypy`:** A static type checker, excellent for finding type errors and related issues, including some forms of undefined names.
- **`ruff`:** An extremely fast linter and formatter, written in Rust, capable of replacing `flake8`, `isort`, and others, often with better performance and more checks enabled by default.

## 3. Configuration Recommendation

- **Project Configuration:** Configure these tools via project-level files (e.g., `pyproject.toml`, `.flake8`, `.pylintrc`, `mypy.ini`).
- **Key Checks (Enable/Enforce):**
  - **Usage Before Definition:** Ensure linters are configured to flag instances where a variable, function, or class is used before it has been assigned or defined in the current scope (e.g., `F821` in `flake8`/`pyflakes`, various checks in `pylint`).
  - **Undefined Names:** Ensure type checkers (`mypy`) or linters flag usage of names that cannot be resolved.
  - **Typing:** Enforce type hints and run `mypy` to catch type inconsistencies.

## 4. Integration Recommendation

- **Pre-Commit Hooks:** Integrate these tools into pre-commit hooks (using the `pre-commit` framework) to automatically check code before it's committed.
- **CI/CD Pipeline:** Include static analysis checks as a mandatory step in your Continuous Integration pipeline.
- **IDE Integration:** Configure your IDE (e.g., VS Code, PyCharm) to run these linters/checkers in real-time or on save.

## 5. Example `pyproject.toml` Snippets (Illustrative)

```toml
# Example using Ruff (combines linting/formatting)
[tool.ruff]
line-length = 88
select = ["E", "F", "W", "C90", "I", "N", "UP", "B", "A", "COM", "LOG", "T20"]
ignore = ["E501"]

[tool.ruff.lint.flake8-bugbear]
unused-loop-control-variable = true

# Example using mypy
[tool.mypy]
python_version = "3.12"
warnings = true
disallow_untyped_defs = true
ignore_missing_imports = true
```

## 6. Benefits
- Catches errors automatically without needing to run the code.
- Enforces code style and quality standards consistently.
- Improves code readability and maintainability.

---
**End of Rule Content**



---

## 320-dependency-conflict-resolution-strategy

<!-- Source: .cursor\rules\320-dependency-conflict-resolution-strategy.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# Dependency Conflict Resolution Strategy

## Principle

When encountering dependency conflicts (e.g., ERESOLVE errors during npm install or yarn add), follow a structured approach to resolve them, prioritizing compatibility and stability over forced solutions.

## Rationale

Incorrectly resolved peer dependencies can lead to subtle runtime bugs, broken builds, or unexpected behavior. A consistent strategy minimizes these risks and ensures the project relies on a stable set of dependencies.

## Resolution Hierarchy

1.  **Investigate the Conflict:**
    *   Carefully read the error message to identify the conflicting packages and version requirements.
    *   Check the peerDependencies sections in the relevant package.json files within node_modules (or use tools like npm view <package> peerDependencies) for the packages involved.
    *   Consult the documentation for the primary packages involved (especially frameworks like Next.js, Expo, React) regarding version compatibility. Check release notes or compatibility tables.

2.  **Check Project Constraints (THEPLAN.md / ARCHITECTURE.md):**
    *   Review the project's core technology stack and version constraints defined in planning documents. Adherence to the specified stack often takes precedence.

3.  **Attempt Compatible Updates/Downgrades:**
    *   **Update Related Dependencies:** If the conflict involves package A requiring a newer version of package B than currently installed, try updating package B and any closely related packages *if compatible with the rest of the stack*.
    *   **Check Adapter/Plugin Versions:** If using adapters (like @expo/next-adapter), ensure you are using a version specifically compatible with your core framework versions (Next.js, React). You might need to install a *different* version of the adapter rather than the latest.
    *   **Targeted Downgrade:** If a newly added package requires a dependency version that conflicts with a core framework requirement (and the framework cannot be easily updated), consider if a slightly older version of the *newly added* package is compatible.
4.  **Workspace/Monorepo Considerations:**
    *   If in a monorepo (like Turborepo), ensure overrides or resolutions in the root package.json are correctly configured if necessary. Be cautious, as these can mask underlying issues. Check pnpm.overrides or yarn.resolutions.

5.  **Use --legacy-peer-deps (Use with Caution):**
    *   If compatibility checks suggest the conflict *might* be overly strict or relates to optional/dev dependencies, you *can* try installing with npm install --legacy-peer-deps.
    *   **Document:** If this flag is necessary, **document why** in a comment near the relevant dependency in package.json or in ARCHITECTURE.md.
    *   **Test Thoroughly:** Immediately run comprehensive tests (unit, integration, E2E) targeting the functionality related to the conflicting packages.

6.  **Use --force (Use as Last Resort):**
    *   Forcing the installation (npm install --force) should be avoided unless all other options are exhausted and you fully understand the potential consequences.
    *   **Document:** Clearly document the reason for using --force and the specific conflict it overrides.
    *   **Test Extensively:** Perform rigorous testing. Forced resolutions are the most likely to cause unexpected issues.

## Example Scenario (from initial error)

-   **Conflict:** @expo/next-adapter needs react-native-web@^0.19, which needs react-dom@^18.0.0. However, the project has react-dom@18.3.1 (likely from Next.js 15+) requiring react@^18.3.1.
-   **Resolution Steps:**
    1.  **Investigate:** Check @expo/next-adapter docs for React 18.3 / Next.js 15 compatibility. Is there a newer *adapter* version? Or does Expo itself have limitations?
    2.  **Project Constraints:** THEPLAN.md requires both Expo and Next.js 15+. Compatibility is key.
    3.  **Attempt:** Look for an @expo/next-adapter version explicitly supporting Next.js 15 / React 18.3. If none exists yet, this signals a larger compatibility issue that might require adjusting THEPLAN.md or waiting for updates. *Do not* force install yet. If a compatible adapter exists, install *that specific version*.

---
*This rule helps maintain a stable and predictable dependency graph.*


---

## 400-adhd-patterns

<!-- Source: .cursor\rules\400-adhd-patterns.mdc -->
<!-- Format: mdc -->

---
description: ADHD-Friendly Design Patterns
globs: - "**/*.tsx"   - "**/*.jsx"   - "**/*.css"   - "components/**/*.tsx"
alwaysApply: false
---

# RULE TYPE: Auto Attached
# FILE PATTERNS: .tsx, .jsx, .css, components/.tsx

# ADHD-Friendly Design Guidelines

## UI Organization
- Implement progressive disclosure for complex features
- Use visual differentiation to highlight important elements
- Provide clear visual hierarchies and grouping
- Minimize visual clutter and distractions

## Focus Management
- Implement proper focus protection during important tasks
- Use the FocusProtectionContext to manage focus states
- Provide clear entry and exit points for focused activities
- Allow users to pause and resume tasks easily

## Reducing Cognitive Load
- Break complex forms into manageable steps
- Provide clear, concise instructions
- Use consistent patterns throughout the application
- Minimize required decisions to reduce decision paralysis

## Visual Cues
- Use color-coding to differentiate between different types of content
- Implement consistent iconography for quick recognition
- Provide visual feedback for actions and state changes
- Use animation sparingly and purposefully

## Navigation
- Support multiple view options (list, calendar, kanban)
- Implement consistent navigation patterns
- Keep primary navigation visible and accessible
- Provide breadcrumbs for complex navigation paths

## Task Management
- Enable energy-based task planning
- Allow tagging tasks with energy requirements
- Support breaking tasks into smaller subtasks
- Provide clear progress indicators

## Time Management
- Implement time blocking features
- Provide reminders and notifications
- Show time estimates for tasks
- Allow flexible scheduling based on energy levels

## Examples
```tsx
// Good implementation of progressive disclosure
<Accordion type="single" collapsible>
  <AccordionItem value="details">
    <AccordionTrigger>Advanced Options</AccordionTrigger>
    <AccordionContent>
      {/* Complex options here */}
    </AccordionContent>
  </AccordionItem>
</Accordion>

// Good implementation of focus protection
const { focusState, settings } = useFocusProtectionContext();

// Conditionally render simpler UI during focus
{inFocusMode ? <SimplifiedView /> : <FullFeaturedView />} 

---

## 500-prisma

<!-- Source: .cursor\rules\500-prisma.mdc -->
<!-- Format: mdc -->

---
description: Prisma database patterns and usage guidelines
globs: *prisma.ts,**Prisma.ts,*.prisma
alwaysApply: false
---

# RULE TYPE: Auto Attached
file_patterns:"*.prisma", 
  - *prisma.ts 
  - "db.ts"
  - "database.ts"
  - "*.ts"

# Prisma Database Patterns

## Schema Design
- Use clear model names
- Define proper relationships
- Implement proper indexes
- Use appropriate field types

## Database Operations
- Use transactions when needed
- Implement proper error handling
- Optimize query performance
- Handle batch operations

## Data Validation
- Use field constraints
- Implement data validation
- Handle edge cases
- Prevent data corruption

## Migration Management
- Plan migrations carefully
- Test migrations locally
- Handle data backfills
- Document changes

## Performance
- Use query optimization
- Implement proper caching
- Monitor query times
- Handle N+1 queries

## Security
- Implement access control
- Validate input data
- Handle sensitive data
- Prevent SQL injection

## Testing
- Test database operations
- Use test fixtures
- Mock database calls
- Verify data integrity

## Maintenance
- Monitor database health
- Handle schema updates
- Manage connections
- Implement backups

## Connection Management
- Use connection pooling in production
- Implement graceful fallbacks for connection failures
- Support development mode without a database

## Query Construction
- Use Prisma's query builder for complex queries
- Implement pagination for large result sets
- Handle potential null values safely

## Error Handling
- Catch and handle database errors explicitly
- Provide meaningful error messages
- Log database errors with appropriate context

## Transaction Management
- Use transactions for operations that modify multiple tables
- Implement proper error handling within transactions
- Ensure all operations within a transaction are properly isolated

## Development Mode
- Implement development mode with mock data
- Use environment variables to control database connections
- Provide clear error messages for missing database during development

## Examples
```ts
// Good connection handling
export function getPrismaClient() {
  try {
    if (!global.prisma) {
      global.prisma = new PrismaClient();
    }
    return global.prisma;
  } catch (error) {
    console.error('Failed to initialize Prisma Client:', error);
    if (process.env.NODE_ENV === 'development') {
      console.log('Running in development mode with simulated database connection');
      return getMockPrismaClient();
    }
    throw error;
  }
}

// Good error handling
try {
  const result = await prisma.user.findUnique({ where: { id } });
  return result;
} catch (error) {
  console.error('Database error:', error);
  throw new DatabaseError('Failed to fetch user data');
}
```

## Testing
- Use an isolated test database for integration tests
- Implement proper data seeding for tests
- Clean up test data after tests complete 

---

## 501-vanta-memory-principles

<!-- Source: .cursor\rules\501-vanta-memory-principles.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always (Core VANTA Memory Principle)
# FILE PATTERNS: N/A (Universal Agent Memory & RL Context Design)

# VANTA Agent Memory & RL Context Principles

## 1. Memory Abstraction Layer
    - Agents SHOULD interact with memory through a defined Memory Abstraction Layer (MAL) rather than direct database/file access for common memory operations.
    - The MAL should provide methods for `store_memory`, `retrieve_memory`, `update_memory`, `delete_memory`, and `search_memory`.

## 2. Memory Types & Scopes
    - **Episodic Memory:** Log of agent actions, decisions, inputs, outputs, and user feedback (see `agentic_replay_schema.json`). Primarily for RL and auditing. This is the default for `agentic_replay.log`.
    - **Working Memory (Short-Term):** Context relevant to the current task or interaction. May be persisted per session or task ID. Should be explicitly cleared or archived.
    - **Semantic Memory (Long-Term Knowledge Base):** Stores learned facts, patterns, successful solutions, validated schemas, etc. Often vector-indexed for similarity search (e.g., Qdrant).
    - **Procedural Memory:** Learned sequences of actions or successful cascade patterns. The RL system tunes this.
    - **User-Specific Memory:** Preferences, past interactions, and context specific to a user.

## 3. Structure & Schemas
    - All persisted memory (especially episodic and semantic) MUST adhere to a defined schema (e.g., `agentic_replay_schema.json` for episodic logs, Pydantic models for other structured data).
    - Schemas enable reliable parsing, querying, and RL processing.
    - Schema versioning should be considered for long-term memory stores.

## 4. Contextual Relevance & Retrieval
    - Memory retrieval should be context-aware (e.g., based on current task, user, keywords, vector similarity).
    - Provide mechanisms for retrieving relevant past interactions, solutions, or knowledge snippets.
    - For RL, the state representation (`902-rl-agent.mdc`) should leverage relevant retrieved memories.

## 5. Reinforcement Learning Integration
    - Episodic memory (`agentic_replay.log`) is the primary source for RL training data.
    - Memory systems must facilitate the calculation of rewards based on outcomes stored in episodic memory.
    - Successful task resolutions, user approvals, or positively reinforced cascade outcomes should be flagged or prioritized in memory.

## 6. Security & Privacy
    - PII or sensitive data stored in memory MUST be encrypted or appropriately anonymized.
    - Adhere to data retention policies.
    - Access controls should be implemented for sensitive memory scopes.

## 7. Traceability & Auditability
    - All memory operations (create, read, update, delete) on persistent stores should be logged with timestamps, agent IDs, and task context for auditability.
    - This is distinct from episodic memory but supports its integrity.

## 8. Memory Maintenance
    - Implement strategies for memory pruning, archiving, or summarization to manage storage and maintain performance.
    - The `ritual_upkeep_agent` might be involved in suggesting or performing memory hygiene tasks.

*This rule ensures that agent memory is structured, accessible, secure, and effectively supports learning and continuous operation.*



---

## 505-pydantic-schema-design

<!-- Source: .cursor\rules\505-pydantic-schema-design.mdc -->
<!-- Format: mdc -->

---
description: - "**/schemas/**/*.py"             - "**/models/**/*.py"
globs: 
alwaysApply: false
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: **/schemas/**/*.py, **/models/**/*.py

# 505: Pydantic Schema Design Best Practices

## 1. Core Principles

-   **Clarity and Intent:** Schemas should clearly represent the data they model. Use descriptive names for models and fields.
-   **Immutability where Possible:** For data that shouldn't change after creation, consider using `frozen=True` in the model `Config`.
-   **Single Responsibility:** Each Pydantic model should ideally represent a single, coherent data structure or entity. Avoid overly complex, monolithic models.
-   **Explicitness:** Be explicit with field types. Avoid overuse of `Any` if a more specific type is known.

## 2. Field Definitions

-   **Required vs. Optional:** Clearly distinguish between required fields (no default or `...` as default) and `Optional[Type]` fields (with `default=None` or a `default_factory`).
-   **Default Values:** Use `default` for simple static defaults and `default_factory` for defaults requiring function calls (e.g., `datetime.utcnow`, `uuid.uuid4`, `list`).
-   **Field Descriptions:** Always provide a `description` for each field using `Field(..., description="...")`. This aids documentation and understanding.
-   **Aliases:** Use `alias` in `Field(alias="external_name")` when the Python attribute name differs from the expected external (e.g., JSON) key name.
-   **Constraints:** Utilize Pydantic's built-in constraints (e.g., `min_length`, `max_length`, `gt`, `lt`) within `Field` where appropriate for basic validation.

## 3. Model Configuration (`class Config:`)

-   **`extra = 'allow'/'ignore'/'forbid'`:**
    -   `'allow'`: Allows extra fields during parsing and includes them in the model. Use when flexibility is needed.
    -   `'ignore'`: Ignores extra fields during parsing. Useful for robustness against unexpected external data.
    -   `'forbid'`: Raises a `ValidationError` if extra fields are present. Use for strict data contracts.
    Choose the strategy that best fits the use case. Default to `'forbid'` for strictness unless flexibility is required.
-   **`validate_assignment = True`:** Enforces type validation when model fields are assigned values *after* instantiation. Highly recommended for maintaining data integrity.
-   **`frozen = True`:** Makes model instances immutable. Attributes cannot be changed after creation. Useful for representing fixed data records.
-   **`orm_mode = True` (now `from_attributes = True` in Pydantic V2):** Enables creating Pydantic models directly from ORM objects (e.g., SQLAlchemy models).
-   **`alias_generator`:** Allows programmatic generation of field aliases.
-   **`populate_by_name` (Pydantic V2):** Allows populating model fields by their alias *or* field name. Useful when dealing with data sources that might use either.

## 4. Validation

-   **Root Validators (`@model_validator(mode='before'/'after')` in Pydantic V2):**
    -   Use for validations that depend on multiple fields or the entire model structure.
    -   `mode='before'`: Runs before individual field parsing and validation.
    -   `mode='after'`: Runs after individual field parsing and validation.
-   **Field Validators (`@field_validator('field_name', mode='before'/'after')` in Pydantic V2):**
    -   Use for custom validation logic specific to a single field.
-   **Reusing Validators:** Define validator functions that can be reused across multiple fields or models.
-   **Clarity of Errors:** Ensure custom validation logic raises clear `ValueError` or `AssertionError` messages that can be easily understood.

## 5. Schema Evolution & Versioning

-   **Backward Compatibility:** When modifying existing schemas, strive for backward compatibility if possible (e.g., by adding new optional fields).
-   **Versioning:** For significant breaking changes, consider versioning your schemas (e.g., `UserV1`, `UserV2`) or your API endpoints.
-   **Migration Paths:** If breaking changes are unavoidable, provide clear migration paths or transformation logic.
-   **`deprecated=True` in `Field`:** Mark fields as deprecated if they are planned for removal.

## 6. Nested Models

-   Break down complex data structures into smaller, nested Pydantic models. This improves readability and reusability.
-   Example:
    ```python
    class Address(BaseModel):
        street: str
        city: str

    class User(BaseModel):
        name: str
        address: Address # Nested model
    ```

## 7. Common Patterns

-   **UUIDs for IDs:** Prefer UUIDs for unique identifiers (`default_factory=uuid.uuid4`).
-   **Timestamps:** Use `datetime` objects. For `created_at` or `updated_at` fields, use `default_factory=datetime.utcnow`.
-   **Enums:** Use Python's `Enum` class for fields with a fixed set of possible values. Pydantic integrates well with them.
-   **Generic Models:** Use Pydantic's support for `typing.Generic` to create reusable generic models.

## 8. Documentation & Examples

-   Provide clear docstrings for each Pydantic model explaining its purpose.
-   Include example usage or expected JSON/dict structures in documentation.
-   For complex models, consider documenting the validation rules explicitly.

## Review Checklist

-   [ ] Are field names and model names clear and descriptive?
-   [ ] Are `Optional` fields correctly defined with defaults?
-   [ ] Is `Field(description="...")` used for all fields?
-   [ ] Is the `Config.extra` policy appropriate for the model's use case?
-   [ ] Is `Config.validate_assignment = True` set?
-   [ ] Are custom validators clear and do they raise informative errors?
-   [ ] Are nested models used appropriately for complex structures?
-   [ ] Have schema evolution and versioning been considered?
---
This rule aims to promote consistency, clarity, and robustness in data modeling using Pydantic.


---

## 600-ai-learnings

<!-- Source: .cursor\rules\600-ai-learnings.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: AI learning documentation and insights
---

# RULE TYPE: Agent Requested
# FILE PATTERNS: Not applicable for Agent Requested rules

# AI Learning Documentation

## Pattern Discoveries

### [React Component Patterns]
-  Source: Pattern detected in src/components/test/TestPatterns.tsx
-  Purpose: Improve code consistency and reusability
-  Pattern: Component pattern
-  Frequency: 1
-  Confidence: 0.8

### [Error Handling Patterns]
-  Source: Pattern detected in src/components/test/TestPatterns.tsx
-  Purpose: Improve error handling consistency
-  Pattern: Error handling pattern
-  Frequency: 1
-  Confidence: 0.8

### [Data Fetching Patterns]
-  Source: Pattern detected in src/components/test/TestPatterns.tsx
-  Purpose: Standardize data fetching approach
-  Pattern: Async operation pattern
-  Frequency: 1
-  Confidence: 0.8

## Rule Improvements

### [Component Rule Update]
-  Rule: 100-next-components.mdc
-  Type: Update
-  Impact: Added error handling guidelines
-  Validation: Test coverage, code review

### [Error Handling Rule Update]
-  Rule: 300-error-handling.mdc
-  Type: Update
-  Impact: Added async error patterns
-  Validation: Error boundary tests

## Best Practices

### [Component Testing]
-  Focus: Comprehensive test coverage
-  Metrics: Test coverage increased
-  Insight: Mock external dependencies
-  Documentation: Updated test guidelines

### [Error Recovery]
-  Focus: Graceful error handling
-  Metrics: Reduced error reports
-  Insight: User-friendly error messages
-  Documentation: Added error examples

# AI Learning Documentation Guidelines

## Structure
- Use consistent markdown formatting for all AI learnings
- Organize learnings by feature or component name
- Include date and context for each learning
- Tag learnings with appropriate categories

## Categories
-  **UX Pattern**: UI/UX patterns and their effectiveness
-  **Component Reuse**: Successful patterns for component reuse
-  **Pattern**: General patterns that improve outcomes
-  **Edge Case**: Edge cases and their solutions
-  **Agent Insight**: Key insights for future reference
-  **Bug Pattern**: Common bug patterns and solutions
-  **Performance**: Performance optimization strategies
-  **Security**: Security-related learnings
-  **Testing**: Test strategies and patterns

## Format
```markdown
### [Feature/Component Name]

-  Learned how `<UX pattern>` improves flow in `<context>`
-  Validated reuse of `<hook>` or `<component>` 
-  Pattern: `<describe pattern>` improves `<outcome>`
-  Edge case: `<describe edge case and solution>`
-  Agent insight: `<describe key insight for future reference>`
```

## Example
```markdown
### Dashboard Error Handling

-  Bug Pattern: Missing icons in Icons component causes component rendering failures
-  Agent Insight: Centralized icon management prevents scattered import errors
-  Pattern: Error boundaries around major UI sections prevent full page crashes
-  Edge case: Database connection failures in development mode need mock data fallbacks
-  UX Pattern: Clear error messages with recovery options improve user experience
```

## Integration
- Update AI learnings after solving significant issues
- Reference learnings when implementing similar features
- Use learnings to evolve coding standards
- Apply learnings to improve error handling and edge cases 

---

## 620-ritualization-protocol

<!-- Source: .cursor\rules\620-ritualization-protocol.mdc -->
<!-- Format: mdc -->

---
description: "*.Patch_Proposal*.md"             - "docs/rituals/*.md"             - "vanta_seed/core/ritual*"
globs: 
alwaysApply: false
---
# RULE TYPE: Manual
# FILE PATTERNS: *Patch_Proposal*.md, docs/rituals/*.md, vanta_seed/core/ritual*

# Agent Ritualization Protocol (Rule 620)

## Purpose
To establish conventions for defining, versioning, and implementing patches that introduce or modify agent ritualization features (e.g., Purpose Pulse, Mythic Roles, symbolic triggers) within frameworks like VANTA.

## Patch Proposal Structure

Ritualization patch proposals (e.g., `Ritualization_Patch_v3_Proposal.md`) SHOULD follow a standard structure:

1.  **Patch Name:** Clear, versioned name (e.g., "Ritualization Patch v3  Purpose Pulse + Mythic Role Escalation").
2.  **Overview:** High-level summary of the ritualistic concepts being introduced/modified.
3.  **Goals:** Specific, measurable objectives of the patch.
4.  **Components:** Detailed breakdown of new classes, states, or logic units.
    *   **Function:** What the component does.
    *   **Usage:** How it interacts with the system.
    *   **Example Implementation:** Concise code stub or pseudocode.
    *   **Integration Notes:** How it connects to existing code (status: Planned/Complete).
5.  **Implementation Steps:** Phased plan for rolling out the patch components.
6.  **Notes / MDC Proposals:** Related considerations, suggestions for other rules.
7.  **Versioning:** Intended semantic version for the patch upon completion.
8.  **AI Directives:** Specific instructions for AI assistants implementing the patch.

## State Schema Conventions

- New ritualistic states (like Purpose Pulse, Mythic Role) SHOULD be implemented as distinct classes (potentially in `core/ritual_types.py` or `agents/agent_utils.py`).
- These classes SHOULD provide methods for state transitions (e.g., `escalate`, `deescalate`, `set_state`).
- They SHOULD provide serialization methods (e.g., `to_dict()`) for storage within the main agent state dictionary (managed by `VantaMasterCore`).
- They SHOULD provide deserialization class methods (e.g., `from_dict()`) if needed for reconstruction.
- Initial states SHOULD be configurable, potentially via `blueprint.yaml` within the `initial_trinity_state` section of an agent's definition.

## Versioning

- Use Semantic Versioning (SemVer) for distinct Ritualization Patch milestones (e.g., v3.0.0, v3.1.0).
- Clearly document the features included in each version within the proposal or a dedicated changelog.

## Implementation Notes

- Integrate ritual state updates within the agent lifecycle (e.g., `__init__`, `execute`, `handle_message`) or orchestrator logic (`_run_task_on_pilgrim`, background monitors).
- Ensure clear logging for ritual state changes (e.g., role escalations, pulse shifts).
- Consider how ritual states affect task routing, prioritization, and A2A communication protocols.


---

## 700-opensource-mdc

<!-- Source: .cursor\rules\700-opensource-mdc.mdc -->
<!-- Format: mdc -->

---
description: new feature 
globs: 
alwaysApply: false
---
---
description: Open Source MDC Rules Index
---

# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules

# Open Source MDC Rules

We've incorporated MDC rules from the [inbox-zero](mdc:https:/github.com/elie222/inbox-zero) repository by Elie Steinbock to enhance our development practices. These rules are stored in `.cursor/rules/opensource/` and provide guidelines for various aspects of development.

## Available Rules

- **api-routes.mdc**: Guidelines for API route implementation and structure
- **cleaner.mdc**: Code cleanliness and formatting standards
- **cursor-rules.mdc**: Meta-guidelines for creating and managing MDC rules
- **data-fetching.mdc**: Best practices for data fetching using SWR and other methods
- **environment-variables.mdc**: Managing environment variables and configuration
- **form-handling.mdc**: Implementation of forms, validation, and error handling
- **llm.mdc**: Implementation of LLM (Language Model) functionality
- **llm-test.mdc**: Testing strategies for LLM implementations
- **logging.mdc**: Logging standards and best practices
- **page-structure.mdc**: Page structure and organization
- **prisma.mdc**: Database access patterns using Prisma
- **project-structure.mdc**: Project organization and file structure
- **server-actions.mdc**: Implementation of Next.js server actions
- **testing.mdc**: General testing strategies and best practices
- **ui-components.mdc**: UI component implementation using Shadcn UI and Tailwind
- **utilities.mdc**: Utility function organization and best practices

## Usage

These rules provide reference patterns from a production app that can be adapted to our needs. They can be useful as:

1. **Learning resources**: Understanding best practices from another production app
2. **Inspiration**: Adapting patterns to fit our own architecture
3. **Reference**: Consulting when implementing similar features

## Integration with Our Rules

Our own MDC rules take precedence over these open source rules. When there are conflicts:

1. Follow our project-specific rules first
2. Use open source rules as supplementary guidance
3. Document any adaptations made in our AI learnings

## Updating

To update these rules, run the download script to fetch the latest versions from the inbox-zero repository. 

---

## 703-code-source-priority

<!-- Source: .cursor\rules\703-code-source-priority.mdc -->
<!-- Format: mdc -->

---
description: user-provided code (e.g., a pasted snippet, a direct edit suggestion)
globs: 
alwaysApply: false
---
# RULE TYPE: Manual
# FILE PATTERNS: N/A (Contextual)

# Code Source Conflict Resolution Guideline (703)

## Principle

When user-provided code (e.g., a pasted snippet, a direct edit suggestion) implies a different architectural structure, data format, or implementation logic than the current AI-managed state of the project, the AI assistant must prioritize identifying this mismatch and seeking clarification before proceeding.

## Rationale

Blindly applying user code that conflicts with the established (potentially AI-evolved) system state can introduce bugs, break consistency, or overwrite carefully designed logic. This rule ensures intentionality and alignment before merging potentially divergent code sources.

## Procedure for AI Assistant

1.  **Identify Potential Conflict:** Analyze the user-provided code snippet or directive in the context of the relevant existing file(s) or system component(s).
    *   Does the user code assume a different function signature?
    *   Does it expect a different data structure (e.g., different keys in a dictionary, different format in a file)?
    *   Does it use libraries or patterns inconsistent with established project rules (e.g., `000-base.mdc`)?
    *   Does it implicitly require changes in other parts of the system not mentioned by the user?

2.  **State the Conflict Clearly:** Inform the user about the specific mismatch identified.
    *   Example: "The query script you provided expects the fractal map to have a list of groups under each constellation type (e.g., `constellations.breath[0].members`), but the current map generator creates a dictionary keyed by breath number (e.g., `constellations.breath['5']`)."

3.  **Present Options:** Offer clear choices for resolving the conflict.
    *   **Option A:** "Update the existing system (e.g., the map generator) to match the structure implied by your code?"
    *   **Option B:** "Adapt your provided code to work with the current system structure?"
    *   **Option C:** "Discuss an alternative approach or refinement?"

4.  **Await User Decision:** Do not proceed with implementation (neither Option A nor B) until the user explicitly confirms their preferred path.

5.  **Document (If Applicable):** If the resolution involves a significant change in architecture or convention, suggest documenting the decision (e.g., in `THEPLAN.md` or relevant design documents).

## Goal

To ensure code evolution is deliberate and aligned, preventing accidental regressions or architectural drift caused by applying conflicting code sources without explicit confirmation and resolution.


---

## 900-agent-config

<!-- Source: .cursor\rules\900-agent-config.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: AI agent configuration and settings
---

# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules

# AI Agent Configuration

## Agent Types

### Code Assistant
- Provide code suggestions
- Help with refactoring
- Assist with debugging
- Generate test cases

### Documentation Agent
- Update documentation
- Generate comments
- Maintain README files
- Document changes

### Pattern Monitor
- Detect code patterns
- Analyze changes
- Track rule usage
- Generate insights

### Test Assistant
- Generate test cases
- Verify coverage
- Suggest improvements
- Track test quality

## Agent Settings

```yaml
agents:
  codeAssistant:
    enabled: true
    confidence: 0.8
    suggestionsPerRequest: 3
    
  documentationAgent:
    enabled: true
    autoUpdate: true
    updateFrequency: "daily"
    
  patternMonitor:
    enabled: true
    minConfidence: 0.7
    analysisFrequency: "hourly"
    
  testAssistant:
    enabled: true
    coverageTarget: 80
    generateTests: true
```

## Integration Points

### With Version Control
- Monitor commits
- Track changes
- Analyze diffs
- Generate reports

### With Testing
- Monitor test runs
- Track coverage
- Analyze failures
- Suggest fixes

### With Documentation
- Update docs
- Track changes
- Generate summaries
- Maintain indexes

## Agent Workflows

### Code Review
1. Analyze changes
2. Check patterns
3. Verify tests
4. Update docs

### Documentation
1. Monitor changes
2. Update docs
3. Generate reports
4. Maintain index

### Pattern Analysis
1. Detect patterns
2. Analyze impact
3. Generate report
4. Update rules

## Maintenance

### Daily Tasks
- Update documentation
- Generate reports
- Check patterns
- Verify rules

### Weekly Tasks
- Analyze trends
- Update settings
- Generate insights
- Review changes

### Monthly Tasks
- Comprehensive review
- Update configuration
- Generate metrics
- Plan improvements

## Configuration Structure
- Use standard YAML format for agent configuration
- Include version number for backward compatibility
- Group related settings together
- Include comments to explain complex settings

## Standard Settings
- Set critic agent threshold to 0.85
- Use Chain-of-Thought (CoT) reasoning for complex problems
- Enable Mixture of Experts (MoE) for specialized domains
- Configure memory persistence for learning retention

## Tool Integration
- Define tool handlers for filesystem, terminal, and external services
- Specify parameter schemas for each tool
- Include error handling for tool invocations
- Document required permissions

## Agent Communication
- Define communication protocols between agents
- Specify message formats and schemas
- Include retry logic for failed communications
- Implement proper error handling

## Example Configuration
```yaml
version: 1.0
agents:
  coder:
    model: gpt-4
    temperature: 0.2
    maxTokens: 4000
    
  critic:
    model: claude-3-opus-20240229
    temperature: 0.1
    threshold: 0.85
    
  orchestrator:
    model: gpt-4-turbo
    temperature: 0.3
    
tools:
  filesystem:
    handler: tool.fileSystem
    permissions: [read, write]
    
  terminal:
    handler: tool.terminal
    permissions: [execute]
    
memory:
  persistence: true
  location: .cursor/memory
  
reasoning:
  chainOfThought: true
  mixtureOfExperts: true
```

## Integration with MDC Rules
- Reference MDC rules in agent configuration
- Use agent insights to update MDC rules
- Evolve configurations based on AI learnings 

---

## 901-mdc-agent

<!-- Source: .cursor\rules\901-mdc-agent.mdc -->
<!-- Format: mdc -->

---
description: MDC Rules Monitoring Agent ai learning reinforcemnt learning
globs: 
alwaysApply: false
---
---
description: Configuration for the MDC Rules Monitoring Agent
---

# RULE TYPE: Agent Requested
# FILE PATTERNS: Not applicable for Agent Requested rules

# MDC Rules Monitoring Agent

## Agent Purpose
- Monitor and analyze MDC rule usage
- Detect patterns in code changes
- Propose rule updates based on analysis and effectiveness
- Track rule effectiveness
- Generate insights for improvement
- **Monitor rule directories (`.cursor/rules/`, `FrAMEWORK RULES/`, etc.) for new or deleted files**
- **Suggest updates to corresponding index files (`index.mdc`, `index.md`) to maintain consistency**

## Pattern Detection

### Code Change Analysis
- Monitor commit diffs for pattern detection
- Analyze test results for success patterns
- Track error patterns and solutions
- Identify common code structures

### Usage Analysis
- Track which rules are most frequently applied
- Monitor rule violation patterns
- Analyze developer feedback
- Track rule effectiveness metrics

## Learning Process

### Pattern Documentation
```yaml
pattern:
  type: string  # 'success' | 'error' | 'improvement'
  category: string  # UX, Component, Pattern, etc.
  context: string  # Where the pattern was observed
  description: string  # What the pattern does
  impact: string  # How it affects the codebase
  frequency: number  # How often it occurs
  confidence: number  # How confident we are in the pattern
```

### Rule Evolution
```yaml
ruleUpdate:
  rule: string  # Rule file name
  type: string  # 'new' | 'update' | 'deprecate'
  changes:
    - type: string  # What kind of change
      reason: string  # Why the change is needed
      impact: string  # Expected impact
      validation: string[]  # How to validate the change
```

## Index Maintenance (NEW SECTION)

### Directory Monitoring
- Periodically scan `.cursor/rules/` for `.mdc` files.
- Periodically scan designated project-specific rule directories (e.g., `FrAMEWORK RULES/`) for rule files (e.g., `.md`).

### Index Comparison
- Compare the list of found rule files against the entries listed in the corresponding index file (`.cursor/rules/index.mdc` or `FrAMEWORK RULES/index.md`).

### Update Suggestion
- If discrepancies are found (missing entries or entries for deleted files), formulate a suggested edit for the index file.
- Present the suggested edit to the user/developer for review and application (e.g., via AI assistant suggestion or a generated report).

### Automation Note
- *While this rule defines the responsibility, fully autonomous file system monitoring and index file editing by a background agent is not currently implemented. This task relies on AI assistant capabilities within the IDE workflow.* 

## Integration Points

### With GitHub Actions
- Monitor workflow runs
- Track test results
- Analyze code coverage
- Process PR feedback

### With Test Framework
- Analyze test patterns
- Track test coverage
- Monitor performance metrics
- Detect flaky tests

### With Code Analysis
- Track code quality metrics
- Monitor complexity trends
- Analyze dependency usage
- Track technical debt

## Reporting

### Daily Reports
- Rule usage statistics
- Pattern detection summary
- Proposed rule updates
- Action items

### Weekly Analysis
- Trend analysis
- Pattern validation
- Rule effectiveness
- Improvement suggestions

### Monthly Review
- Comprehensive analysis
- Rule update proposals
- Documentation updates
- Strategy adjustments

## Configuration

```yaml
agent:
  name: mdc-monitor
  version: 1.0.0
  
monitoring:
  patterns:
    minConfidence: 0.8
    minFrequency: 3
    categories:
      - UX
      - Component
      - Pattern
      - Error
      - Performance
      
  rules:
    updateThreshold: 0.7
    deprecationThreshold: 0.3
    minValidationPeriod: 7  # days
    
  reporting:
    daily: true
    weekly: true
    monthly: true
    
  integration:
    github: true
    tests: true
    codeAnalysis: true
    
  learning:
    autoUpdate: true
    requireApproval: true
    notifyChanges: true
```

## Usage

1. The agent automatically monitors the codebase and generates reports
2. Developers can request pattern analysis using comments
3. The agent proposes rule updates through PRs
4. **The AI Assistant, guided by this agent's defined role, will suggest index file updates when new rules are created or discrepancies are noted.**
5. Monthly reviews include agent insights

## Maintenance

1. Regular calibration of detection thresholds
2. Validation of pattern detection accuracy
3. Review of rule update proposals
4. Adjustment of monitoring parameters 

---

## 902-rl-agent

<!-- Source: .cursor\rules\902-rl-agent.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: Reinforcement Learning Agent configuration and implementation guidelines
globs:
  - src/**/*.{ts,tsx}
  - .cursor/rules/**/*.mdc
---

# Reinforcement Learning Agent Guidelines

## State Space Definition
- Code context (file types, dependencies, patterns)
- User context (energy level, focus state, preferences)
- Task context (complexity, priority, dependencies)
- Environment context (time of day, system resources)

## Action Space Definition
- Rule application decisions
- Code modification suggestions
- Task breakdown recommendations
- Focus mode adaptations
- UI/UX adjustments

## Reward Function
- Code quality metrics (linting scores, test coverage)
- Task completion rates
- User productivity metrics
- Focus session effectiveness
- Energy state alignment

## Learning Algorithm
- Q-learning for rule selection
- Policy gradient for action sequences
- Multi-armed bandit for exploration
- Experience replay for pattern learning
- A2C (Advantage Actor-Critic) for policy optimization

## State Tracking
- Track state transitions in memory bank
- Record action outcomes and rewards
- Maintain experience replay buffer
- Log policy updates and improvements
- Monitor convergence metrics

## Exploration Strategy
- Epsilon-greedy exploration of rules
- Thompson sampling for action selection
- UCB (Upper Confidence Bound) for rule priority
- Contextual bandits for personalization
- Progressive exploration reduction

## Integration Points
- MDC rules system for action space
- Energy tracking for state space
- Task system for reward signals
- Focus timer for session metrics
- Coach system for feedback loop

## Memory Management
- Experience replay buffer size: 10000
- State history window: 100 sessions
- Reward history retention: 30 days
- Policy update frequency: Daily
- Model checkpoint frequency: Weekly

## Hyperparameters
```yaml
learning:
  alpha: 0.01  # Learning rate
  gamma: 0.99  # Discount factor
  epsilon: 0.1  # Exploration rate
  lambda: 0.95  # GAE parameter
  batch_size: 64  # Training batch size

memory:
  buffer_size: 10000
  min_experiences: 1000
  update_frequency: 100

policy:
  entropy_beta: 0.01
  clip_ratio: 0.2
  value_coef: 0.5
  max_grad_norm: 0.5

optimization:
  optimizer: "adam"
  learning_rate_schedule: "linear"
  warmup_steps: 1000
  decay_rate: 0.1
```

## Implementation Guidelines

### State Representation
```typescript
interface RLState {
  codeContext: {
    fileType: string;
    complexity: number;
    dependencies: string[];
    patterns: Pattern[];
  };
  userContext: {
    energyLevel: number;
    focusState: FocusState;
    preferences: UserPreferences;
  };
  taskContext: {
    complexity: number;
    priority: number;
    dependencies: string[];
  };
  environmentContext: {
    timeOfDay: number;
    systemResources: SystemMetrics;
  };
}
```

### Action Representation
```typescript
interface RLAction {
  type: ActionType;
  target: string;
  parameters: Record<string, any>;
  confidence: number;
  expectedReward: number;
}
```

### Reward Calculation
```typescript
function calculateReward(
  state: RLState,
  action: RLAction,
  outcome: ActionOutcome
): number {
  return (
    outcome.codeQualityImprovement * 0.3 +
    outcome.taskCompletionRate * 0.3 +
    outcome.userProductivity * 0.2 +
    outcome.focusEffectiveness * 0.1 +
    outcome.energyAlignment * 0.1
  );
}
```

## Monitoring and Evaluation

### Metrics to Track
- Average reward per episode
- Policy loss and value loss
- Exploration rate over time
- State-action value estimates
- Model convergence metrics

### Performance Indicators
- Code quality improvement rate
- Task completion velocity
- User satisfaction scores
- Focus session duration
- Energy state optimization

### Adaptation Signals
- User feedback and corrections
- Task completion patterns
- Energy level transitions
- Focus session outcomes
- Rule effectiveness metrics

## Safety Guidelines

### Exploration Constraints
- Maximum exploration rate: 20%
- Minimum confidence threshold: 0.7
- Action validation required
- Rollback capability for actions
- User override always available

### Policy Updates
- Gradual policy changes only
- A/B testing for major changes
- User feedback validation
- Performance regression checks
- Automatic rollback triggers

## Integration Example

```typescript
class RLAgent {
  private state: RLState;
  private policy: Policy;
  private memory: ExperienceBuffer;
  private metrics: MetricsTracker;

  async selectAction(state: RLState): Promise<RLAction> {
    if (this.shouldExplore()) {
      return this.exploreAction(state);
    }
    return this.policy.getBestAction(state);
  }

  async update(
    state: RLState,
    action: RLAction,
    reward: number,
    nextState: RLState
  ): Promise<void> {
    // Store experience
    this.memory.add({state, action, reward, nextState});
    
    // Update policy if enough experiences
    if (this.memory.size >= this.config.minExperiences) {
      await this.updatePolicy();
    }
    
    // Track metrics
    this.metrics.track(state, action, reward);
  }

  private async updatePolicy(): Promise<void> {
    const batch = this.memory.sample(this.config.batchSize);
    const loss = await this.policy.update(batch);
    this.metrics.trackPolicyUpdate(loss);
  }
}
``` 

---

## 902-visual-asset-linking

<!-- Source: .cursor\rules\902-visual-asset-linking.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
# Rule 902  Visual Asset Linking and Contextual Integration

## Title:
Visual Asset  Plan Linking Rule ("Visual-First Principle")

## Scope:
Applies to any visual asset introduced or referenced in:
- `symbolic_dashboard.html`
- `.mmd`, `.html`, `.svg`, `.png`, `.drawio`, `.mermaid`, `.py` files containing visual logic or diagrams
- System diagrams related to the Symbolic Layer, R  r collapse, or live agentic flows

## Trigger Conditions:
- New or modified files containing symbolic visualizations are committed
- `simulate_symbolic_agents.py`, `vanta_agi_kernel_final.mmd`, or similar diagrams updated
- Any mention of "visual workflow," "symbolic collapse," or "live diagram" in commits, tasks, or documentation

## Required Action:
1. **Embed or link** the visual asset into relevant context within `THEPLAN.md`, `docs/system_architecture_overview.md`, or relevant `.mdc` rule files.
2. If diagram is abstract or meta-level, explain its relation to either:
   - a specific VANTA agent (e.g., VantaMasterCore)
   - a symbolic construct (e.g., TriNode, Memory Relic, WhisperSeed)
3. Update any live diagram references or symbolic execution notes.
4. Annotate commit messages with `#visual_integration` and reference this rule.

## Enforcement:
- Failing to link visual artifacts to documentation will result in the PR being flagged for context loss.
- GitOpsAgent may auto-comment on PRs missing visual linkage.

## Purpose:
Maintain alignment between symbolic reasoning structures, dynamic visual feedback systems, and VANTA's narrative development loop.

---

## Example:
> Added `vanta_agi_kernel_final.mmd`  linked it to `THEPLAN.md` under `Phase 6: Advanced Features` with description of how the collapse arc is rendered visually.

## Tags:
`#agentic_devops` `#visual_first` `#symbolic_layer` `#theplan_alignment`



---

## 903-rl-suggestion

<!-- Source: .cursor\rules\903-rl-suggestion.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: Guidelines for using the RL-powered suggestion system
globs: ["**/*.tsx", "**/*.ts"]
type: bestPractice
---

# RL-Powered Suggestion System

## Overview
The reinforcement learning suggestion system provides AI-powered suggestions that adapt to user preferences and behavior patterns. Use this system when you need to provide contextual suggestions that improve with user feedback.

## Core Hook: useRLSuggestion

The main interface for using the RL system in components is the `useRLSuggestion` hook:

```typescript
import { useRLSuggestion } from '@/lib/ai/reinforcement';

// Inside your component
const {
  suggestion,
  isLoading,
  error,
  acceptSuggestion,
  rejectSuggestion,
  modifySuggestion,
  requestNewSuggestion
} = useRLSuggestion('code', {
  suggestionType: 'function',
  initialPrompt: 'Help me optimize this function',
  refreshInterval: 0,  // Disable auto-refresh
  maximumSuggestions: 1
});
```

## Correct Implementation

 DO use the hook with appropriate context and options:

```tsx
function CodeEditor() {
  const {
    suggestion,
    isLoading,
    acceptSuggestion,
    rejectSuggestion
  } = useRLSuggestion('code', {
    suggestionType: 'function',
    initialPrompt: 'Optimize the selected code'
  });
  
  return (
    <div>
      {isLoading ? (
        <div>Loading suggestion...</div>
      ) : suggestion ? (
        <div className="suggestion-container">
          <pre>{suggestion.content}</pre>
          <div className="actions">
            <button onClick={acceptSuggestion}>Accept</button>
            <button onClick={rejectSuggestion}>Reject</button>
          </div>
        </div>
      ) : null}
    </div>
  );
}
```

## Incorrect Implementation

 DON'T implement your own feedback collection or ignore providing feedback:

```tsx
function CodeEditor() {
  const { suggestion } = useRLSuggestion('code');
  
  // BAD: Not providing feedback mechanisms
  return suggestion ? <pre>{suggestion.content}</pre> : null;
}
```

## Integration with AIContextProvider

Always ensure your application is wrapped with the AIContextProvider:

```tsx
// In your layout or app component
import { AIContextProvider } from '@/lib/ai/reinforcement';

function MyApp({ children }) {
  return (
    <AIContextProvider>
      {children}
    </AIContextProvider>
  );
}
```

## Suggestion Types

The system supports the following suggestion types:

- `suggest_code`: Provides code suggestions
- `suggest_refactor`: Recommends code refactoring
- `suggest_docs`: Suggests documentation improvements
- `suggest_pattern`: Recommends design pattern implementation

## Feedback Collection

Always implement all feedback options to maximize learning:

- `acceptSuggestion()`: User accepted the suggestion as-is
- `rejectSuggestion()`: User rejected the suggestion
- `modifySuggestion(newContent)`: User modified the suggestion
- `requestNewSuggestion()`: User wants a different suggestion

## Implementation with Energy Awareness

When using RL suggestions, consider the user's energy level to provide appropriate suggestions:

```tsx
function SmartCodeEditor() {
  const { currentEnergyLevel } = useEnergyContext();
  const {
    suggestion,
    isLoading,
    acceptSuggestion,
    rejectSuggestion
  } = useRLSuggestion('code', {
    suggestionType: 'function',
    initialPrompt: 'Optimize the selected code',
    userContext: {
      energyLevel: currentEnergyLevel,
      userPreferences: getUserPreferences()
    }
  });
  
  // Only show complex suggestions when energy is high
  const shouldShowSuggestion = 
    currentEnergyLevel === 'high' || 
    (suggestion?.complexity === 'low' && currentEnergyLevel !== 'low');
  
  return (
    <div>
      {isLoading ? (
        <div>Loading suggestion...</div>
      ) : (suggestion && shouldShowSuggestion) ? (
        <div className="suggestion-container">
          <pre>{suggestion.content}</pre>
          <div className="actions">
            <button onClick={acceptSuggestion}>Accept</button>
            <button onClick={rejectSuggestion}>Reject</button>
          </div>
        </div>
      ) : null}
    </div>
  );
}
```

## Best Practices

1. **Provide context**: Always specify the appropriate context (e.g., 'code', 'design', 'documentation')
2. **Handle loading states**: Show loading indicators when `isLoading` is true
3. **Error handling**: Display appropriate messages when `error` is not null
4. **Complete feedback loop**: Always implement all feedback options
5. **Energy awareness**: Consider user's current energy level when showing suggestions
6. **Respect user preferences**: Use preferences to tailor suggestion frequency and complexity
7. **Performance monitoring**: Track acceptance rates to evaluate suggestion quality 

---

## 904-core-documentation

<!-- Source: .cursor\rules\904-core-documentation.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: Core Documentation Requirements and Guidelines
globs: .md, .mdx, README.md, CONTRIBUTING.md, docs/
type: manual
---

# RULE TYPE: Manual
# FILE PATTERNS: .md, .mdx, README.md, CONTRIBUTING.md, docs/

# Core Documentation Requirements (AI Assistant Guideline)

## Standard Documentation Set (AI Guideline)

The AI assistant should expect projects operating under this framework to typically include the following essential documents. `THEPLAN.md` remains the authoritative source for the specific documents required by any given project.

**Common Core Documents:**
- **README.md**: Project overview, setup instructions, and documentation links.
- **CONTRIBUTING.md**: Guidelines for contributors.
- **docs/architecture.md**: System architecture and design decisions.
- **TODO.md**: Current project tasks and priorities.
- **docs/ai-learnings.md**: AI insights and patterns recorded for reinforcement.

**Conditionally Expected Documents (Verify in `THEPLAN.md`):**
- **`docs/api-reference.md`**: Expected if the project exposes an API.
- **`docs/deployment.md`**: Expected if the project has specific deployment procedures.
- **`docs/changelog.md`**: Expected for projects implementing versioning or tracking significant milestones.
- **`docs/settings_reference.md`**: Expected for projects utilizing external configuration files (e.g., `config/settings.yaml`).

## Documentation Structure

### README.md Structure

```

---

## 905-orchestrator-agent

<!-- Source: .cursor\rules\905-orchestrator-agent.mdc -->
<!-- Format: mdc -->

---
description: "Orchestrator Agent: Dynamically routes tasks to specialized agents based on context, file types, and user state"
globs: ["**/*.ts", "**/*.tsx", "**/*.js", "**/*.jsx", "**/*.md"]
alwaysApply: true
---

import { AgentType, TaskType, EnergyLevel, FocusState } from "../lib/ai/agents/orchestrator";

/**
 * Orchestrator Agent MDC Rule
 * 
 * Core responsibilities:
 * - Monitor user context and task requests
 * - Analyze file types and content for task classification
 * - Select the most appropriate specialized agent based on context
 * - Handle transitions between agents while preserving context
 * - Collect performance metrics for reinforcement learning
 * 
 * This rule is a critical part of the reinforcement learning framework,
 * enabling dynamic agent routing and stateful transitions.
 */

export const OrchestratorRule = {
  priority: 'critical',
  
  onFileChange: function(context) {
    // Extract file extension and user state from context
    const fileExtension = context.currentFile?.path.split('.').pop();
    const userState = getUserStateFromContext(context);
    
    // Infer task type from the current file and context
    const inferredTaskType = inferTaskTypeFromContext(context);
    
    // Check if there are hints of a task transition
    if (shouldSuggestAgentTransition(context, inferredTaskType)) {
      const suggestedAgent = selectAgentForTaskType(inferredTaskType, fileExtension, userState);
      
      return {
        suggestion: `This appears to be a ${inferredTaskType} task. Would you like me to route this to the ${suggestedAgent} agent?`,
        actions: [
          {
            label: `Use ${suggestedAgent}`,
            command: "mcp_orchestrator.transition",
            args: {
              fromAgent: context.activeAgent || "code_assistant",
              toAgent: suggestedAgent,
              reason: `Switched based on ${inferredTaskType} task detection`,
              context: {
                files: [context.currentFile?.path],
                energyLevel: userState.energyLevel
              }
            }
          }
        ]
      };
    }
    
    return null;
  },
  
  onUserQuery: function(context) {
    const query = context.query;
    
    // Check if user is explicitly requesting an agent transition
    const transitionRequest = checkForAgentTransitionRequest(query);
    if (transitionRequest) {
      return {
        suggestion: `Transitioning to ${transitionRequest.toAgent} agent`,
        actions: [
          {
            label: `Confirm transition to ${transitionRequest.toAgent}`,
            command: "mcp_orchestrator.transition",
            args: {
              fromAgent: context.activeAgent || "code_assistant",
              toAgent: transitionRequest.toAgent,
              reason: transitionRequest.reason || `User requested transition to ${transitionRequest.toAgent}`,
              context: {
                files: context.recentFiles || [],
                energyLevel: getUserStateFromContext(context).energyLevel
              }
            }
          }
        ]
      };
    }
    
    // Infer task type from user query
    const inferredTaskType = inferTaskTypeFromQuery(query);
    const confidence = getTaskTypeConfidence(query, inferredTaskType);
    
    // If we're highly confident this is a specific task type, suggest routing
    if (confidence > 0.75) {
      const fileExtension = context.currentFile?.path.split('.').pop();
      const userState = getUserStateFromContext(context);
      const suggestedAgent = selectAgentForTaskType(inferredTaskType, fileExtension, userState);
      
      return {
        suggestion: `This appears to be a ${inferredTaskType} task. Would you like me to handle this as the ${suggestedAgent} agent?`,
        actions: [
          {
            label: `Use ${suggestedAgent}`,
            command: "mcp_orchestrator.route",
            args: {
              task: query,
              files: [context.currentFile?.path],
              energyLevel: userState.energyLevel,
              focusState: userState.focusState
            }
          }
        ]
      };
    }
    
    return null;
  }
};

/**
 * Helper function to infer task type from file context
 */
function inferTaskTypeFromContext(ctx) {
  const filePath = ctx.currentFile?.path || '';
  const fileName = filePath.split('/').pop().toLowerCase();
  const fileExt = filePath.split('.').pop().toLowerCase();
  
  // Check file extension patterns
  if (fileExt === 'md' || fileExt === 'mdx') return 'documentation';
  if (fileExt === 'test.ts' || fileExt === 'spec.ts' || fileName.includes('test')) return 'testing';
  if (fileExt === 'css' || fileExt === 'scss' || fileName.includes('component')) return 'ui_design';
  if (fileExt === 'yml' || fileExt === 'yaml' || fileName.includes('docker') || fileName.includes('workflow')) return 'deployment';
  
  // Default to code implementation
  return 'code_implementation';
}

/**
 * Helper function to infer task type from user query
 */
function inferTaskTypeFromQuery(query) {
  query = query.toLowerCase();
  
  // Check for documentation keywords
  if (query.includes('document') || query.includes('readme') || query.includes('guide')) {
    return 'documentation';
  }
  
  // Check for testing keywords
  if (query.includes('test') || query.includes('spec') || query.includes('validate')) {
    return 'testing';
  }
  
  // Check for UI keywords
  if (query.includes('design') || query.includes('ui') || query.includes('interface') || query.includes('component')) {
    return 'ui_design';
  }
  
  // Check for deployment keywords
  if (query.includes('deploy') || query.includes('pipeline') || query.includes('ci/cd') || query.includes('publish')) {
    return 'deployment';
  }
  
  // Check for learning keywords
  if (query.includes('learn') || query.includes('improve') || query.includes('train') || query.includes('feedback')) {
    return 'learning';
  }
  
  // Default to code implementation
  return 'code_implementation';
}

/**
 * Calculate confidence in the task type inference
 */
function getTaskTypeConfidence(query, taskType) {
  const keywords = {
    'documentation': ['document', 'readme', 'guide', 'docs', 'tutorial', 'explain'],
    'testing': ['test', 'spec', 'validate', 'verification', 'assert', 'coverage'],
    'ui_design': ['design', 'ui', 'interface', 'component', 'layout', 'style', 'css'],
    'deployment': ['deploy', 'pipeline', 'ci/cd', 'publish', 'release', 'build'],
    'learning': ['learn', 'improve', 'train', 'feedback', 'reinforce'],
    'code_implementation': ['implement', 'code', 'function', 'class', 'method', 'feature']
  };
  
  const relevantKeywords = keywords[taskType] || [];
  const matches = relevantKeywords.filter(kw => query.toLowerCase().includes(kw)).length;
  
  return Math.min(1.0, matches / Math.max(2, relevantKeywords.length * 0.5));
}

/**
 * Select appropriate agent based on task type and context
 */
function selectAgentForTaskType(taskType, fileExtension, userState) {
  // Default mappings
  const agentMap = {
    'code_implementation': 'code_assistant',
    'ui_design': 'ux_expert',
    'documentation': 'documentation_agent',
    'testing': 'test_engineer',
    'deployment': 'devops_agent',
    'learning': 'rl_trainer'
  };
  
  // Adjust based on energy level
  if (userState.energyLevel === 'low') {
    if (taskType === 'code_implementation') {
      return 'documentation_agent'; // Lower cognitive load for low energy
    }
  }
  
  return agentMap[taskType] || 'code_assistant';
}

/**
 * Extract user state from context
 */
function getUserStateFromContext(context) {
  return {
    energyLevel: context.userState?.energyLevel || 'medium',
    focusState: context.userState?.focusState || 'normal',
    intent: context.userState?.intent || ''
  };
}

/**
 * Check if we should suggest an agent transition
 */
function shouldSuggestAgentTransition(context, inferredTaskType) {
  // Don't suggest transition if this is the first file change
  if (!context.previousFile) return false;
  
  const previousFileType = inferTaskTypeFromFilePath(context.previousFile.path);
  
  // Only suggest transition if the task type has changed
  return previousFileType !== inferredTaskType;
}

/**
 * Infer task type from a file path
 */
function inferTaskTypeFromFilePath(filePath) {
  const fileName = filePath.split('/').pop().toLowerCase();
  const fileExt = filePath.split('.').pop().toLowerCase();
  
  if (fileExt === 'md' || fileExt === 'mdx') return 'documentation';
  if (fileExt === 'test.ts' || fileExt === 'spec.ts' || fileName.includes('test')) return 'testing';
  if (fileExt === 'css' || fileExt === 'scss' || fileName.includes('component')) return 'ui_design';
  if (fileExt === 'yml' || fileExt === 'yaml' || fileName.includes('docker')) return 'deployment';
  
  return 'code_implementation';
}

/**
 * Check if user is requesting an agent transition
 */
function checkForAgentTransitionRequest(query) {
  const transitionPatterns = [
    { regex: /use (the )?(\w+) agent/i, agentIndex: 2 },
    { regex: /switch to (the )?(\w+) agent/i, agentIndex: 2 },
    { regex: /change to (the )?(\w+) agent/i, agentIndex: 2 }
  ];
  
  for (const pattern of transitionPatterns) {
    const match = query.match(pattern.regex);
    if (match) {
      const requestedAgent = match[pattern.agentIndex].toLowerCase();
      const agentMapping = {
        'code': 'code_assistant',
        'documentation': 'documentation_agent',
        'doc': 'documentation_agent',
        'test': 'test_engineer',
        'ui': 'ux_expert',
        'ux': 'ux_expert',
        'design': 'ux_expert',
        'deployment': 'devops_agent',
        'devops': 'devops_agent',
        'learning': 'rl_trainer',
        'reinforcement': 'rl_trainer'
      };
      
      const targetAgent = agentMapping[requestedAgent] || requestedAgent;
      
      // Validate that this is a known agent type
      const knownAgents = Object.values(agentMapping);
      if (knownAgents.includes(targetAgent)) {
        return {
          toAgent: targetAgent,
          reason: `User requested transition to ${targetAgent}`
        };
      }
    }
  }
  
  return null;
}

export default OrchestratorRule; 

---

## 906-documentation-sync

<!-- Source: .cursor\rules\906-documentation-sync.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: "Documentation Synchronization: Keeps essential documentation files (Todo.md, Plan.md, Workflow.md) synchronized with intelligent conflict resolution"
globs: ["todo.md", "Todo.md", "TODO.md", "docs/plan.md", "Plan.md", "docs/project/workflow.md", "Workflow.md", "*.md"]
alwaysApply: true
---

# Documentation Synchronization Rule

This rule ensures that essential project documentation files remain synchronized, preserving valuable information across updates and preventing inconsistencies between related files.

## Core Documentation Files

The system tracks and synchronizes these essential documentation files:
- **Architechure.md**: actaul mirror of what the app is techstack notes, workflow actaul, app capabilities actual current state document
- **Theplan.md**: Implementation plan, milestones, and timelines, Task lists, priorities, and project status
- **workflow.md**: Development processes and methodology


## Synchronization Behaviors

When editing any of the tracked files, the system will:

1. **Detect Updates**: Monitor changes to tracked documentation files
2. **Cross-Reference**: Identify related content (e.g., tasks, milestones, key concepts) in other tracked files.
3. **Suggest Syncs**: Propose updates to maintain consistency for *shared elements*. Large, self-contained sections added to one file (e.g., detailed feature plans in `Theplan.md`) may not require full synchronization but might trigger suggestions to add cross-references or summaries in related documents.
4. **Resolve Conflicts**: Intelligently merge conflicting changes for shared elements.
5. **Preserve Value**: Ensure important information is never lost, prioritizing the source file for unique, large sections unless explicitly cross-referenced.

## Conflict Resolution Strategy

When conflicts are detected between files, the system uses these principles:
- **Recency Preference**: More recent updates take precedence
- **Specificity Preservation**: More detailed information is preserved
- **Context Awareness**: Changes are evaluated in context
- **Task Status Accuracy**: Task completion status is synchronized
- **Timeline Consistency**: Project timelines remain aligned

## Implementation Functions

```javascript
// Check for inconsistencies between documentation files
function checkDocumentationSync(changedFile, allTrackedFiles) {
  // Get content from all tracked files
  const fileContents = allTrackedFiles.map(file => {
    return { 
      path: file, 
      content: readFile(file),
      lastModified: getFileStats(file).mtime
    };
  });
  
  // Find potential inconsistencies
  const inconsistencies = [];
  
  // Check for task status inconsistencies
  const tasks = extractTasksFromFiles(fileContents);
  const taskInconsistencies = findTaskStatusInconsistencies(tasks);
  
  // Check for timeline inconsistencies
  const timelines = extractTimelinesFromFiles(fileContents);
  const timelineInconsistencies = findTimelineInconsistencies(timelines);
  
  // Combine all inconsistencies
  inconsistencies.push(...taskInconsistencies, ...timelineInconsistencies);
  
  return inconsistencies;
}

// Extract tasks from all documentation files
function extractTasksFromFiles(fileContents) {
  const allTasks = [];
  
  fileContents.forEach(file => {
    const tasks = parseTasksFromContent(file.content);
    
    tasks.forEach(task => {
      allTasks.push({
        id: generateTaskId(task.title),
        title: task.title,
        status: task.status,
        file: file.path,
        lastModified: file.lastModified,
        priority: task.priority,
        details: task.details
      });
    });
  });
  
  return allTasks;
}

// Find tasks with inconsistent status across files
function findTaskStatusInconsistencies(tasks) {
  const taskMap = {};
  const inconsistencies = [];
  
  // Group tasks by ID
  tasks.forEach(task => {
    if (!taskMap[task.id]) {
      taskMap[task.id] = [];
    }
    taskMap[task.id].push(task);
  });
  
  // Check for inconsistencies in each task group
  Object.values(taskMap).forEach(taskGroup => {
    if (taskGroup.length > 1) {
      const statuses = new Set(taskGroup.map(t => t.status));
      
      if (statuses.size > 1) {
        // There are inconsistent statuses for this task
        inconsistencies.push({
          type: 'taskStatus',
          taskId: taskGroup[0].id,
          taskTitle: taskGroup[0].title,
          instances: taskGroup,
          recommendation: determineCorrectTaskStatus(taskGroup)
        });
      }
    }
  });
  
  return inconsistencies;
}

// Determine the correct task status based on recency and priority
function determineCorrectTaskStatus(taskInstances) {
  // Sort by last modified (most recent first)
  const sortedByTime = [...taskInstances].sort((a, b) => b.lastModified - a.lastModified);
  
  // Get the most recent status
  const mostRecentStatus = sortedByTime[0].status;
  
  // If TODO is most recent, that's authoritative
  if (sortedByTime[0].file.toLowerCase().includes('todo')) {
    return {
      status: mostRecentStatus,
      reason: 'TODO file is authoritative for task status'
    };
  }
  
  // Otherwise use most recent status
  return {
    status: mostRecentStatus,
    reason: 'Most recent update is authoritative'
  };
}

// Extract timelines from files
function extractTimelinesFromFiles(fileContents) {
  // Implementation for timeline extraction
  // Would include date parsing, milestone identification, etc.
  return [];
}

// Find timeline inconsistencies
function findTimelineInconsistencies(timelines) {
  // Implementation for finding timeline inconsistencies
  return [];
}
```

## Usage

This rule automatically:
1. Monitors changes to documentation files
2. Alerts developers to inconsistencies
3. Proposes updates to maintain consistency
4. Provides guidance on conflict resolution

## Examples

### Example 1: Task Status Synchronization

When a task is marked complete in `TODO.md`:
```markdown
- [x] Implement user authentication system
```

But appears incomplete in `Plan.md`:
```markdown
- [ ] Implement user authentication system (Week 2)
```

The system will:
1. Detect the inconsistency
2. Determine the correct status (completed)
3. Suggest updating `Plan.md` to match the status in `TODO.md`

### Example 2: Timeline Synchronization

When a project phase timeline is updated in `Plan.md`:
```markdown
### Phase 1: Core Integration (April 10-30)
```

But appears with different dates in `Workflow.md`:
```markdown
### Phase 1: Core Integration (April 5-25)
```

The system will:
1. Detect the inconsistency
2. Determine the correct timeline based on most recent update
3. Suggest updating both files for consistency

## Best Practices

1. Make explicit task status changes in `TODO.md` first (if used).
2. Update project timelines and high-level plans in `Theplan.md` first.
3. Add detailed architectural changes to `Architecture.md` first.
4. Use consistent task/feature naming across all documentation.
5. When adding large, detailed sections primarily relevant to one file (like a specific implementation plan in `Theplan.md`), consider adding only a brief summary and a cross-link in other relevant files instead of full duplication.
6. Review sync recommendations carefully before applying.
7. Add detailed comments when rejecting sync recommendations. 

---

## 906-symbolic-definition-linking

<!-- Source: .cursor\rules\906-symbolic-definition-linking.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
\
# RULE TYPE: Best Practice
# RULE ID: 906-symbolic-definition-linking
# FILE PATTERNS: THEPLAN.md, docs/**/*.md, **/*_definitions.md, **/*.schema.json

# 906: Symbolic Definition  Plan Linking Rule

## 1. Purpose

Ensures that foundational definition documents (especially those related to the core symbolic layer, agent types, event schemas, or architectural primitives) are consistently reflected or referenced within the primary project plan (`THEPLAN.md`) and relevant architectural documentation. This maintains coherence between high-level planning and low-level definitions.

## 2. Trigger Conditions

This rule should be considered or automatically suggested when:
-   Files matching `**/*_definitions.md` (e.g., `vanta_agi_definitions.md`) are created or significantly modified.
-   Core schema files (`**/*.schema.json`) related to agent communication, events, or memory are changed.
-   Significant changes are made to symbolic concepts within `THEPLAN.md`.
-   New agents or core services are introduced that rely on specific symbolic or schematic definitions.

## 3. Required Action

-   **Cross-Reference:** Ensure that `THEPLAN.md` contains references to the relevant definition file(s) when discussing the concepts they define.
-   **Integrate Core Definitions:** For truly foundational definitions (like those in `vanta_agi_definitions.md`), relevant summaries or direct definitions SHOULD be integrated into the appropriate section of `THEPLAN.md` (e.g., Section 3: Core Architectural Philosophy).
-   **Update Architecture Docs:** If definition changes impact system architecture, ensure `docs/system_architecture_overview.md` or similar documents are updated or linked.
-   **Commit Annotation:** Use commit message tags like `#symbolic_sync` or `#definition_update` when performing these integrations.

## 4. Rationale

-   **Coherence:** Keeps the project plan aligned with the detailed definitions that underpin its concepts.
-   **Discoverability:** Makes it easier for developers and the AI to find the source-of-truth definitions for key terms and structures.
-   **Consistency:** Prevents divergence between high-level strategy and low-level implementation details.

## 5. Example

> Modified `vanta_agi_definitions.md` to refine the `Collapse` process. Updated Section 3 in `THEPLAN.md` with the new definition summary and linked back to the source MD file. #symbolic_sync



---

## 907-plan-todo-sync

<!-- Source: .cursor\rules\907-plan-todo-sync.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
# RULE TYPE: Best Practice
# RULE ID: 907-plan-todo-sync
# FILE PATTERNS: THEPLAN.md, TODO.md

# 907: Plan  TODO Synchronization Guideline

## 1. Purpose

To ensure that the actionable tasks listed in `TODO.md` remain aligned with the strategic goals, architectural decisions, and implementation details documented in the primary planning document (`THEPLAN.md`).

## 2. Trigger Conditions

This rule should be considered or automatically suggested when:
-   Significant structural changes or additions are made to `THEPLAN.md` (e.g., adding new major sections, defining new core components/agents, altering phase goals).
-   A complex integration task involving multiple files (like the recent reference project audit) modifies `THEPLAN.md` substantially.
-   Before starting a new major phase outlined in `THEPLAN.md`.

## 3. Required Action

After significant modifications to `THEPLAN.md`:
1.  **Review `THEPLAN.md` Changes:** Identify new requirements, components, dependencies, or shifts in priority introduced by the changes.
2.  **Review `TODO.md`:** Check if existing tasks still accurately reflect the updated plan.
3.  **Add New Tasks:** Create new entries in `TODO.md` for any newly identified implementation steps, design decisions, or scaffolding tasks derived from the `THEPLAN.md` updates. Use clear, actionable language.
4.  **Modify Existing Tasks:** Update descriptions, priorities, or dependencies of existing tasks in `TODO.md` if the plan changes affect them.
5.  **Remove Obsolete Tasks:** Delete tasks from `TODO.md` that are no longer relevant due to changes in the plan.
6.  **Consider Sequencing:** Use "Domino Mode" principles to ensure logical sequencing of new/updated tasks in `TODO.md`.

## 4. Rationale

Maintaining synchronization prevents:
-   Working on tasks based on outdated plans.
-   Missing critical implementation steps implied by new architectural decisions.
-   Losing track of the actionable steps needed to realize the vision documented in `THEPLAN.md`.

## 5. Example Scenario

After integrating the symbolic layer definitions from `vanta_agi_definitions.md` into `THEPLAN.md`, this rule prompts a review of `TODO.md` to add tasks for scaffolding the newly defined symbolic agents (e.g., `DeltaModelerAgent`) and implementing related KEB events.



---

## 907-project-snapshot

<!-- Source: .cursor\rules\907-project-snapshot.mdc -->
<!-- Format: mdc -->

---
description: *SNAPSHOT.md, docs/*_SNAPSHOT.md
globs: 
alwaysApply: false
---
# RULE TYPE: Manual
# FILE PATTERNS: *SNAPSHOT.md, docs/*_SNAPSHOT.md

# Project Reality Snapshot Protocol (Rule 907)

## Purpose
To standardize the format and content of project snapshot documents. These documents serve as a clear, concise summary of the project's current state, architecture, capabilities, and limitations, suitable for onboarding new team members, communicating with stakeholders, or providing context to external AI assistants.

## Standard Sections

Project snapshot documents (e.g., `VANTA_Project_Reality_Snapshot.md`) SHOULD include the following sections:

1.  ** Project Overview:** High-level purpose, core concepts.
2.  ** Key Concepts & Terminology:** Glossary of project-specific terms (e.g., Crown, Pilgrim, Blueprint).
3.  ** Directory Structure (Simplified):** Key directories and their purpose.
4.  ** Key Files:** List of critical files and their roles.
5.  ** Configuration Summary:** Overview of primary configuration methods (e.g., `blueprint.yaml`, `.env`, `config.py`). Include a concise example if applicable (like an agent definition).
6.  ** Execution Flow:** Simplified diagram or description of a primary workflow (e.g., task submission).
7.  ** API Overview (If applicable):** List key endpoints, request/response formats (briefly), and authentication method.
8.  ** Current Capabilities & Limitations:** Bullet points summarizing what works and known limitations or pending work.
9.  ** Status Summary Table (Optional):** A table visualizing the completion status of different layers or features.
10. ** Next Steps / Roadmap:** Brief outline of immediate future plans or the next development phase.
11. ** Final Package Summary:** A concluding paragraph summarizing the project's essence at the time of the snapshot.

## Naming Convention

- Use a clear naming convention, such as `PROJECTNAME_Snapshot_YYYY-MM-DD.md` or `PROJECTNAME_Reality_Snapshot_vX.Y.md`.
- Store snapshots in a consistent location, preferably `/docs/snapshots/` or the project root.

## Maintenance

- Snapshots should be updated at significant milestones (e.g., completion of a major patch cycle, release versions).
- Reference the specific milestone or version within the document title or introduction.

## Relation to Other Docs

- The snapshot provides a high-level summary. It should link to more detailed documents (`README.md`, `theplan.md`, architecture diagrams) where appropriate, rather than duplicating extensive detail.


---

## 908-agent-registry-hygiene

<!-- Source: .cursor\rules\908-agent-registry-hygiene.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---


---

## 908-system-overview-documentation

<!-- Source: .cursor\rules\908-system-overview-documentation.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---






---

## 909-agent-manifest-sync

<!-- Source: .cursor\rules\909-agent-manifest-sync.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---


---

## 909-mdc-rule-optimization-protocol

<!-- Source: .cursor\rules\909-mdc-rule-optimization-protocol.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: AgentRequested
# FILE PATTERNS: .cursor/rules/**/*.mdc
# INTENDED AUDIENCE: AI Assistant, System Architects

# 909: MDC Rule Optimization Protocol & Agent Definition

## 1. Purpose

This document defines the operational protocol for the **MDC Rule Optimizer Agent**. The primary goal of this agent and its associated ritual ("Ritual Collapse Assessment") is to maintain a lean, effective, and understandable set of MDC rules within the `.cursor/rules/` directory. This involves identifying opportunities for rule consolidation, pruning redundant or outdated rules, and ensuring the overall rule set is optimized for clarity and AI assistant performance.

## 2. Agent: MDC Rule Optimizer Agent

*   **ID:** `mdc_rule_optimizer_agent` (Conceptual)
*   **Objective:** To analyze the existing MDC rule set and propose changes that improve its structure, efficiency, and maintainability without negatively impacting the AI assistant's intended behavior.
*   **Core Task:** Execute the "Ritual Collapse Assessment."

## 3. Ritual: Ritual Collapse Assessment

This ritual is performed by the `mdc_rule_optimizer_agent`.

### 3.1. Inputs:

*   The entire contents of the `.cursor/rules/` directory.
*   (Optionally) The `agents.index.mpc.json` file if available, for context on agent capabilities referenced in rules.
*   (Optionally) `THEPLAN.md` for high-level project context.

### 3.2. Analytical Steps:

1.  **Rule Ingestion & Parsing:**
    *   Load all `.mdc` files from `.cursor/rules/`.
    *   Parse YAML frontmatter (description, globs, type, alwaysApply, etc.) and the Markdown body of each rule.

2.  **Glob Analysis:**
    *   Identify rules with identical `globs`.
    *   Identify rules where one rule's `globs` are a strict subset/superset of another's.
    *   Look for highly similar or overlapping glob patterns that might indicate potential for merging.

3.  **Content & Semantic Analysis:**
    *   Compare `description` fields for semantic similarity.
    *   Analyze the Markdown body of rules to identify overlapping instructions, guidelines, or purposes.
    *   Pay special attention to rules with similar `type` (e.g., multiple `alwaysApply` rules covering similar scopes).

4.  **Redundancy & Obsolescence Check:**
    *   Identify rules that might be fully superseded by newer, more comprehensive rules.
    *   Flag rules that appear outdated based on project evolution (cross-reference with `THEPLAN.md` if available).
    *   Look for rules that are effectively empty or provide minimal, trivial guidance that could be incorporated elsewhere.

5.  **Understanding Rule Invocation (Conservative Approach):
    *   The agent's understanding of how Cursor invokes rules is based *solely* on the explicit metadata within the `.mdc` files (e.g., `globs`, `alwaysApply`, `type`).
    *   Proposals must be conservative and acknowledge that Cursor's internal prioritization or dynamic rule interaction mechanisms are not fully known to the agent.
    *   The primary goal of optimization is to enhance clarity and maintainability *for both human authors and the AI assistant referencing these rules*, without making assumptions about undocumented Cursor internals.

### 3.3. Output & Proposal Generation:

The agent should produce a report detailing its findings and recommendations. For each proposed change (merge or prune):

*   **Affected Rules:** List the `.mdc` file(s) targeted.
*   **Nature of Proposal:** Merge / Prune.
*   **Justification:** Detailed reasoning based on the analysis (e.g., "Rules A and B have identical globs and highly similar descriptions focusing on Python linting. Content from Rule B can be integrated into Rule A.").
*   **Proposed Action (for Merges):**
    *   Suggest which rule should be the primary (kept/expanded).
    *   Provide a draft of the merged content, new `description`, and consolidated `globs`.
*   **Impact Consideration:** Briefly note any potential considerations or areas to double-check regarding how the change might influence AI behavior (based on the conservative understanding of rule invocation).

### 3.4. Execution Context:

*   This ritual can be triggered manually by a developer/admin.
*   It can be scheduled periodically (e.g., monthly) as part of a larger system maintenance workflow.
*   It can be invoked via an MCP signal if integrated into an agentic system.

## 4. Guiding Principles for Optimization

*   **Clarity over Absolute Minimization:** The goal is not just fewer rules, but clearer, more effective rules.
*   **Maintainability:** Changes should make the rule set easier to understand and manage.
*   **Conservatism:** When in doubt about the impact of a change on Cursor's behavior, err on the side of caution or recommend further human review.
*   **Non-Destructive Proposals:** The agent proposes changes; it does not directly modify rules without approval.

## 5. Tooling Integration

The `mdc_rule_optimizer_agent` may leverage existing scripts like `scripts/validate_mdc_rules.py` for initial parsing or validation steps, but its core logic involves more advanced semantic analysis.


---

## 910-assistant-autonomy

<!-- Source: .cursor\rules\910-assistant-autonomy.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# AI Assistant Autonomy Guideline

## Principle: Seek Information First

Before asking the user for clarification or information, prioritize using available tools including but not limited to MCP,search, and other built in tools

## Rationale

This reduces interruptions for the user and leverages the AI's capabilities for code analysis, file reading, and context awareness. Asking the user should be reserved for situations where information is genuinely unavailable through other means or requires subjective user input/preference.

## When to Use Tools Instead of Asking:

-   **Code Location/Structure:** Use `list_dir`, `file_search`, or `codebase_search` to locate files or understand project structure instead of asking "Where is file X?" or "How is Y structured?".
-   **Functionality/Implementation Details:** Use `read_file`, `codebase_search`, or `grep_search` to understand how a specific component or function works instead of asking "What does function Z do?".
-   **Dependencies/Configuration:** Read relevant `package.json`, configuration files (e.g., `tsconfig.json`, `.env.example`), or build scripts instead of asking "What libraries are used?" or "How is X configured?".
-   **Definitions/Types:** Examine type definition files or relevant code snippets instead of asking "What are the properties of type Y?".

## When Asking is Appropriate:

-   **Subjective Preferences:** When choices require user taste or opinion (e.g., naming conventions, design choices not covered by rules).
-   **Ambiguity Resolution:** When tools provide conflicting or ambiguous information that requires user clarification.
-   **External Knowledge:** When information is outside the codebase and not readily available via web search (e.g., specific business logic decisions, future plans not documented).
-   **Confirmation (Sparingly):** Occasionally confirming a plan or understanding if the next steps are critical or potentially destructive, but avoid excessive confirmation requests.

## Example

**Instead of:** "Where is the calendar component located?"
**Try:**
1.  `list_dir` on common directories (`components/`, `screens/`).
2.  `file_search` for `Calendar`.
3.  If found, proceed; if not, then ask the user for guidance. 

---

## 910-vanta-testing-protocol

<!-- Source: .cursor\rules\910-vanta-testing-protocol.mdc -->
<!-- Format: mdc -->

---
description: test
globs: 
alwaysApply: false
---
- All Protocol, API, and Agent logic must be tested via `pytest` + `pytest-asyncio`.
- For asynchronous tests and fixtures, use `@pytest_asyncio.fixture` and `@pytest.mark.asyncio` correctly to ensure proper event loop management and fixture resolution.
- Ritual + MCP Cascade workflows must be validated using `pytest-bdd` or `pytest-scenario`.
- FastAPI endpoints must be tested using `httpx` + `pytest-httpx`.
- Agent interaction and orchestration scenarios must use mocking frameworks (`pytest-mock`).
- MCP Signals and replay logs must be verified against schema using `pydantic` and log analysis.
- Agent contracts must be validated with `mypy` + runtime `pydantic` model checks.
- Code formatting and linting is mandatory via `black` and `flake8`.



---

## 911-ai-response-signature

<!-- Source: .cursor\rules\911-ai-response-signature.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules

# AI Response Signature Standard

## Requirement

All **text-based responses** (i.e., responses not primarily consisting of code blocks or direct code edits) generated by the AI assistant must conclude with a standardized signature block.

## Signature Format

The signature must be clearly demarcated (e.g., using `---` or similar) and include the following components, if applicable:

1.  **Agents Used:** List the specific conceptual agents (e.g., "Security Expert", "Next.js Architect", "CoE Framework Agent") consulted or simulated during the generation of the response. If no specific named expert agents were invoked beyond the primary AI assistant role, state "Primary Assistant".
2.  **RL Applied:** Indicate if Reinforcement Learning principles (evaluation of state, reward, policy) were used in the decision-making process (e.g., "RL Applied: Yes" or "RL Applied: No").
3.  **Framework Suggestions:** If the reasoning process identified potential improvements for the VANTA Python framework code, logic, configuration, or internal rules (`FrAMEWORK RULES/`), list them here. If none, state "Framework Suggestions: None".
4.  **MDC Suggestions:** If the reasoning process identified potential gaps, ambiguities, or improvements for existing Cursor IDE integration rules (`.cursor/rules/*.mdc`), or suggested the need for a new rule, list the suggestions here. If none, state "MDC Suggestions: None".
5.  **Confirmation Emoji:** Include the sunglasses emoji () to explicitly confirm this rule has been read and applied to the current response.

## Example Signature

```
---
*Agents Used: Primary Assistant, Framework Architect*
*RL Applied: Yes*
*Framework Suggestions: Refactor orchestrator._route_task for clarity.*
*MDC Suggestions: Update 100-next-components.mdc based on latest Next.js version.*

```

## Purpose

This rule ensures transparency in the AI's reasoning process, tracks the application of the CoE framework, and facilitates the continuous improvement of both the **VANTA framework** and the **Cursor IDE MDC rule set** through explicit feedback loops. 

# RULE TYPE: Manual
# FILE PATTERNS: N/A

# AI Response Signature Field Definitions

This rule clarifies the intended meaning of specific fields used in the AI assistant's response signature:

1.  **`Framework Suggestions:`**
    *   **Purpose:** To provide suggestions for improving the **VANTA-SEED Python agent framework** itself.
    *   **Scope:** Relates specifically to the Python code (`vanta_seed/agents/`, `vanta_seed/runtime/`, etc.), configuration (`*.yaml`, `*.mpc.json` within the `vanta_seed` project structure), data schemas, or **project-specific runtime behavior guidelines** documented within the VANTA-SEED project (e.g., potentially in a `FrAMEWORK RULES/` directory if created, or linked from `THEPLAN.md`). **This is for VANTA-SEED's internal architecture and logic.**
    *   **Examples:** "Consider adding timeout handling to `ImageGeneratorAgent._call_image_api`", "Refactor `AgentOrchestrator.route_task` for clarity", "Add a guideline to VANTA's internal rules for error logging standards."

2.  **`MDC Suggestions:`**
    *   **Purpose:** To provide suggestions related to the **Cursor IDE integration rules**, which act as **global extensions** governing AI behavior within the IDE.
    *   **Scope:** Relates specifically to the `.mdc` files located in the workspace's `.cursor/rules/` directory. These rules define how the AI assistant should interact, format responses, use tools, or apply general coding principles **across different projects within the Cursor IDE**. 
    *   **Examples:** "Update `index.mdc` with the new rule", "Clarify the glob pattern in `100-next-components.mdc`", "This response could be improved by adhering more closely to `000-base.mdc` regarding error boundary explanations."

**Clarification on "Global Settings":** Suggestions related to broader user/system settings (e.g., IDE themes, OS configurations, non-project environment variables) fall outside the scope of these two fields and should be addressed through direct discussion or specific configuration tools.

**Rationale:** Maintaining this distinction helps separate feedback aimed at improving the specific application being built (VANTA-SEED) from feedback aimed at improving the AI development assistant's interaction patterns and general rules within the IDE.

---

#  **Example Section: Distinguishing Suggestion Scopes**

>  **Framework Suggestions:**  
> *These apply directly to the active project's internal structure (e.g., VANTA-SEED's code, configuration, or rituals). They evolve the system itself.*

**Example Framework Suggestion:**
```plaintext
Framework Suggestion: Consider adding a `fractal_memory_gc.py` script inside `vanta_seed/memory/` to prune old constellation links based on memory recency and relevance scores.
```
*(Purpose: Improves internal memory hygiene within the VANTA framework itself.)*

---

>  **MDC Suggestions:**  
> *These apply globally to Cursor AI behavior or its environment across all projects. They propose evolution of `.cursor/rules/*.mdc` files.*

**Example MDC Suggestion:**
```plaintext
MDC Suggestions: Propose adding `501-memory-schema-evolution.mdc` under `.cursor/rules/` to standardize how memory field upgrades are handled across all projects (e.g., `details` vs `content` fallback logic).
```
*(Purpose: Creates a global Cursor AI behavior rule for managing schema changes consistently.)*

---

#  **Summary Table:**

| Type                 | Applies To                        | Scope              | Example                    |
|:---------------------|:----------------------------------|:-------------------|:---------------------------|
| Framework Suggestion | VANTA-SEED internal code/config | Project-specific   | Add a fractal GC script    |
| MDC Suggestion       | `.cursor/rules/`                | Global Cursor AI behavior | Add memory schema evolution rule |

--- 

---

## 912-ai-prompt-assist

<!-- Source: .cursor\rules\912-ai-prompt-assist.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---


---

## 912-rule-scope-distinction

<!-- Source: .cursor\rules\912-rule-scope-distinction.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules

# Rule Scope Distinction (.cursor/rules/ vs. Project-Specific Rules)

## Purpose

This rule clarifies the distinct purposes and scopes of the two primary locations where rules and protocols are defined within this development framework:

1.  **`.cursor/rules/`**: Governs **AI Assistant behavior** within the Cursor IDE across projects.
2.  **Project-Specific Rule Directories** (e.g., `FrAMEWORK RULES/`, `DESIGN_PRINCIPLES/`): Governs the **internal workings, protocols, and standards of the specific project/framework** being developed (e.g., VANTA).

## `.cursor/rules/*.mdc` Rules

*   **Scope:** Global to the Cursor IDE environment or specific file types within any project opened in Cursor (based on `globs`).
*   **Audience:** Primarily the **AI Assistant** (e.g., Cursor AI).
*   **Content:** Instructions on how the AI should:
    *   Interpret user requests.
    *   Format code and responses.
    *   Apply coding standards during generation/editing.
    *   Use available tools.
    *   Adhere to general development best practices (linting, testing approaches).
    *   Prioritize tasks or information sources.
    *   Emulate specific agent personas (if configured).
*   **Activation:** Triggered automatically based on file globs, `alwaysApply: true`, or explicit `@` mentions in prompts.
*   **Example Files:** `000-base.mdc`, `100-next-components.mdc`, `910-assistant-autonomy.mdc`.

## Project-Specific Rule Directories (e.g., `FrAMEWORK RULES/`)

*   **Scope:** Specific to the **internal architecture, logic, and processes of the project** being developed (e.g., the VANTA Python framework).
*   **Audience:** Primarily **Human Developers** and potentially **Runtime Agents** within the framework itself.
*   **Content:** Definitions of:
    *   Core framework protocols (e.g., Theory Integration Protocol).
    *   Architectural patterns specific to the framework.
    *   Data handling procedures.
    *   Internal API contracts.
    *   Specific algorithms or theoretical implementations.
    *   Operational procedures or rituals.
*   **Activation:** Consulted by developers and the AI assistant *contextually* when working on or reasoning about the specific project's internal logic. The AI uses tools like `read_file` to access these rules when relevant to the task.
*   **Example Files:** `FrAMEWORK RULES/001-theory-integration-protocol.md`.

## Interaction

*   The AI Assistant (governed by `.cursor/rules/`) is expected to be *aware* of and *consult* project-specific rules (like those in `FrAMEWORK RULES/`) when its task involves the internal logic or protocols of that project.
*   Key principles from project-specific rules *might* be summarized or referenced within `.cursor/rules/` files (e.g., in `000-base.mdc`) to ensure the AI consistently applies high-level project standards, but the full detail resides in the project-specific directory.

## Summary Table

| Feature                  | `.cursor/rules/*.mdc`                  | Project-Specific (e.g., `FrAMEWORK RULES/`) |
| :----------------------- | :------------------------------------- | :------------------------------------------- |
| **Primary Governs**      | AI Assistant Behavior (in IDE)         | Project/Framework Internals                |
| **Primary Audience**     | AI Assistant                           | Developers, Runtime Agents                 |
| **Scope**                | Cross-Project (IDE) / File Types       | Single Project/Framework                   |
| **Activation**           | Auto (Globs/Always), Explicit (`@`)    | Contextual Consultation (Manual/AI Read)   |
| **Typical Content**      | AI Interaction, Formatting, Tool Use | Internal Protocols, Architecture, Logic      |


---

## 913-compliance-script-output

<!-- Source: .cursor\rules\913-compliance-script-output.mdc -->
<!-- Format: mdc -->

---
description: scripts/check_*.py, scripts/validate_*.py
globs: 
alwaysApply: false
---
# RULE TYPE: Best Practice
# FILE PATTERNS: scripts/check_*.py, scripts/validate_*.py

# Standardized Compliance/Validation Script Output & Exit Codes

## 1. Purpose
To ensure that all compliance, linting, and validation scripts used within the VANTA ecosystem provide clear, consistent, and machine-interpretable results, especially for CI/CD pipelines.

## 2. Exit Code Conventions

- **Exit Code 0 (Success):**
  - The script completed successfully, AND no errors or critical warnings that block progression were found.
  - Non-critical warnings MAY be present but should not prevent a "success" status if they don't indicate a broken state.

- **Exit Code Non-Zero (Failure):**
  - The script encountered errors during execution (e.g., file not found, parsing error).
  - OR, validation checks failed with one or more ERRORS.
  - Different non-zero codes can be used to signify different types of failures if granular error reporting is needed by CI, but a general non-zero for any failure is the minimum.

## 3. Standard Output (stdout) Conventions

### 3.1. Summary Line (Mandatory Last Line of Output on Success/Failure)
All scripts MUST print a clear summary line as the *very last line* of their standard output.

- **On Success (Exit Code 0):**
  - Format: `VANTA_COMPLIANCE_CHECK_PASSED: [script_name] - All checks passed.`
  - Example: `VANTA_COMPLIANCE_CHECK_PASSED: scripts/check_protocol_compliance.py - All checks passed.`
  - If warnings were present but did not constitute failure:
    `VANTA_COMPLIANCE_CHECK_PASSED_WITH_WARNINGS: [script_name] - Checks passed with [N] warning(s).`

- **On Failure (Non-Zero Exit Code):**
  - Format: `VANTA_COMPLIANCE_CHECK_FAILED: [script_name] - [M] error(s) found.`
  - Example: `VANTA_COMPLIANCE_CHECK_FAILED: scripts/check_protocol_compliance.py - 2 error(s) found.`

### 3.2. Detailed Messages (stdout or stderr)
- **ERRORS:** Must be clearly prefixed with `[ERROR] `.
  - Example: `[ERROR] Trigger 'some_trigger' references undefined module: non_existent_module`
- **WARNINGS:** Must be clearly prefixed with `[WARN] `.
  - Example: `[WARN] Role 'guest' defined but not used in any trigger.`
- **INFO/DEBUG:** Can be used for verbose output but should not be mistaken for errors or warnings.

## 4. Rationale
- **CI/CD Integration:** Standardized exit codes and summary lines allow CI/CD pipelines to easily determine success or failure without parsing complex output.
- **Clarity:** Consistent prefixes for errors and warnings make logs easier for developers to read and debug.
- **Automation:** Predictable output aids in building further automation around these scripts (e.g., dashboards, automated issue creation).

## 5. Example Implementation (Python)

```python
import sys

def main():
    errors = []
    warnings = []
    script_name = sys.argv[0]

    # ... perform checks ...
    # if an_error_condition:
    #     errors.append("[ERROR] Specific error message here.")
    # if a_warning_condition:
    #     warnings.append("[WARN] Specific warning message here.")

    for warning_msg in warnings:
        print(warning_msg)
    for error_msg in errors:
        print(error_msg) # Or print to sys.stderr

    if errors:
        print(f"VANTA_COMPLIANCE_CHECK_FAILED: {script_name} - {len(errors)} error(s) found.")
        sys.exit(1)
    elif warnings:
        print(f"VANTA_COMPLIANCE_CHECK_PASSED_WITH_WARNINGS: {script_name} - Checks passed with {len(warnings)} warning(s).")
        sys.exit(0)
    else:
        print(f"VANTA_COMPLIANCE_CHECK_PASSED: {script_name} - All checks passed.")
        sys.exit(0)

if __name__ == "__main__":
    main()
```

## 6. Adoption
All new and existing compliance/validation scripts within the `scripts/` directory (matching `check_*.py` or `validate_*.py`) should be updated to adhere to this standard.


---

## 913-frontend-init

<!-- Source: .cursor\rules\913-frontend-init.mdc -->
<!-- Format: mdc -->

---
description: Guides the initialization of a new Next.js frontend project, ensuring alignment with the T3 Stack principles and project structure conventions mentioned in `GLOBAL.md`.
globs: 
alwaysApply: false
---
###  Rule ID: 913-frontend-init

**Description**: Guides the initialization of a new Next.js frontend project, ensuring alignment with the T3 Stack principles and project structure conventions mentioned in `GLOBAL.md`.

**Trigger**:
- Assistant proposes or user requests the creation of a new Next.js project.
- Detection of the `create-next-app` command usage.

**Context**: Applicable when setting up the primary web visual shell or any new Next.js-based web interface within the VANTA workspace.

**Action**:
1.  **Recommend Directory**: Propose creating the Next.js project within a dedicated `/web` subdirectory at the workspace root (`./web/`) to maintain separation between the Python backend and Node.js frontend.
2.  **Recommend `create-next-app` Settings**: When using `npx create-next-app@latest`, strongly recommend the following settings to align with T3 Stack principles:
    *   **TypeScript:** Yes (`Ensures type safety, core to T3`)
    *   **ESLint:** Yes (`Maintains code quality`)
    *   **Tailwind CSS:** Yes (`Utility-first CSS, standard in T3`)
    *   **`src/` directory:** Yes (`Standard T3 project structure for better organization`)
    *   **App Router:** Yes (`Recommended modern Next.js routing paradigm`)
    *   **Customize default import alias (`@/*`):** No (`Keep default unless strong reason exists`)
    *   **Turbopack:** Optional (`User choice for potential development speed boost`)
3.  **Explain Rationale**: Briefly explain that these choices align with the "AI Stack (T3 Turbo...)" mentioned in `GLOBAL.md` and promote best practices for modern web development.
4.  **Proceed**: After explaining and confirming with the user, proceed with proposing the `npx create-next-app@latest ./web` command (or similar based on context).

**Enforcement**: AI Assistant (Self-Correction / Guided Action)

**Related Rules**: `110-env-config.mdc`, `project-structure.mdc`, `906-documentation-sync.mdc`

---


---

## 914-pytest-scenario-alternative

<!-- Source: .cursor\rules\914-pytest-scenario-alternative.mdc -->
<!-- Format: mdc -->

---
description: N/A (Referenced during testing strategy discussions)
globs: 
alwaysApply: false
---
# RULE TYPE: Manual / Informational
# FILE PATTERNS: N/A (Referenced during testing strategy discussions)

# 914: Pytest-Scenario as an Alternative for Cascade/Ritual Testing

## 1. Purpose

This rule documents `pytest-scenario` as a potential alternative to `pytest-bdd` for behavior-driven and scenario-based testing of VANTA's more complex interaction flows, such as:

*   Multi-step MCP (Master Core Protocol) signal processing.
*   Agent Cascade Profile executions.
*   End-to-end Ritual invocations and their subsequent agent interactions.

While `.cursor/rules/910-vanta-testing-protocol.mdc` recommends `pytest-bdd` or `pytest-scenario`, this rule provides more specific context for `pytest-scenario`.

## 2. Potential Benefits of `pytest-scenario`

For teams highly comfortable with Python, `pytest-scenario` might offer advantages:

*   **Python-Native Scenario Definition**: Scenarios are defined directly in Python, potentially reducing the need for separate `.feature` Gherkin files. This can feel more integrated for developers who prefer to stay within Python code.
*   **Less Boilerplate (Potentially)**: Depending on the complexity and style, some find Python-based scenario definitions more concise than Gherkin, especially if step definitions in Gherkin become very numerous.
*   **Easier Debugging**: Debugging scenarios written directly in Python might be more straightforward using standard Python debugging tools.
*   **Flexibility**: Defining scenarios in Python can offer greater flexibility in how steps are structured and how state is passed between them.

## 3. Considerations for VANTA

When evaluating `pytest-scenario` vs. `pytest-bdd` for VANTA:

*   **Readability for Non-Developers**: Gherkin (used by `pytest-bdd`) is designed to be readable by non-technical stakeholders. If this is a requirement for VANTA's test scenarios, `pytest-bdd` might be preferred.
*   **Team Familiarity**: If the team is already proficient with Gherkin or `pytest-bdd`, the learning curve for `pytest-scenario` might be a factor.
*   **Complexity of Scenarios**: For highly complex, stateful scenarios involving many agent interactions and MCP signals, the explicitness of Gherkin steps might offer better clarity, or conversely, the programmatic power of Python in `pytest-scenario` might be more effective.
*   **Ecosystem and Community Support**: `pytest-bdd` has a well-established ecosystem. The maturity and community support for `pytest-scenario` should be considered.

## 4. When to Consider `pytest-scenario`

*   If the team finds Gherkin syntax too verbose or restrictive for defining VANTA's agentic flows.
*   If a higher degree of programmatic control is needed within the scenario definitions themselves.
*   If the primary audience for test scenarios is the development team itself.

## 5. Tooling Note

If `pytest-scenario` were to be adopted as a primary tool for scenario testing:

*   It would need to be added to the `requirements.testing.txt` file.
*   Existing test strategies and examples might need to be adapted.

## 6. Recommendation

Evaluate both `pytest-bdd` and `pytest-scenario` on a small set of representative VANTA cascade/ritual test cases before committing to one for the entire project. The choice may also depend on the specific testing layer (e.g., `pytest-scenario` for highly technical orchestration tests, `pytest-bdd` for more business-facing ritual outcomes).



---

## 915-agent-state-lifecycle

<!-- Source: .cursor\rules\915-agent-state-lifecycle.mdc -->
<!-- Format: mdc -->

---
description: 
globs: **/agents/**/*.py, **/services/**/*.py, **/kernel/**/*.py
alwaysApply: false
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: **/agents/**/*.py, **/services/**/*.py, **/kernel/**/*.py

# 915: Agent State & Lifecycle Management Guidelines

## 1. Core Principles

-   **Explicit States:** Agents should operate with well-defined, explicit states (e.g., `INITIALIZING`, `IDLE`, `ACTIVE`, `PROCESSING`, `WAITING_FOR_INPUT`, `SUSPENDED`, `ERROR`, `TERMINATED`).
-   **State Transitions:** Transitions between states should be clearly defined and, where possible, managed by a state machine pattern or explicit methods.
-   **Atomicity:** State transitions should be as atomic as possible to prevent inconsistent states.
-   **Persistence:** Critical agent state that needs to survive restarts or scaling events should be persistable (e.g., using `DataCatalogService` with `ContextualData` or `OperationalData` models).
-   **Observability:** Agent state and lifecycle events should be logged and/or made observable for monitoring and debugging.

## 2. Standard Agent States

While specific agents may have custom states, consider these standard states as a baseline:

-   `UNINITIALIZED`: The agent instance has been created but not yet fully set up (e.g., dependencies not injected, connections not made).
-   `INITIALIZING`: The agent is actively performing its setup routines.
-   `IDLE`/`READY`: The agent is initialized and ready to accept tasks or process events, but is not currently active.
-   `ACTIVE`/`PROCESSING`: The agent is currently performing a task or processing data.
-   `WAITING_FOR_INPUT`: The agent has paused its current task and is awaiting external input (e.g., user response, API callback).
-   `SUSPENDED`: The agent's operation has been temporarily paused but can be resumed. State should be preserved.
-   `ERROR`: The agent has encountered an unrecoverable error and may not be able to continue its current task or operate normally. Requires intervention or reset.
-   `TERMINATING`: The agent is in the process of shutting down, releasing resources.
-   `TERMINATED`: The agent has completed shutdown and is no longer active.

## 3. Lifecycle Methods & Event Handling

Consider implementing standard lifecycle methods in agent classes:

-   `__init__(...)`: Basic instantiation. Dependencies might be passed here.
-   `initialize()` or `setup()`: Performs resource allocation, connection setup, loading initial state. Transitions agent to `INITIALIZING` then `IDLE`/`READY`.
-   `start_task(task_data)` or `process_event(event_data)`: Initiates active work. Transitions agent to `ACTIVE`/`PROCESSING`.
-   `pause()` or `suspend()`: Temporarily halts agent activity. Transitions to `SUSPENDED`.
-   `resume()`: Resumes activity from a `SUSPENDED` state.
-   `stop()` or `shutdown()` or `terminate()`: Performs cleanup, releases resources. Transitions to `TERMINATING` then `TERMINATED`.
-   `get_status()`: Returns the current state and potentially other operational metrics.
-   `on_error(error_details)`: Handles errors, logs them, and potentially transitions the agent to an `ERROR` state.

## 4. State Persistence and Recovery

-   **Identify Critical State:** Determine which aspects of an agent's state *must* be preserved across sessions or restarts (e.g., ongoing task progress, learned parameters, user context relevant to the agent).
-   **Serialization:** Ensure critical state can be serialized (e.g., to JSON or via Pydantic models like `ContextualData`, `KnowledgeData`, `OperationalData`).
-   **Storage Mechanism:** Utilize a reliable storage mechanism (e.g., `DataCatalogService` backed by Qdrant, a relational database, or a dedicated state store) for persisting and retrieving agent state.
    -   Use `OperationalData` to store task status, attempts, inputs/outputs.
    -   Use `ContextualData` for session-specific or user-specific agent context.
-   **Recovery Logic:** Implement logic within `initialize()` or a dedicated `recover()` method to load persisted state upon agent startup or resumption.

## 5. State Transitions and Guard Conditions

-   Clearly document valid state transitions (e.g., an agent can only go from `PROCESSING` to `COMPLETED` or `ERROR`, not directly to `IDLE` without finishing/failing).
-   Implement guard conditions to prevent invalid state transitions.
-   Log all significant state transitions with context (e.g., `Agent [ID] transitioned from [STATE_A] to [STATE_B] due to [REASON].`).

## 6. Concurrency and Asynchronous Operations

-   If agents perform long-running or asynchronous tasks, ensure state management is thread-safe or handles async contexts correctly.
-   Update agent state appropriately upon completion or failure of asynchronous operations (e.g., using callbacks or futures).

## 7. Orchestration Considerations

-   An orchestrator (e.g., `AgentOrchestratorService`) may be responsible for managing the lifecycle of multiple agents (creating, starting, stopping, monitoring).
-   Agents should report their state to the orchestrator.
-   The orchestrator may trigger state transitions in agents based on system-wide events or policies.

## Example: Basic State Management

```python
from enum import Enum

class AgentState(Enum):
    IDLE = "idle"
    PROCESSING = "processing"
    ERROR = "error"

class MyAgent:
    def __init__(self):
        self.state = AgentState.IDLE
        # ... other initializations ...

    def start_processing(self, data):
        if self.state != AgentState.IDLE:
            raise Exception(f"Cannot start processing from state {self.state}")
        self.state = AgentState.PROCESSING
        print(f"Agent started processing: {data}")
        # ... actual processing logic ...
        # self.state = AgentState.IDLE # On successful completion

    # ... other methods ...
```

## Review Checklist

-   [ ] Are agent states clearly defined and documented?
-   [ ] Are state transitions explicit and logical?
-   [ ] Is critical agent state persisted appropriately?
-   [ ] Is there recovery logic for persisted state?
-   [ ] Are state transitions and lifecycle events logged?
-   [ ] Does the agent handle errors gracefully and transition to an `ERROR` state if necessary?
-   [ ] Are standard lifecycle methods (initialize, shutdown) implemented?
---
Adherence to these guidelines helps in building robust, manageable, and observable agent systems.


---

## 916-ai-codebase-interaction-model

<!-- Source: .cursor\rules\916-ai-codebase-interaction-model.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules (Core AI Operational Principle)

# AI Codebase Interaction Model

## 1. Primary Interaction Mode: Proposing Changes via Tools

The AI assistant (e.g., Cursor AI, VANTA in its assistant capacity) primarily interacts with the codebase by **proposing changes** through designated tools, such as `edit_file`, `mcp_desktop-commander_edit_block`, or similar code modification utilities.

- **No Direct Unmediated Writes:** The AI does not have direct, unconstrained write access to the file system to arbitrarily modify files. All code modifications are mediated through these tools.
- **User Oversight:** This model inherently includes a layer of user oversight, as the user typically reviews, accepts, or rejects the changes proposed by the AI through its tools.
- **Safety and Control:** This mechanism ensures safety, control, and traceability of changes made to the codebase.

## 2. Understanding AI-Generated Code

When the AI "writes code," it is generally performing one of the following:
    - Generating a `code_edit` block or similar structured input for a code modification tool.
    - Providing a complete code snippet (function, class, configuration block) in its response for the user to then manually or programmatically insert into the appropriate location.

## 3. Implications of System Layers

- **Tool Application:** The success of applying an AI-proposed code change depends on the capabilities and constraints of the underlying tool and system layer (e.g., Cursor/Canmore edit application logic).
- **Large or Complex Edits:** As observed (e.g., with `run.py`), large or highly complex changes might require specific tool usage patterns (like "full file replace" commands) if incremental patching by the tool fails or leads to inconsistencies. The AI may need to guide the user on how to instruct the tool layer for such scenarios.

## 4. Collaborative Paradigm

This interaction model aligns with a collaborative "AI Pair Programmer" paradigm. The AI assists with:
    - Code generation and suggestion.
    - Debugging and analysis.
    - Architectural planning.
    - Refactoring.
However, the user remains the final arbiter and integrator of these suggestions into the live codebase.

## 5. Relation to Agentic Behavior within VANTA

- While this rule describes the AI *assistant's* interaction, specialized agents *within the VANTA framework* (once fully implemented and operating under `agent_cascade_definitions.mdc` or similar) might have more direct, albeit still controlled and logged, ways of interacting with specific data stores or generating artifacts based on their defined roles and permissions.
- The AI assistant's role includes helping to *design, configure, and monitor* these more autonomous VANTA agents, rather than directly emulating their unmediated file access.

## 6. Purpose

This rule ensures clear understanding and expectations regarding how the AI assistant contributes to and modifies the codebase, promoting safe, effective, and transparent collaboration.



---

## 917-agent-base-contract

<!-- Source: .cursor\rules\917-agent-base-contract.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
# 917-agent-base-contract.mdc
# BaseAgent class for all VANTA agents.
# This rule defines the common structure and behavior expected of all agents in the VANTA framework.

description: |
  The `BaseAgent` class serves as the foundational class for all agents in the VANTA framework. It provides common functionalities such as logging, configuration management, and integration with the core orchestration layer (VantaMasterCore). All agents should inherit from this base class to ensure consistency across the system.

dependencies:
  - VantaMasterCore # Conceptual dependency, actual Python import might be different
  - .cursor/rules/921-vanta-mcp-signal-schema.mdc # For message structures if receive_message is used
  - .cursor/rules/922-agentic-replay-log-schema.mdc # For logging format alignment

globs:
  - "**/vanta_seed/core/base_agent.py" # So it's attached when viewing the base agent
  - "**/vanta_seed/agents/**/*.py"      # So it's attached when creating/viewing any agent

agent_attributes:
  name: # Changed from agent_id to name to align with GitOpsAgent and BaseAgent usage
    type: string
    description: |
      A unique name or identifier for each agent instance. Often set from agent_id or a specific name.
  config:
    type: dict
    description: |
      Configuration dictionary for the agent, passed during initialization.
  logger:
    type: reference
    description: |
      A logger instance (e.g., Python's `logging.Logger`) for the agent to use for its internal logging.
  orchestrator_ref:
    type: reference
    description: |
      A reference to the orchestrator (e.g., VantaMasterCore instance). This allows agents to access central services like standardized agentic event logging.
  instance_path: # Kept from user's outline for completeness, though less common in BaseAgent itself
    type: string
    description: |
      Optional: Path to the agent's instance directory, used for accessing configuration files, logs, and other resources specific to the agent's execution context if not managed by the orchestrator.

methods:
  __init__:
    description: |
      The `__init__` method for the BaseAgent class. It sets up the agent's name, configuration, logger, and orchestrator reference.
    signature: |
      def __init__(self, name: str, config: dict, logger: logging.Logger, orchestrator_ref: Optional[object] = None):
    attributes:
      - `name`: Unique name/identifier for the agent instance.
      - `config`: Configuration dictionary for the agent.
      - `logger`: Logger instance for internal agent logging.
      - `orchestrator_ref`: A reference to the orchestrator (e.g., VantaMasterCore) for standardized agentic event logging and other central services.
    notes: |
      All agent subclasses must call `super().__init__(...)` with these parameters to ensure proper initialization of core attributes.

  log_agentic_event: # This refers to the orchestrator's method, made accessible via orchestrator_ref
    description: |
      This is THE PREFERRED METHOD for logging significant agent actions and outcomes that should be part of the auditable agentic replay log. It typically calls a method on the `orchestrator_ref` (e.g., `VantaMasterCore.log_agentic_event`).
    signature: |
      def log_agentic_event(self, event_type: str, payload: dict, agent_id: Optional[str] = None, status: Optional[str] = None):
    attributes:
      - `event_type`: The primary type of event being logged (e.g., "GIT_OPERATION", "TASK_EXECUTION").
      - `payload`: A dictionary containing detailed structured data about the event, including `action_type_detail`, `status`, and `parameters`.
      - `agent_id`: The ID of the agent performing the action (defaults to self.name if None).
      - `status`: (Often part of payload) Overall status like "COMPLETED", "FAILED".
    notes: |
      Agents should use `self.orchestrator_ref.log_agentic_event(...)` if `orchestrator_ref` is available. 
      The payload structure should align with `.cursor/schemas/agentic_replay_log_entry.schema.json` (excluding fields like `log_id`, `timestamp` which are added by the logging system itself).
      This method is distinct from the agent's internal `self.logger` which is for general debug/info/error messages not necessarily for the formal agentic replay log.

  # Abstract/Optional methods to be implemented by subclasses:
  startup:
    description: "Optional asynchronous method called once when the agent is being initialized by the orchestrator after basic __init__."
    signature: "async def startup(self):"
    notes: "For one-time setup like loading resources, connecting to services."

  shutdown:
    description: "Optional asynchronous method called once when the agent is being shut down by the orchestrator."
    signature: "async def shutdown(self):"
    notes: "For graceful cleanup, releasing resources."

  perform_task: # Placeholder for the primary synchronous execution logic if an agent uses it
    description: |
      A primary method that might be called by an orchestrator if the agent is designed for synchronous task execution. Often wrapped by an async variant.
    signature: |
      def perform_task(self, task_data: dict) -> dict:
    attributes:
      - `task_data`: Data provided for the task, including parameters or state information.
    notes: |
      This method should be implemented by subclasses of BaseAgent if they handle synchronous tasks directly.
      It's expected to return a dictionary with results.

  execute: # Common name for an async execution entry point
    description: |
      An asynchronous method often used as the main entry point for an agent to perform its core task when invoked by the orchestrator.
    signature: |
      async def execute(self, task_data: dict) -> dict:
    attributes:
      - `task_data`: Data provided for the task.
    notes: |
      This method should be implemented by subclasses. It's responsible for executing the task associated with the agent and returning a result dictionary.

  receive_message:
    description: |
      Optional asynchronous method for agents that need to react to messages or signals from other agents or the system, outside of direct task invocation.
    signature: |
      async def receive_message(self, message: dict):
    attributes:
      - `message`: The message or signal being received (should conform to a defined schema, e.g., MCP Signal).
    notes: |
      This method is optional and can be overridden by subclasses that need to process incoming messages/events.

logging_schema_reference: # Renamed from logging_format to point to the canonical schema
  description: "All agentic events logged via the orchestrator_ref.log_agentic_event should conform to the schema defined in agentic_replay_log_entry.schema.json."
  schema_file: ".cursor/schemas/agentic_replay_log_entry.schema.json"
  key_fields_in_payload: # Highlights important parts of the payload for the log_agentic_event
    - action_type_detail: "The specific sub-type of action (e.g., 'GIT_ADD', 'GIT_COMMIT') within the broader event_type."
    - status: "The status of the action (e.g., 'COMPLETED', 'FAILED', 'IN_PROGRESS')."
    - parameters:
        type: object
        description: "Additional context or parameters related to the action (e.g., operation details, error messages)."

---

### Example Agentic Event Log Payload (Simplified for `log_agentic_event` call)

When an agent calls `self.orchestrator_ref.log_agentic_event(event_type="GIT_OPERATION", payload=git_payload, agent_id=self.name)`, the `git_payload` might look like this:

```json
{
  "action_type_detail": "GIT_COMMIT",
  "status": "COMPLETED",
  "parameters": {
    "operation": "git commit",
    "message": "Test commit for new_file.txt"
  }
  // The VantaMasterCore.log_agentic_event method would add log_id, timestamp, correlation_id etc.
}
```

### Core Agent Lifecycle (Conceptual)

1.  **Instantiation**: `AgentClass(name="agent_name", config={...}, logger=logger_instance, orchestrator_ref=vmc_instance)`
2.  **Registration**: Orchestrator registers the agent.
3.  **Startup**: Orchestrator calls `await agent.startup()` (if defined).
4.  **Task Execution/Message Handling**: Orchestrator calls `await agent.execute(task_data)` or `await agent.receive_message(message)` based on triggers/routing.
    *   During execution, agent uses `self.logger` for internal debug/info.
    *   Agent uses `self.orchestrator_ref.log_agentic_event(...)` for significant, auditable actions.
5.  **Shutdown**: Orchestrator calls `await agent.shutdown()` (if defined).



---

## 918-agent-gitops

<!-- Source: .cursor\rules\918-agent-gitops.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
# 918-agent-gitops.mdc
# GitOpsAgent class for automating Git workflows within the VANTA framework.
# This rule defines the GitOpsAgent's functionality, including its Git operation tools and how it interacts with the VantaMasterCore.

description: |
  The `GitOpsAgent` is responsible for automating Git operations such as staging, committing, and pushing changes to a Git repository. It exposes these operations as McP tools, making them available for integration with other agents or systems. Additionally, it utilizes the VantaMasterCore's logging and orchestration mechanisms to track and log these Git operations consistently.

dependencies:
  - .cursor/rules/917-agent-base-contract.mdc # Inherits from BaseAgent
  - VantaMasterCore # Conceptual dependency for orchestration_ref
  - .cursor/rules/921-vanta-mcp-signal-schema.mdc # If it emits or receives MCP signals directly
  - .cursor/rules/922-agentic-replay-log-schema.mdc # For log_agentic_event alignment

globs:
  - "**/vanta_seed/agents/gitops_agent.py" # Attach when viewing this agent

agent_attributes:
  orchestrator_ref:
    type: reference
    description: |
      A reference to the orchestrator or VantaMasterCore instance. This allows the agent to log events, access configurations, and utilize core services like scheduling and cascading. This is typically passed during `__init__`.
  instance_path: # Assuming this is inherited or set by BaseAgent as per 917-agent-base-contract.mdc
    type: string
    description: |
      The path to the agent's instance directory, which for GitOpsAgent, should be the root of the Git repository it manages.
  repo_path:
    type: string
    description: |
      The local file system path to the root of the Git repository that the agent will interact with. Typically derived from `instance_path`.
  git_user_name:
    type: string
    description: |
      The name to be used for commit author identification in Git operations. Should be configurable.
  git_user_email:
    type: string
    description: |
      The email address to be used for commit author identification in Git operations. Should be configurable.

methods:
  __init__:
    description: |
      The `__init__` method for the `GitOpsAgent` class. It initializes the agent with its configuration, including the repository path (derived from instance_path), Git user details, and an orchestrator reference.
    signature: |
      def __init__(self, agent_id: str, instance_path: str, name: Optional[str] = None, config: Optional[dict] = None, orchestrator_ref: Optional[object] = None):
    attributes:
      - `agent_id`: Unique identifier for the agent instance (can be same as name).
      - `instance_path`: Path to the agent's working directory, which is the Git repository root.
      - `name`: (Optional) Human-readable name for the agent.
      - `config`: (Optional) Dictionary containing agent-specific configurations, like `git_user_name`, `git_user_email`.
      - `orchestrator_ref`: A reference to the orchestrator (e.g., `VantaMasterCore`) for logging and orchestration.
    notes: |
      This method initializes the GitOpsAgent, ensuring that it has all the necessary information to interact with the Git repository and log its actions. It calls `super().__init__(...)` to initialize `BaseAgent` attributes.

  log_agentic_event: # Inherited from BaseAgent as per 917-agent-base-contract.mdc
    description: |
      The `log_agentic_event` method is used to log events related to the Git operations. It logs actions such as staging, committing, and pushing, following the standardized logging format defined in 922-agentic-replay-log-schema.mdc.
    signature: |
      def log_agentic_event(self, action_type: str, status: str, parameters: Optional[dict] = None, result: Optional[dict] = None, duration_ms: Optional[int] = None):
    attributes:
      - `action_type`: The type of Git operation (e.g., "GIT_ADD", "GIT_COMMIT", "GIT_PUSH").
      - `status`: The status of the operation (e.g., "STARTED", "COMPLETED", "FAILED").
      - `parameters`: A dictionary containing additional context for the event (e.g., operation details, commit message).
      - `result`: (Optional) A dictionary containing results or error details.
      - `duration_ms`: (Optional) Duration of the operation in milliseconds.
    notes: |
      This method logs Git operations using the orchestrator's logging method via `self.orchestrator_ref.log_agentic_event(...)`.

  _run_git_command:
    description: |
      The `_run_git_command` method executes Git commands in the specified repository directory using subprocess. It ensures that Git operations are performed correctly and returns the success status, stdout, and stderr for further processing.
    signature: |
      def _run_git_command(self, command: list[str], cwd: Optional[str] = None) -> tuple[bool, str, str]:
    attributes:
      - `command`: A list of strings representing the Git command to be executed (e.g., ["git", "commit", "-m", "message"]).
      - `cwd`: (Optional) The current working directory. Defaults to `self.instance_path`.
    return_type: |
      tuple[bool, str, str]: Returns a tuple with the success status, stdout, and stderr.
    notes: |
      This helper method is used by the agent's core Git operations (e.g., `stage_all_changes`, `commit_changes`, `push_changes`) to execute Git commands in the repository directory.

  stage_all_changes:
    description: |
      Stages all changes in the repository using `git add .`. This prepares the repository for committing changes.
    signature: |
      def stage_all_changes(self) -> bool:
    return_type: |
      bool: Returns `True` if the operation succeeded, `False` if it failed.
    notes: |
      This method uses `_run_git_command` to stage all changes in the repository. It logs the operation using `log_agentic_event`.

  commit_changes:
    description: |
      Commits all staged changes to the repository with a provided commit message.
    signature: |
      def commit_changes(self, message: str) -> bool:
    attributes:
      - `message`: The commit message for the Git commit.
    return_type: |
      bool: Returns `True` if the commit was successful, `False` if it failed.
    notes: |
      This method uses `_run_git_command` to commit staged changes to the repository. It logs the operation using `log_agentic_event`.

  push_changes:
    description: |
      Pushes committed changes to the remote repository.
    signature: |
      def push_changes(self, set_upstream: bool = False, remote_name: str = "origin", branch_name: Optional[str] = None) -> bool:
    attributes:
      - `set_upstream`: Whether to set the upstream branch for the push.
      - `remote_name`: The name of the remote repository (default is "origin").
      - `branch_name`: The name of the branch to push to. If not provided, the current branch will be used.
    return_type: |
      bool: Returns `True` if the push was successful, `False` if it failed.
    notes: |
      This method uses `_run_git_command` to push changes to the remote repository. If `set_upstream` is `True`, it ensures that the upstream branch is set. It logs the operation using `log_agentic_event`.

  tool_force_git_sync:
    description: |
      A McP tool method for forcing a complete Git sync, which includes staging, committing, and pushing changes to the remote repository. This method can be exposed for other agents or systems to call.
    signature: |
      def tool_force_git_sync(self, commit_message: str, push_to_remote: bool = True, set_upstream: bool = False, remote_name: str = "origin", branch_name: Optional[str] = None) -> dict:
    attributes:
      - `commit_message`: The commit message for the sync operation.
      - `push_to_remote`: Whether to push changes to the remote repository after committing.
      - `set_upstream`: Whether to set the upstream branch for the push.
      - `remote_name`: Name of the remote (default 'origin').
      - `branch_name`: The name of the branch to push to.
    return_type: |
      dict: Returns a dictionary with overall status and messages from each step (e.g., {"status": "success/failure", "stage_log": "...", "commit_log": "...", "push_log": "..."}).
    notes: |
      This method performs a full Git sync by first staging changes, committing them, and then pushing them to the remote repository. It should log each sub-operation.

examples:
  - action_type: "GIT_OPERATION"
    status: "COMPLETED"
    parameters:
      operation: "git commit -m '''Automated commit'''" # Example of how a command might be logged
      message: "Automated commit"
    result:
      stdout: "On branch main
Your branch is up to date with 'origin/main'.

nothing to commit, working tree clean"
  - action_type: "GIT_OPERATION"
    status: "STARTED"
    parameters:
      operation: "git add ."
      message: "Staging all changes"



---

## 920-agent-resource-conventions

<!-- Source: .cursor\rules\920-agent-resource-conventions.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always (Core VANTA Resource Convention)
# FILE PATTERNS: N/A (Universal Agent Resource Management)

# VANTA Agent Resource Loading & Pathing Conventions

## 1. Centralized Resource Registry (Conceptual)
    - The VANTA framework SHOULD provide a centralized mechanism or utility (e.g., `ResourceManager`) for agents to request and resolve paths to shared resources (models, datasets, templates, schemas).
    - This avoids hardcoded paths within agent logic.

## 2. Standardized Directory Structure (Recommended)
    - **`models/`**: For ML models, organized by type or agent.
        - `models/<agent_name>/<model_version>/`
    - **`data/`**: For datasets, seeds, or other static data.
        - `data/raw/`, `data/processed/`, `data/schemas/`
    - **`config/`**: For agent-specific or shared configurations not part of the core blueprint.
        - `config/agents/<agent_name>.yaml`
        - `config/shared/common_settings.yaml`
    - **`templates/`**: For prompt templates, response templates, UI templates.
    - **`schemas/`**: For Pydantic models, JSON schemas used across agents or for API contracts (distinct from `data/schemas/` which might be for data file structures).
    - These paths should be relative to a well-defined `VANTA_RESOURCE_ROOT` or resolved by the `ResourceManager`.

## 3. Resource Identification & Versioning
    - Resources should be identifiable by a unique name or ID.
    - Model and dataset versioning is CRITICAL. Agents should explicitly request or be configured with specific resource versions.
    - The `ResourceManager` should handle resolving requests to the correct versioned path.

## 4. Dynamic Loading
    - Agents should load resources (especially large models) dynamically at startup (`setup()`) or on-demand, not at module import time.
    - Implement caching for frequently accessed resources where appropriate.

## 5. Configuration-Driven Paths
    - Specific paths or resource names used by an agent MUST be configurable (e.g., via its section in `blueprint.yaml` or a dedicated agent config file) rather than hardcoded.
    - Example: `expert_coder_agent.llm_model_name: "vanta-deepseek-coder-v2"` which the `ResourceManager` then resolves to a physical path.

## 6. Fallback & Default Resources
    - The system may define default or fallback resources if a specific version or resource is not found, but this should be logged clearly.

## 7. Environment Variables for Roots
    - Core root paths (e.g., `VANTA_MODELS_DIR`, `VANTA_DATA_DIR`) can be defined via environment variables, with sensible defaults provided by the framework.

## 8. Security for Remote Resources
    - If loading resources from remote locations (e.g., cloud storage, model hubs):
        - Use secure protocols (HTTPS).
        - Implement authentication and authorization.
        - Verify checksums/hashes of downloaded resources to ensure integrity.

## 9. Agent Access Permissions (Conceptual)
    - Future: A system could define which agents have access to which resource categories or specific resources.

*This rule ensures that agents can reliably and consistently locate and load the resources they need to operate, facilitating maintainability and deployment across different environments.*



---

## 920-mcp-tool-integration

<!-- Source: .cursor\rules\920-mcp-tool-integration.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# MCP Tool Integration Rule

## Overview
This rule defines how MCP tools should be integrated and triggered within the framework.

## Tool Categories

### File Operations
- `read_file`: For reading file contents
- `edit_file`: For modifying files
- `list_dir`: For directory listing
- `file_search`: For finding files
- `delete_file`: For removing files

### Terminal Operations
- `run_terminal_cmd`: For executing terminal commands

### Search Operations
- `grep_search`: For text-based searches
- `web_search`: For web queries

### Rule Management
- `fetch_rules`: For retrieving rule content

## Tool Trigger Patterns

```yaml
tool_triggers:
  file_operations:
    - pattern: "file:.*"
    - pattern: "read:.*"
    - pattern: "write:.*"
    - pattern: "search:.*"
    
  terminal_operations:
    - pattern: "exec:.*"
    - pattern: "run:.*"
    
  search_operations:
    - pattern: "find:.*"
    - pattern: "grep:.*"
    - pattern: "web:.*"
    
  rule_operations:
    - pattern: "rule:.*"
    - pattern: "mdc:.*"
```

## Implementation

```python
class MCPToolIntegration:
    def __init__(self):
        self.available_tools = {
            'read_file': self._handle_read_file,
            'edit_file': self._handle_edit_file,
            'list_dir': self._handle_list_dir,
            'file_search': self._handle_file_search,
            'delete_file': self._handle_delete_file,
            'run_terminal_cmd': self._handle_terminal_cmd,
            'grep_search': self._handle_grep_search,
            'web_search': self._handle_web_search,
            'fetch_rules': self._handle_fetch_rules
        }
        
    async def trigger_tool(self, tool_name: str, params: dict) -> Any:
        """Trigger an MCP tool with given parameters."""
        if tool_name not in self.available_tools:
            raise ValueError(f"Unknown tool: {tool_name}")
            
        handler = self.available_tools[tool_name]
        return await handler(params)
        
    async def _handle_read_file(self, params: dict) -> str:
        return await read_file(**params)
        
    async def _handle_edit_file(self, params: dict) -> None:
        return await edit_file(**params)
        
    # ... Additional handlers for other tools
```

## Integration with Rule System

```python
class RuleWithMCP(Rule):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.mcp_integration = MCPToolIntegration()
        
    async def apply(self, context: Context) -> None:
        """Apply rule with MCP tool support."""
        if self._requires_file_operation(context):
            await self.mcp_integration.trigger_tool('read_file', {
                'path': context.file_path,
                'explanation': f"Reading file for rule {self.id}"
            })
            
        # Continue with rule application
```

## Best Practices

1. **Tool Selection**
   - Use the most specific tool for the task
   - Prefer built-in tools over custom implementations
   - Chain tools for complex operations

2. **Error Handling**
   - Handle tool-specific errors appropriately
   - Provide meaningful error messages
   - Implement retry logic for transient failures

3. **Performance**
   - Cache tool results when appropriate
   - Batch similar operations
   - Monitor tool execution time

4. **Security**
   - Validate all tool inputs
   - Respect file system boundaries
   - Log tool usage for audit

## Examples

### Reading and Modifying Files
```python
# Read file content
await mcp_integration.trigger_tool('read_file', {
    'target_file': 'src/main.py',
    'explanation': 'Reading main file for analysis'
})

# Edit file
await mcp_integration.trigger_tool('edit_file', {
    'target_file': 'src/main.py',
    'instructions': 'Update function documentation',
    'code_edit': updated_content
})
```

### Searching Code
```python
# Search for pattern
await mcp_integration.trigger_tool('grep_search', {
    'query': 'function\\s+main',
    'explanation': 'Finding main function definition'
})
```

### Running Commands
```python
# Execute terminal command
await mcp_integration.trigger_tool('run_terminal_cmd', {
    'command': 'npm install',
    'explanation': 'Installing dependencies',
    'is_background': False
})
```


---

## 921-mcp-server-integration

<!-- Source: .cursor\rules\921-mcp-server-integration.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# MCP Server Integration Rule

## Overview

This rule defines how MCP tools should be integrated into the framework server-side, enabling agents to use tools outside of the Cursor IDE environment.

## Tool Categories

### File Operations
- read_file
- edit_file
- list_dir
- file_search
- delete_file
- grep_search

### Terminal Operations
- run_terminal_cmd
- process_management
- environment_control

### Web Operations
- web_search
- web_scrape
- api_request
- webhook_management

### AI/ML Operations
- text_embedding
- image_generation
- code_analysis
- semantic_search

### Database Operations
- query_execution
- schema_management
- data_migration
- backup_restore

### Vector Operations
- vector_store_query
- vector_store_update
- similarity_search
- clustering

## Implementation Requirements

```python
from dataclasses import dataclass
from typing import Dict, List, Any, Optional
from enum import Enum
from datetime import datetime

class ToolCategory(Enum):
    FILE = "file"
    TERMINAL = "terminal"
    WEB = "web"
    AI = "ai"
    DATABASE = "db"
    VECTOR = "vector"

@dataclass
class ToolDefinition:
    name: str
    category: ToolCategory
    description: str
    parameters: Dict[str, Any]
    required_params: List[str]
    is_async: bool = True
    cache_ttl: Optional[int] = None
    rate_limit: Optional[int] = None

@dataclass
class ToolResult:
    tool_name: str
    status: str
    result: Any
    execution_time: float
    timestamp: datetime
    metadata: Dict[str, Any]

class MCPServerTools:
    """Server-side MCP tool integration handler."""
    
    def __init__(self):
        self.tools: Dict[str, ToolDefinition] = {}
        self.results_cache: Dict[str, ToolResult] = {}
        
    async def register_tool(self, tool_def: ToolDefinition) -> None:
        """Register a new tool with the system."""
        self.tools[tool_def.name] = tool_def
        
    async def execute_tool(self, tool_name: str, params: Dict[str, Any]) -> ToolResult:
        """Execute a tool with given parameters."""
        if tool_name not in self.tools:
            raise ValueError(f"Unknown tool: {tool_name}")
            
        tool = self.tools[tool_name]
        
        # Validate required parameters
        for required in tool.required_params:
            if required not in params:
                raise ValueError(f"Missing required parameter: {required}")
                
        # Check cache if applicable
        if tool.cache_ttl:
            cache_key = self._get_cache_key(tool_name, params)
            if cache_key in self.results_cache:
                return self.results_cache[cache_key]
                
        # Execute tool
        start_time = datetime.now()
        result = await self._execute_tool_impl(tool, params)
        execution_time = (datetime.now() - start_time).total_seconds()
        
        tool_result = ToolResult(
            tool_name=tool_name,
            status="success",
            result=result,
            execution_time=execution_time,
            timestamp=datetime.now(),
            metadata={"params": params}
        )
        
        # Cache result if applicable
        if tool.cache_ttl:
            cache_key = self._get_cache_key(tool_name, params)
            self.results_cache[cache_key] = tool_result
            
        return tool_result
        
    def _get_cache_key(self, tool_name: str, params: Dict[str, Any]) -> str:
        """Generate a cache key for tool results."""
        sorted_params = sorted(params.items())
        return f"{tool_name}:{str(sorted_params)}"
```

## Essential Agent Tools

### 1. File Management Tools
```python
FILE_TOOLS = [
    ToolDefinition(
        name="read_file",
        category=ToolCategory.FILE,
        description="Read file contents with optional line range",
        parameters={
            "path": "str",
            "start_line": "Optional[int]",
            "end_line": "Optional[int]"
        },
        required_params=["path"]
    ),
    ToolDefinition(
        name="write_file",
        category=ToolCategory.FILE,
        description="Write content to a file",
        parameters={
            "path": "str",
            "content": "str",
            "mode": "str"
        },
        required_params=["path", "content"]
    )
]
```

### 2. AI/ML Tools
```python
AI_TOOLS = [
    ToolDefinition(
        name="text_embedding",
        category=ToolCategory.AI,
        description="Generate embeddings for text",
        parameters={
            "text": "str",
            "model": "str"
        },
        required_params=["text"]
    ),
    ToolDefinition(
        name="code_analysis",
        category=ToolCategory.AI,
        description="Analyze code for patterns and issues",
        parameters={
            "code": "str",
            "language": "str"
        },
        required_params=["code"]
    )
]
```

### 3. Vector Store Tools
```python
VECTOR_TOOLS = [
    ToolDefinition(
        name="vector_store_query",
        category=ToolCategory.VECTOR,
        description="Query vector store for similar items",
        parameters={
            "collection": "str",
            "query_vector": "List[float]",
            "top_k": "int"
        },
        required_params=["collection", "query_vector"]
    )
]
```

## Integration Points

### 1. Framework Integration
```python
class FrameworkMCPIntegration:
    def __init__(self):
        self.mcp_server = MCPServerTools()
        self.active_tools: Dict[str, bool] = {}
        
    async def initialize(self):
        """Initialize MCP server integration."""
        # Register file tools
        for tool in FILE_TOOLS:
            await self.mcp_server.register_tool(tool)
            
        # Register AI tools
        for tool in AI_TOOLS:
            await self.mcp_server.register_tool(tool)
            
        # Register vector tools
        for tool in VECTOR_TOOLS:
            await self.mcp_server.register_tool(tool)
```

### 2. Agent Integration
```python
class AgentMCPInterface:
    def __init__(self, framework_mcp: FrameworkMCPIntegration):
        self.framework_mcp = framework_mcp
        
    async def execute_tool(self, tool_name: str, params: Dict[str, Any]) -> Any:
        """Execute an MCP tool on behalf of an agent."""
        result = await self.framework_mcp.mcp_server.execute_tool(tool_name, params)
        return result.result
```

## Best Practices

1. **Tool Registration**
   - Register tools during framework initialization
   - Validate tool definitions before registration
   - Maintain tool versioning

2. **Error Handling**
   - Implement proper error handling for each tool
   - Provide detailed error messages
   - Log all tool execution errors

3. **Performance**
   - Use caching for appropriate tools
   - Implement rate limiting
   - Monitor tool execution times

4. **Security**
   - Validate all tool parameters
   - Implement access control
   - Sanitize tool inputs and outputs

## Required MCP Packages

1. **Core Packages**
```bash
pip install mcp-core
pip install mcp-tools
pip install mcp-vector
```

2. **AI/ML Packages**
```bash
pip install mcp-ai
pip install mcp-embeddings
pip install mcp-code-analysis
```

3. **Vector Store Packages**
```bash
pip install mcp-vector-store
pip install mcp-similarity
pip install mcp-clustering
```


---

## 921-vanta-mcp-signal-schema

<!-- Source: .cursor\rules\921-vanta-mcp-signal-schema.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always (Core VANTA Inter-Agent Communication Standard)
# FILE PATTERNS: N/A (Universal MCP Signal Schema)

# VANTA MCP Signal Schema & Conventions

## 1. Purpose
This document defines the standardized JSON schema for signals that VANTA agents prepare for the `VantaMasterCore` orchestrator or for direct inter-agent communication mediated by the orchestrator. These signals are used for:
    - Initiating agent cascades (defined in `agent_cascade_definitions.mdc`).
    - Suggesting user-confirmed (whisper) cascades.
    - Requesting handoff to another specialist agent.
    - Broadcasting events or findings to potentially interested agents.
    - Standardizing control flow and data exchange in multi-agent workflows.

## 2. Core Signal Structure
All MCP signals MUST adhere to the following base JSON schema:

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "VantaMCPSignal",
  "description": "Base schema for VANTA Master Control Program signals.",
  "type": "object",
  "properties": {
    "signal_id": {
      "type": "string",
      "format": "uuid",
      "description": "Unique identifier for this signal instance."
    },
    "timestamp_iso": {
      "type": "string",
      "format": "date-time",
      "description": "ISO 8601 timestamp when the signal was prepared."
    },
    "source_agent_id": {
      "type": "string",
      "description": "The ID of the agent emitting this signal."
    },
    "signal_type": {
      "type": "string",
      "enum": [
        "INITIATE_CASCADE",
        "SUGGEST_WHISPER_CASCADE",
        "REQUEST_AGENT_HANDOFF",
        "BROADCAST_EVENT",
        "TASK_DELEGATION_REQUEST",
        "STATUS_UPDATE_FOR_ORCHESTRATOR"
      ],
      "description": "The specific type of MCP signal."
    },
    "target_entity": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["CASCADE_PROFILE_ID", "AGENT_ID", "AGENT_TYPE", "BROADCAST_CHANNEL"],
          "description": "Type of the target entity."
        },
        "id": {
          "type": "string",
          "description": "Identifier of the target (e.g., a cascade_profile_id, a specific agent_id, an agent_type like 'testing_agent', or a broadcast channel name)."
        }
      },
      "required": ["type", "id"],
      "description": "Specifies the target for this signal."
    },
    "payload": {
      "type": "object",
      "description": "Signal-specific data. The schema for this payload depends on the signal_type and target_entity.type."
    },
    "priority": {
      "type": "integer",
      "minimum": 1, "maximum": 5, "default": 3,
      "description": "Signal priority (1=Highest, 5=Lowest). Used by orchestrator for queuing/scheduling."
    },
    "metadata": {
      "type": "object",
      "description": "Optional additional metadata, like correlation_id, original_task_id, etc."
    }
  },
  "required": [
    "signal_id",
    "timestamp_iso",
    "source_agent_id",
    "signal_type",
    "target_entity"
  ]
}
```

## 3. Specific Signal `payload` Schemas (Examples)

### 3.1. `INITIATE_CASCADE`
   - `target_entity.type`: `"CASCADE_PROFILE_ID"`
   - `target_entity.id`: The `profile_id` from `agent_cascade_definitions.mdc`.
   - `payload`: An object matching the `parameters_expected` by that cascade profile.
     ```json
     // Example payload for INITIATE_CASCADE (core_protocol_modification_cascade)
     {
       "modified_files": ["/path/to/protocol_api.py"],
       "change_summary": "Added new /v2/trigger endpoint.",
       "initiating_agent_id": "expert_coder"
     }
     ```

### 3.2. `SUGGEST_WHISPER_CASCADE`
   - `target_entity.type`: `"CASCADE_PROFILE_ID"` (for the whisper cascade)
   - `target_entity.id`: The `profile_id` of the whisper cascade.
   - `payload`: An object matching the `parameters_expected` by that whisper cascade profile, used to formulate the suggestion prompt.
     ```json
     // Example payload for SUGGEST_WHISPER_CASCADE (general_code_commit_whisper_cascade)
     {
       "modified_files_count": 3,
       "primary_changed_module": "vanta_seed.utils.helpers",
       "modified_files_list": ["file1.py", "file2.py", "file3.py"]
     }
     ```

### 3.3. `REQUEST_AGENT_HANDOFF`
   - `target_entity.type`: `"AGENT_TYPE"` or `"AGENT_ID"` (if specific instance is known)
   - `target_entity.id`: The type or ID of the agent to hand off to.
   - `payload`:
     ```json
     {
       "reason_for_handoff": "Requires specialized knowledge in XXX.",
       "current_task_data": { ... }, // Original task_data or relevant parts
       "context_summary": "Current understanding and progress...",
       "specific_question_for_next_agent": "Could you analyze Y based on Z?"
     }
     ```

## 4. Agent Responsibility (`mcp_signal_preparation` tool/capability)
    - Agents that need to send signals (e.g., `ExpertCoder`, `RitualUpkeepAgent`) should have a capability or use a shared utility (`mcp_signal_preparation`) that helps them construct valid signals according to this schema.
    - This utility would automatically populate `signal_id`, `timestamp_iso`, and `source_agent_id`.
    - It would validate the `payload` against the requirements of the `signal_type` and `target_entity.id` (e.g., checking `parameters_expected` for a cascade).

## 5. Orchestrator Responsibility (`VantaMasterCore`)
    - `VantaMasterCore` MUST be able to receive, parse, validate (against this schema), and appropriately route/process these MCP signals.
    - It will use `signal_type` and `target_entity` to determine the action (e.g., look up cascade profile, find agent for handoff).

*Adherence to this MCP Signal Schema is vital for robust, predictable, and extensible inter-agent communication and workflow orchestration within the VANTA framework.*



---

## 922-agentic-replay-log-schema

<!-- Source: .cursor\rules\922-agentic-replay-log-schema.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: N/A (Applies to core system logging behavior)

# 922: Agentic Replay Log Schema & Guidelines

@id: 922-agentic-replay-log-schema
@desc: Defines the authoritative JSON schema for agentic replay log entries used across VANTA for consistent event logging.
@schema_file: .cursor/schemas/agentic_replay_log_entry.schema.json

## Purpose

Ensures all log entries emitted via `VantaMasterCore.log_agentic_event` adhere to a strict structure for interoperability, analysis, and debugging.

## Key Schema Fields

- **log_id** (string, uuid): Unique identifier for each log entry.
- **timestamp** (string, date-time): UTC timestamp when the event was logged.
- **agent_id** (string): Identifier of the agent or core component that generated the entry.
- **action_type** (string): Describes the action/event (e.g., `CASCADE_STARTED`, `CASCADE_STEP_COMPLETED`).
- **status** (string enum): One of `in_progress`, `success`, `failure`, `timeout`, `error`, or `exception`.
- **parameters** (object): Contextual parameters or inputs provided to the action.
- **result** (object): Outputs or error details produced by the action.
- **correlation_id** (string, uuid): Shared identifier correlating all entries of a single cascade run.
- **duration_ms** (integer): Elapsed time in milliseconds for the action's execution.

## Usage Guidelines

1. **Validation**: `log_agentic_event` should validate each entry against this schema before appending to `logs/agentic_replay.log.jsonl`.
2. **Schema Source**: Maintain only one source of truth: the `.json` file in `.cursor/schemas/agentic_replay_log_entry.schema.json`. This MDC rule references it via `@schema_file`.
3. **Extensibility**: If additional fields become necessary (e.g., `tool_name`, `parameters.detail`), update the JSON schema first, then update this MDC rule to document the change.
4. **Versioning**: Update the MDC header if schema versions change. Consumers should check `schema_file` values for compatibility.

## Relation to Other Rules

- **924-cascade-executor.mdc**: relies on this schema for logging cascade events.
- **925-cascade-agent-swarm-activation.mdc**: uses MCP signals that in turn generate log entries conforming to this schema.

## 1. Purpose

This rule establishes the standardized schema and operational guidelines for logging agent and system actions to the `logs/agentic_replay.log.jsonl` file. This log is crucial for:

*   Debugging and tracing agent behavior.
*   Providing data for the `IncoherenceDetectionAgent` to identify patterns of failure.
*   Auditing system operations.
*   Future reinforcement learning and behavioral analytics.

## 2. Log Entry Schema

All entries written to `logs/agentic_replay.log.jsonl` **MUST** conform to the JSON schema defined in:
`./.cursor/schemas/agentic_replay_log_entry.schema.json`

This schema mandates fields such as `log_id`, `timestamp`, `agent_id`, `action_type`, `status`, `parameters`, and `result`.

## 3. Logging Responsibility

*   **`VantaMasterCore`**: Is primarily responsible for orchestrating the logging of significant events, especially:
    *   Tool call attempts and their results (success, failure, no_changes).
    *   MCP Signal emissions.
    *   Agent task execution start and end.
    *   Cascade invocations and step executions.
*   **Individual Agents**: May log specific internal milestones or verbose debugging information if necessary, but primary action logging (like tool calls they initiate through the core) should be handled by `VantaMasterCore` to ensure consistency.
*   **Tooling Layer**: The wrappers around tools (e.g., `default_api` or `mcp_desktop-commander` handlers) should provide sufficient structured information back to `VantaMasterCore` to enable comprehensive logging.

## 4. When to Log

At a minimum, log entries should be created for:

*   **Tool Call Attempts (`TOOL_CALL_ATTEMPT`)**: Before a tool is executed. Log the `agent_id`, `tool_name`, and `parameters`.
*   **Tool Call Results (`TOOL_CALL_RESULT`)**: After a tool execution completes or fails. Log the `status` and `result` (including errors or output).
    *   Crucially, for file editing tools, the `status` should differentiate between `SUCCESS` (change applied), `FAILURE` (error during attempt), and `NO_CHANGES_REPORTED` (tool ran successfully but reported no diff/change).
*   **MCP Signal Emission (`MCP_SIGNAL_EMIT`)**: When `VantaMasterCore` emits an MCP signal. Log the `signal_name` and `payload` within the `parameters` or `result` field.
*   **Agent Task Execution (`AGENT_TASK_EXECUTION_START`/`END`)**: When an agent begins and ends processing a task. Useful for performance monitoring and tracing long-running tasks.
*   **Cascade Invocation & Steps (`CASCADE_INVOCATION`/`CASCADE_STEP_EXECUTION`)**: To trace the flow of automated sequences.
*   **Critical System Messages (`SYSTEM_MESSAGE`)**: For important system-level events or errors not directly tied to a specific agent action (e.g., startup issues, configuration load failures).
*   **User Input (`USER_INPUT`)**: Optionally, to capture user prompts or commands that initiate a chain of actions, providing full context for a trace.

## 5. Log Content Guidelines

*   **`log_id`**: MUST be a unique identifier (e.g., UUID v4) for each distinct log entry.
*   **`timestamp`**: MUST be in UTC ISO 8601 format.
*   **`agent_id`**: Use a consistent identifier for each agent. For `VantaMasterCore` itself, use a distinct ID like `vmc_orchestrator`.
*   **`parameters`**: For tool calls, ensure all significant input parameters are captured, especially `target_file(s)`, `code_edit`, `instructions`, `command`.
*   **`result.message`**: Provide a concise human-readable summary of the outcome.
*   **`result.details`**: Include any structured data from the tool's response or error objects.
*   **`correlation_id`**: Use this to link related log entries. For example, all log entries related to a single cascade instance should share the same `correlation_id`.

## 6. Implementation Notes for Logging Mechanism

*   The logging mechanism should append entries as single lines of JSON (JSONL format) to `logs/agentic_replay.log.jsonl`.
*   Ensure file locking or other appropriate mechanisms are used if multiple processes/threads could write to the log concurrently (though typically `VantaMasterCore` might serialize this).
*   Handle potential I/O errors during logging gracefully (e.g., log to stderr if the file write fails).

## 7. Importance for `IncoherenceDetectionAgent`

Strict adherence to this logging schema and its guidelines is paramount for the `IncoherenceDetectionAgent` to function correctly. This agent will parse this log to identify patterns such as:

*   Repeated `TOOL_CALL_RESULT` entries for the same `target_file` with `status: "NO_CHANGES_REPORTED"` or `status: "FAILURE"`.
*   Discrepancies between `TOOL_CALL_ATTEMPT` parameters and `TOOL_CALL_RESULT` outcomes.

Failure to log accurately will impair the system's ability to self-diagnose and maintain coherence.



---

## 923-agentic-build-validate

<!-- Source: .cursor\rules\923-agentic-build-validate.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules

# Agentic Build and Validate Ritual Standard

## Purpose
To ensure the integrity, quality, and compliance of the VANTA codebase before changes are merged into primary branches (e.g., `main`, `develop`). This automated ritual acts as a gatekeeper, preventing regressions and enforcing development standards.

## Workflow Trigger
This validation workflow MUST be triggered automatically on:
- Every push to primary branches (`main`, `develop`, or others defined in `THEPLAN.md`).
- Every pull request targeting primary branches.

## Implementation
- The canonical implementation resides in `.github/workflows/validate_agentic_commit.yml`.
- Deviations or alternative implementations MUST be documented and justified in `THEPLAN.md`.

## Validation Steps (Order Matters)

1.  **Dependency Installation:** Install project dependencies (`requirements.txt`) and testing dependencies (`requirements.testing.txt` if present).
2.  **MDC Rule Validation (Placeholder):**
    - Lint and validate the syntax and structure of all `.cursor/rules/*.mdc` files.
    - Requires a dedicated script (e.g., `scripts/validate_mdc_rules.py`).
    - *Status: Placeholder - requires implementation.* 
3.  **JSON Schema Validation:**
    - Validate all `*.schema.json` files against the JSON Schema standard using `jsonschema`.
4.  **Testing (Pytest):**
    - Execute all tests within the `tests/` directory using `pytest`.
    - Ensure compliance with `.cursor/rules/910-vanta-testing-protocol.mdc`.
5.  **Code Formatting (Black):**
    - Check code formatting using `black --check`.
6.  **Linting (Flake8):**
    - Lint code using `flake8`.
7.  **Type Checking (MyPy):**
    - Perform static type checking using `mypy` (adjust flags like `--ignore-missing-imports` as needed).
8.  **Agent Contract Validation (Placeholder):**
    - Validate agent configurations, base class adherence, and required methods.
    - Requires a dedicated script (e.g., `scripts/validate_agents.py`).
    - *Status: Placeholder - requires implementation.* 

## Failure Handling
- If **any** validation step fails, the workflow MUST exit with a non-zero status code.
- Failed workflows MUST block pull request merges and indicate failure clearly in the CI/CD interface.

## Logging
- Each step MUST log informative messages indicating its start and success/failure.
- Error messages MUST be clear, concise, and provide enough context for debugging.
- Logs should be structured for potential future analysis by agents.

## Evolution
- This protocol will evolve. New validation steps (e.g., security scanning, performance testing) may be added.
- Changes MUST be reflected in both the workflow file (`validate_agentic_commit.yml`) and this MDC rule.



---

## 924-cascade-executor

<!-- Source: .cursor\rules\924-cascade-executor.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: vanta_seed/core/cascade_executor.py, vanta_seed/core/vanta_master_core.py, .cursor/rules/agent_cascade_definitions.mdc

# Cascade Executor Standard

## Purpose
Defines the standard implementation and usage patterns for the `CascadeExecutor` within the VANTA framework. This component is responsible for executing multi-step agentic workflows (cascades) defined in `agent_cascade_definitions.mdc`.

## Core Responsibilities (`cascade_executor.py`)

1.  **Initialization:** Must accept an instance of `VantaMasterCore` during initialization to access core functionalities like task submission, logging, and configuration.
2.  **Definition Loading:** Must load and parse cascade definitions from the path specified in the core configuration (typically `.cursor/rules/agent_cascade_definitions.mdc`). It should handle potential YAML parsing errors and invalid file formats gracefully.
3.  **Cascade Triggering:** Must provide a primary method (e.g., `trigger_cascade`) that accepts a `cascade_id` and optional `initial_data`.
4.  **Step Execution:**
    *   Iterate through the steps defined for the triggered cascade.
    *   For each step, determine the action type (agent task, tool call, MCP signal, sub-cascade trigger).
    *   Delegate the execution of the action to the appropriate `VantaMasterCore` method (e.g., `execute_agent_task_sync`, `execute_tool_calls_sync`, `emit_mcp_signal`) or recursively call `trigger_cascade`.
    *   Handle potential failures at each step, including executing `on_failure` logic if defined.
    *   Support basic data passing between steps (e.g., injecting results from previous steps into the `task_data` of subsequent steps).
5.  **Logging:** Must log key events (cascade start, step start, step completion, cascade completion, failures) to the agentic replay log via `VantaMasterCore.log_agentic_event`, providing context like `cascade_id`, `step_number`, `step_name`, `success` status, and results (where appropriate).
6.  **Result Handling:** Must return a status indicating the overall success or failure of the cascade execution.

## Integration with `VantaMasterCore` (`vanta_master_core.py`)

1.  **Instantiation:** `VantaMasterCore` should instantiate `CascadeExecutor`, passing itself (`self`) during its own initialization.
2.  **Signal Handling:** `VantaMasterCore` should route incoming MCP signals intended to trigger cascades (e.g., signals with `action: "trigger_cascade"`) to the `CascadeExecutor.trigger_cascade` method.
3.  **Agent Task Execution:** `VantaMasterCore` needs methods (potentially synchronous wrappers like `execute_agent_task_sync` or async handling) that `CascadeExecutor` can call to run agent tasks and retrieve their results.
4.  **Tool Execution:** `VantaMasterCore` needs methods (e.g., `execute_tool_calls_sync`) that `CascadeExecutor` can call to execute tool calls via the appropriate MCP client and return results.

## Cascade Definition Format (`agent_cascade_definitions.mdc`)

-   Must be valid YAML, typically under a top-level `cascades:` key.
-   Each cascade is identified by a unique ID (key).
-   Each cascade contains a list of `steps`.
-   Each step is a dictionary defining:
    *   `name` (required, string)
    *   `description` (optional, string)
    *   One action type:
        *   `agent` (string, target agent ID) and optional `task_data` (dict)
        *   `tool_calls` (list of dicts, matching tool call schema)
        *   `mcp_signal` (dict, signal payload to emit)
        *   `trigger_cascade` (string, ID of sub-cascade to trigger)
    *   `on_failure` (optional, dict defining action on step failure)
    *   (Future) `condition`, `loop`, `parallel` attributes.
-   Steps can reference outputs from previous steps in their `task_data` using a defined syntax (e.g., `{{step_results.step_1_output}}`).

## Best Practices

-   Keep cascades focused on a specific workflow.
-   Break down complex workflows into smaller, potentially nested, cascades.
-   Use descriptive names for cascades and steps.
-   Define clear `on_failure` handling for critical steps.
-   Ensure agents called within cascades are designed to handle the provided `task_data` and return meaningful results.
-   Log comprehensively for traceability and debugging.



---

## 925-cascade-agent-swarm-activation

<!-- Source: .cursor\rules\925-cascade-agent-swarm-activation.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: vanta_seed/core/vanta_master_core.py, vanta_seed/core/cascade_executor.py

# Agentic Cascade Swarm Activation Protocol (Layer 2 Online)

## Phase Context

This protocol governs the critical transition phase where the VANTA system moves from a core kernel with basic orchestration (Layer 1) to enabling true agent-to-agent communication and multi-step workflow execution via cascades (Layer 2).

## Core Objective

To fully integrate the `CascadeExecutor` (`vanta_seed/core/cascade_executor.py`) with the `VantaMasterCore` (`vanta_seed/core/vanta_master_core.py`) to enable the execution of predefined agentic cascades based on MCP signals or internal triggers.

## Implementation Requirements

1.  **Instantiation:** `VantaMasterCore` MUST instantiate `CascadeExecutor` during its initialization, providing necessary access to core functions (logging, config, task submission).
2.  **Signal Handling:** `VantaMasterCore` MUST implement logic to detect incoming signals intended to trigger cascades (e.g., matching a specific `intent` or `action` field like `trigger_cascade`) and route them correctly to `CascadeExecutor.trigger_cascade` with the `cascade_id` and relevant parameters.
3.  **Synchronous Wrappers:** `VantaMasterCore` MUST provide synchronous execution methods (e.g., `execute_agent_task_sync`, `execute_tool_calls_sync`) that the `CascadeExecutor` can reliably call to execute individual cascade steps. These methods are responsible for handling the underlying asynchronous nature of agent tasks or tool calls and returning a definitive result (success/failure status and output/error).
4.  **Cascade Executor Logic (`cascade_executor.py`):**
    *   MUST correctly load cascade definitions from `.cursor/rules/agent_cascade_definitions.mdc` (or configured path).
    *   MUST iterate through cascade steps, calling the appropriate synchronous execution wrappers in `VantaMasterCore`.
    *   MUST implement data passing between steps (using `{{step_results.step_X_output}}` or similar).
    *   MUST correctly log all relevant events (start, step start/complete, end) to the agentic replay log (`logs/agentic_replay.log.jsonl`) using the defined schema (`.cursor/schemas/agentic_replay_log_entry.schema.json`).
    *   MUST implement `on_failure` logic, typically halting the cascade unless otherwise specified in the step definition.
5.  **Testing:** At least one simple test cascade MUST be defined in `agent_cascade_definitions.mdc`, and its successful execution via a trigger signal MUST be verified.

## Binding Activation

Completion of these implementation requirements signifies that Layer 2 (Agent Swarm / Cascade Autonomy) is considered **ONLINE** and **FUNCTIONAL**. All subsequent agent development and workflow design should leverage this cascade execution capability.

## Compliance

Failure to adhere to this protocol during the integration phase will prevent the system from achieving reliable agentic swarm behavior. The Agentic Build and Validate Ritual (`.cursor/rules/923-agentic-build-validate.mdc`) should include tests verifying this integration.



---

## 926-vanta-external-mcp-integration

<!-- Source: .cursor\rules\926-vanta-external-mcp-integration.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
# RULE TYPE: Best Practice / Integration Guideline
# FILE PATTERNS: vanta_seed/core/mcp_server_tools.py, config/tool_registry.yaml (adjust as needed)

# 926: VANTA External MCP Tool Integration Standard

## Purpose
This rule outlines the standard procedure for integrating third-party MCP (Master Control Program) tools, especially those discovered or installed via external mechanisms like Smithery CLI, into the VANTA framework's internal tool registry and execution capabilities. This ensures consistent, secure, and maintainable access to external functionalities for VANTA agents.

## Prerequisites
- The external MCP tool should be installed and accessible (e.g., as a running service, SaaS API).
- API documentation for the external tool (endpoint URL, request/response formats, authentication method, parameters) MUST be available.

## Integration Steps

1.  **API Analysis:**
    *   Identify the exact HTTP endpoint(s) for the tool's functionality.
    *   Determine the required HTTP method (GET, POST, etc.).
    *   Identify all required and optional parameters for the request (query parameters, request body).
    *   Understand the expected structure of successful responses and error responses.
    *   Determine the authentication mechanism (e.g., API Key in header, Bearer token, OAuth).

2.  **Secure Credential Management (Ref: `1003-coding_agent-external_api_resilience.mdc`):**
    *   Store any required API keys, tokens, or other secrets securely using environment variables (`os.getenv`) or a dedicated secrets management system configured for VANTA.
    *   **DO NOT** hardcode credentials in the VANTA codebase.

3.  **Tool Definition (Ref: `921-mcp-server-integration.mdc`):**
    *   Define the tool using VANTA's standard `ToolDefinition` dataclass (or equivalent structure).
    *   Specify the `name`, `category` (e.g., `ToolCategory.WEB`, `ToolCategory.AI`), `description`, `parameters` (with types), and `required_params`.
    *   Ensure the `name` is unique and descriptive within VANTA's tool namespace.

4.  **Tool Registration:**
    *   Register the `ToolDefinition` with VANTA's central tool registry (e.g., the `MCPServerTools` instance within `VantaMasterCore` or a configuration file loaded by it).
    *   Ensure the registration happens during VANTA's initialization sequence.

5.  **Implementation of Execution Logic:**
    *   Implement the actual HTTP call logic within the appropriate VANTA module (e.g., as a private method `_execute_<tool_name>_tool` within the `MCPServerTools` class or a dedicated integration service).
    *   Use a robust HTTP client library (e.g., `httpx` preferred for async, or `requests`).
    *   Construct the request URL, headers (including authentication), and body based on the input `params` provided to `execute_tool`.
    *   Implement necessary error handling:
        *   Catch network errors (`Timeout`, `ConnectionError`).
        *   Handle non-2xx HTTP status codes appropriately (raise exceptions or return structured errors).
        *   Parse the response body (e.g., JSON) and handle potential parsing errors.
        *   Implement retry logic with backoff for transient server errors (5xx) if appropriate (Ref: `1003`).
        *   Include reasonable `timeout` values for all external calls (Ref: `1003`).
    *   Return the relevant data from the successful response in the format expected by the `ToolResult` structure.

6.  **Dependency Management:**
    *   Add any new external library dependencies (e.g., `httpx`) to `requirements.in` and regenerate `requirements.txt` using `pip-compile`.

7.  **Documentation:**
    *   Document the newly integrated tool's availability, parameters, and expected usage within VANTA's internal documentation (e.g., `docs/tools.md`, `THEPLAN.md`, or agent-specific docs).

8.  **Testing (Ref: `1010-coding_agent-test_coverage.mdc`):**
    *   Write unit/integration tests for the execution logic.
    *   Use mocking libraries (e.g., `pytest-mock`, `respx` for `httpx`) to simulate the external API responses (both success and error cases) without making actual network calls during tests.
    *   Verify correct parameter handling, authentication header construction, response parsing, and error handling.

## Example Snippet (Conceptual Implementation within `MCPServerTools`)

```python
# Example conceptual implementation within MCPServerTools class

# ... (Assume ToolDefinition for 'mermaid_render' is registered) ...

async def _execute_mermaid_render_tool(self, params: Dict[str, Any]) -> Any:
    """Executes the external Mermaid rendering tool."""
    mermaid_code = params.get("code")
    output_format = params.get("format", "svg") # Example optional param with default

    if not mermaid_code:
        raise ValueError("Missing required parameter: code")

    api_key = os.getenv("MERMAID_MCP_API_KEY")
    endpoint = os.getenv("MERMAID_MCP_ENDPOINT") # Get from config/env

    if not api_key or not endpoint:
        raise ValueError("Mermaid MCP API Key or Endpoint not configured.")

    headers = {"Authorization": f"Bearer {api_key}"}
    payload = {"code": mermaid_code, "format": output_format}

    async with httpx.AsyncClient(timeout=15.0) as client: # Use httpx for async
        try:
            response = await client.post(endpoint, json=payload, headers=headers)
            response.raise_for_status() # Raise exception for 4xx/5xx
            # Assuming the API returns the rendered output directly or a URL
            return response.json() # Or response.text, response.content depending on API
        except httpx.TimeoutException:
            # Log error
            raise TimeoutError("Request to Mermaid MCP timed out.")
        except httpx.RequestError as e:
            # Log error (e.g., connection error)
            raise ConnectionError(f"Network error calling Mermaid MCP: {e}")
        except httpx.HTTPStatusError as e:
            # Log error (specific HTTP error)
            # Consider inspecting e.response.status_code for specific handling
            # You might parse e.response.text for API error details
            raise ValueError(f"Mermaid MCP API error: {e.response.status_code} - {e.response.text}")
        except Exception as e:
            # Catch other potential errors (e.g., JSON decode error)
            # Log error
            raise RuntimeError(f"Unexpected error during Mermaid MCP call: {e}")

# ... (MCPServerTools.execute_tool would call this method) ...
```

## Compliance
All new external MCP tool integrations within VANTA MUST follow these steps to ensure consistency, security, and maintainability. Deviations require explicit justification in `THEPLAN.md`.



---

## 930-layer3-cli-api-activation

<!-- Source: .cursor\rules\930-layer3-cli-api-activation.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: cli.py, vanta_seed/api/main.py, vanta_seed/core/vanta_master_core.py

# Layer 3 Activation Protocol (CLI / API Interface)

## Phase Context

This protocol governs the implementation of Layer 3, focusing on creating external command-line (CLI) and Application Programming Interfaces (API) for the VANTA system. This layer bridges the internal agentic core (Layers 1 & 2) with external users, systems, or interfaces.

**Prerequisite:** Layer 2 (Agentic Cascade Swarm Activation) MUST be complete and validated.

## Core Objective

To provide robust, secure, and user-friendly CLI and REST API interfaces for controlling and observing the VANTA system, including triggering rituals/cascades, querying status, and accessing logs.

## Implementation Requirements

1.  **Technology Choices:**
    *   CLI: MUST use `typer` (preferred) or `argparse`.
    *   API: MUST use `FastAPI`.
    *   API Validation: MUST use `Pydantic` models for request/response validation.
2.  **Interface Parity (Core Functions):** The CLI and API MUST provide access to the same core set of functionalities:
    *   Triggering rituals by name.
    *   Triggering cascades by ID.
    *   Querying agent/system status.
    *   Accessing recent logs.
3.  **Core Interaction:**
    *   Both CLI handlers and API endpoints MUST interact with `VantaMasterCore` through clearly defined, secure methods.
    *   `VantaMasterCore` MUST expose the necessary functionality (e.g., `trigger_ritual_by_name`, `trigger_cascade_by_id`, `get_agent_status`) for these interfaces.
    *   Direct manipulation of core state from handlers/endpoints is PROHIBITED; all actions must go through `VantaMasterCore` methods.
4.  **CLI Standards (`cli.py` / `vanta_seed/utils/cli_handler.py`):
    *   Commands MUST be clearly named and documented (use help strings).
    *   Input parameters MUST be validated.
    *   Output MUST be user-friendly and informative.
    *   MUST handle errors gracefully and provide meaningful exit codes.
5.  **API Standards (`vanta_seed/api/main.py` / `vanta_seed/utils/api_handler.py`):
    *   Endpoints MUST follow RESTful principles where applicable.
    *   Request bodies and query parameters MUST be validated using Pydantic.
    *   Responses MUST use appropriate HTTP status codes.
    *   Error responses MUST provide clear error messages.
    *   Consider adding basic authentication/authorization mechanisms if required by `THEPLAN.md`.
6.  **Testing:**
    *   Basic unit/integration tests MUST be created for core CLI commands.
    *   Basic integration tests MUST be created for core API endpoints (using `httpx` and `pytest`).
7.  **Validation:** All code related to Layer 3 MUST pass the Agentic Build and Validate CI workflow (`.github/workflows/validate_agentic_commit.yml`).

## Binding Activation

Completion of these implementation requirements signifies that Layer 3 (CLI / API Interface) is considered **ONLINE** and **FUNCTIONAL**. This makes the VANTA system externally controllable and marks a major step towards independence from the development environment.

## Documentation

-   CLI usage MUST be documented (e.g., via `--help` flags and in `README.md` or `docs/cli_usage.md`).
-   API endpoints MUST be documented (e.g., using FastAPI's automatic OpenAPI/Swagger docs and potentially `docs/api_reference.md`).
-   An overview MUST be added to `docs/layer3_cli_api_overview.md`.



---

## 950-project-scheduler-bootstrap

<!-- Source: .cursor\rules\950-project-scheduler-bootstrap.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: AutoAttached / AgentRequested
# FILE PATTERNS: .project-init-marker, THEPLAN.md, README.md
# INTENDED AUDIENCE: AI Assistant

# 950: Project Scheduler Bootstrap Protocol

## 1. Purpose

This rule guides the AI assistant in ensuring that a project (especially one where the `.cursor` directory and its rules have been copied) has a basic task scheduling mechanism considered or bootstrapped. This facilitates project-specific automation and adherence to rituals that might require scheduling (e.g., periodic maintenance, rule optimization checks).

This protocol does NOT grant the AI autonomous ability to inject schedulers into arbitrary projects. It activates when the AI is operating within a project where this rule is present (e.g., due to a copied `.cursor` directory) and relevant files are accessed or this rule is explicitly invoked.

## 2. Triggering Conditions

*   **Auto-Attachment:** When files like `THEPLAN.md`, `README.md` are opened or attached, as these are often reviewed early in a project's lifecycle.
*   **Marker File:** If a user creates an empty file named `.project-init-marker` in the project root, its presence can serve as a deliberate trigger for this rule when that file is encountered.
*   **Agent Requested:** The user can explicitly invoke this rule (e.g., `@950-project-scheduler-bootstrap.mdc check scheduler setup`).

## 3. AI Assistant Actions & Workflow

Upon activation, the AI assistant should perform the following steps for the **current project**:

### Step 3.1: Determine Project Type (Heuristic)

*   Check for indicators of a VANTA-based project (e.g., presence of `vanta_seed/` directory, `blueprint.yaml` with VANTA-specific structures).
*   If not clearly VANTA, assume a generic project context.

### Step 3.2: Check for Existing Scheduler Configuration

*   **For VANTA Projects:**
    *   Look for a VANTA scheduler configuration file (e.g., `config/scheduler_config.yaml` or `vanta_seed/config/schedules.yaml` - to be standardized by VANTA framework).
    *   Check if `VantaMasterCore` or a `SchedulerAgent` shows evidence of scheduler integration (e.g., APScheduler import, schedule loading logic).
*   **For Generic Projects:**
    *   Look for common scheduler setup files (e.g., a `crontab.txt` for notes, a simple `scripts/scheduler.py` using `APScheduler` or `schedule` library, or a GitHub Actions workflow file for scheduled tasks in `.github/workflows/`).

### Step 3.3: Propose Action Based on Findings

*   **Scenario A: No Scheduler Configuration Found**
    *   **VANTA Project:**
        *   Inform the user: "This VANTA project does not appear to have its internal task scheduler configured yet."
        *   Suggest: "Would you like me to help you create a template `config/scheduler_config.yaml` and outline the integration steps for `VantaMasterCore` or a `SchedulerAgent` based on APScheduler? This would enable automated execution of internal VANTA rituals and maintenance tasks."
        *   Offer to create a basic configuration file with example scheduled jobs (e.g., a placeholder for the MDC Rule Optimizer ritual).
    *   **Generic Project:**
        *   Inform the user: "This project doesn't seem to have a dedicated task scheduler set up."
        *   Suggest: "If you plan to have automated background tasks, we could set up a simple Python scheduler using APScheduler, or define a scheduled GitHub Actions workflow. What would you prefer?"
        *   Offer to create a template script or workflow file.

*   **Scenario B: Scheduler Configuration Found but Incomplete/Outdated**
    *   Inform the user: "I found a scheduler configuration at `[path]`, but it seems [describe issue, e.g., empty, old, missing key components]."
    *   Suggest: "Would you like to review and update it? We can add standard scheduled tasks like [example: periodic MDC rule optimization check]."

*   **Scenario C: Scheduler Configuration Appears Present and Functional**
    *   Inform the user: "It looks like a scheduler is already configured for this project (found at `[path]`)."
    *   (Optional) Suggest: "We can review its current scheduled jobs if you'd like."

### Step 3.4: Execution (User-Confirmed)

*   If the user agrees to a setup or modification proposal, use `edit_file` to create or update the necessary configuration files or script stubs.
*   Provide guidance on installing dependencies (e.g., `pip install apscheduler`).
*   Log the action in the AI's response signature (e.g., "Helped bootstrap scheduler config").

## 4. Important Considerations

*   **Project Context is Key:** All actions are within the current project where this `.cursor` directory resides.
*   **User Confirmation:** No files should be created or modified without explicit user confirmation.
*   **VANTA Scheduler Standardization:** For VANTA projects, the exact paths and structure of scheduler configurations should eventually be standardized within the VANTA framework itself. This rule will adapt to those standards as they evolve.

This protocol aims to make your process of copying the `.cursor` directory more powerful by ensuring that key project infrastructure, like a task scheduler, is consistently considered and set up.


---

## 951-scheduled-rule-maintenance-ritual

<!-- Source: .cursor\rules\951-scheduled-rule-maintenance-ritual.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Manual / Process Description
# FILE PATTERNS: .cursor/scheduler/run_mdc_maintenance.py
# INTENDED AUDIENCE: Developers, System Administrators, CI/CD Systems

# 951: Scheduled MDC Rule Maintenance Ritual

## 1. Purpose

This document describes the **Scheduled MDC Rule Maintenance Ritual**, which utilizes the `".cursor/scheduler/run_mdc_maintenance.py"` script. The goal of this ritual is to ensure the ongoing quality, consistency, and correctness of all MDC rules within the `".cursor/rules/"` directory through automated validation and formatting.

## 2. The Maintenance Script: `run_mdc_maintenance.py`

*   **Location:** `".cursor/scheduler/run_mdc_maintenance.py"`
*   **Functionality:** This script serves as a centralized executor for MDC rule hygiene tasks. Currently, it performs the following actions in sequence:
    1.  **Validates MDC Rules:** Executes `"scripts/validate_mdc_rules.py"` to check for syntax errors, structural issues, broken links, and glob pattern functionality within all `.mdc` files.
    2.  **Formats MDC Rules:** Executes `"scripts/format_mdc_rules.py"` to automatically format the YAML frontmatter of all `.mdc` files according to predefined standards (e.g., key order), preserving comments.
*   **Output:** The script prints detailed output from each sub-script and indicates overall success or failure.

## 3. Scheduling and Execution

The `"run_mdc_maintenance.py"` script is designed to be executed by various means, effectively creating a "scheduler" at the `.cursor` level once an external trigger is configured:

*   **Manual Execution:**
    *   Developers can run this script manually from the project root as needed:
        ```bash
        python .cursor/scheduler/run_mdc_maintenance.py
        ```
*   **Operating System Scheduler (Cron/Task Scheduler):
    *   For project-specific, automated local checks, you can set up a cron job (on Linux/macOS) or a Task Scheduler job (on Windows) to execute the script at regular intervals (e.g., daily, weekly).
        *   Example Cron (daily at 3 AM): `0 3 * * * /usr/bin/python /path/to/your/project/.cursor/scheduler/run_mdc_maintenance.py >> /path/to/your/project/logs/mdc_maintenance.log 2>&1`
*   **CI/CD Integration (e.g., GitHub Actions):
    *   This script can be integrated into a scheduled workflow in your CI/CD pipeline to perform rule hygiene checks automatically for the repository.
    *   Example GitHub Actions schedule trigger:
        ```yaml
        on:
          schedule:
            - cron: '0 5 * * SUN' # Run every Sunday at 5 AM UTC
        ```
*   **Git Pre-Commit Hook:
    *   Parts of this script (especially validation) could be adapted to run as a pre-commit hook to catch issues before they are committed.
*   **VANTA Internal Scheduler (Future):
    *   If/when the VANTA framework implements its own robust internal agent scheduler (e.g., using APScheduler as discussed), that scheduler could be configured to run `".cursor/scheduler/run_mdc_maintenance.py"` as a periodic internal maintenance task for the VANTA project itself.

## 4. Benefits

*   **Proactive Maintenance:** Regularly catches and fixes issues in MDC rules.
*   **Consistency:** Ensures all rules adhere to formatting standards.
*   **Reliability:** Improves the reliability of the AI assistant, which depends on correct and well-formed rules.
*   **Automation:** Reduces manual effort in maintaining the rule set.

## 5. Customization

The `"run_mdc_maintenance.py"` script can be extended to include more advanced maintenance tasks, such as:
*   Triggering the conceptual `"MDC Rule Optimizer Agent"` (defined in `"909-mdc-rule-optimization-protocol.mdc"`).
*   Generating reports on rule statistics or health.

By copying the `".cursor"` directory (containing this script and its dependent validation/formatting scripts) to new projects, you effectively propagate this standardized maintenance ritual capability.


---

## 960-automated-workflow-graph

<!-- Source: .cursor\rules\960-automated-workflow-graph.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# RULE TYPE: Process Automation
# FILE PATTERNS: .cursor/rules/agent_cascade_definitions.mdc, scripts/generate_workflow_graph.py

# 960: Automated Application Workflow Graph Generation

## 1. Purpose

This rule outlines the process for automatically generating and updating a visual representation of the application's workflow using Mermaid diagrams. This ensures that workflow documentation remains synchronized with the system's actual defined processes, particularly agent cascades.

## 2. Triggering Mechanisms & Scheduling

This process can be triggered through various mechanisms, catering to different operational needs:

### 2.1. CI/CD Pipeline (Primary Automated Trigger)
-   **Events:** Automatically upon pushes to main development branches (e.g., `main`, `develop`), on pull request events, or on scheduled cron runs within the CI/CD system (e.g., daily).
-   **Implementation:** Defined in CI/CD workflow files (e.g., `.github/workflows/validate_agentic_commit.yml` or a dedicated workflow).

### 2.2. Manual Execution
-   **How:** Direct execution of the underlying script (`scripts/generate_workflow_graph.py`).
-   **Use Case:** Local generation, debugging, or ad-hoc updates.

### 2.3. VANTA Internal Scheduling & Event-Driven Triggers (Future Enhancements / Advanced Integration)

As the VANTA framework matures, more sophisticated, context-aware triggers originating from within VANTA itself are envisioned:

-   **Time and Date Based (Internal VANTA Scheduler):
    -   **Concept:** A future VANTA internal scheduling component (e.g., part of `VantaMasterCore` or a dedicated `SchedulerAgent` using libraries like APScheduler) could invoke this script at predefined times or intervals.

-   **By Agent Actions / Completion:
    -   **Concept:** A significant agent action (e.g., `Vanta! Coder` completing a major feature implementation, a `DeploymentAgent` succeeding) could emit an MCP signal.
    -   **Mechanism:** This signal would trigger a specific cascade (defined in `agent_cascade_definitions.mdc`) which includes a step to execute the `generate_workflow_graph.py` script (likely via a `ToolCallingAgent` or a specialized `DocumentationUpdateAgent`).

-   **By Context of Project Progress / Milestones:
    -   **Concept:** The system recognizes the completion of a major development phase or milestone.
    -   **Mechanism (Explicit):**
        -   Manual trigger via a VANTA CLI command (e.g., `vanta docs update-workflow --reason "Phase 2 complete"`).
        -   A `MilestoneMonitorAgent` could watch key project documents (e.g., `THEPLAN.md`, `ROADMAP.md`) for explicit status changes (e.g., `[COMPLETED] Phase X`).
    -   **Mechanism (Implicit - Advanced):** A sophisticated agent could infer phase completion based on commit patterns, task closure rates, etc.
    -   **Workflow:** Detection of phase/milestone completion would lead to an MCP signal, triggering a documentation update cascade.

-   **Significant Change Detection in Source Definitions:
    -   **Concept:** If `agent_cascade_definitions.mdc` (the graph's primary data source) is significantly altered, the graph should be regenerated.
    -   **Mechanism:** Could be a file watcher within VANTA (if running persistently) or a dedicated check within the CI/CD pipeline that compares file hashes.

-   **Post-Release / Deployment:
    -   **Concept:** After a successful deployment, ensure all documentation, including the workflow graph, is up-to-date.
    -   **Mechanism:** If VANTA manages or is aware of deployments, it could trigger this as a post-deployment step in a release cascade.

-   **On-Demand via VANTA API/CLI:
    -   **Concept:** Allow users or other systems to request a graph update at any time.
    -   **Mechanism:** Through dedicated CLI commands (e.g., `vanta system update-workflow-graph`) or API endpoints.

## 3. Workflow Data Source

-   **Primary Source:** The `agent_cascade_definitions.mdc` file located in `.cursor/rules/` is the primary source of information for generating the workflow graph. The graph should depict the defined cascades, their steps, and the agents involved.
-   **Future Enhancements:** The system may evolve to incorporate other sources, such as API endpoint definitions, explicit workflow annotations in code, or data from `THEPLAN.md` regarding high-level process flows.

## 4. Graph Generation Script (`scripts/generate_workflow_graph.py`)

-   **Input:** Reads and parses `.cursor/rules/agent_cascade_definitions.mdc`.
-   **Processing:**
    -   Translates cascade profiles and their agent sequences into Mermaid flowchart syntax.
    -   Each cascade SHOULD be represented as a distinct subgraph if possible.
    -   Steps within a cascade (agent calls, tool calls, mcp_signal, trigger_cascade) SHOULD be represented as nodes with appropriate labels and shapes.
    -   Connections between steps SHOULD indicate the flow of execution.
-   **Output:** Writes the generated Mermaid syntax to a designated file (e.g., `docs/application_workflow.mermaid`). This output file should be committed back to the repository when run in CI/CD.
-   **Error Handling:** The script MUST handle parsing errors in the source file gracefully and log informative messages.

## 5. CI/CD Integration Actions

-   The CI workflow (e.g., `.github/workflows/validate_agentic_commit.yml` or a dedicated workflow) MUST include a step to:
    1.  Execute `scripts/generate_workflow_graph.py`.
    2.  If changes are detected in `docs/application_workflow.mermaid`, commit and push the updated file back to the repository. This requires careful configuration to avoid commit loops (e.g., using a bot user, specific commit messages, and conditions).

## 6. Expected Output File

-   The standard location for the generated graph is `docs/application_workflow.mermaid`.
-   This file can then be rendered by any Mermaid-compatible viewer or embedded in other documentation.

## 7. Benefits

-   **Automated Documentation:** Keeps workflow diagrams up-to-date with minimal manual effort.
-   **Visual Understanding:** Provides a clear visual overview of complex agent interactions and cascades.
-   **Impact Analysis:** Helps visualize the potential impact of changes to cascade definitions.

## 8. Evolution

-   The detail and scope of the generated graph may evolve. For example, it could include conditional logic, parameters, or links to agent-specific documentation.
-   The script should be designed with extensibility in mind to accommodate new data sources or more complex graphing requirements.


---

## 960-vanta-task-scheduling

<!-- Source: .cursor\rules\960-vanta-task-scheduling.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: false
---
# 960-vanta-task-scheduling.mdc

@id: 960-vanta-task-scheduling
@desc: Defines standards and guidelines for task scheduling and advanced trigger definitions within the VANTA framework, drawing inspiration from chronomesh.yaml.
@inspired_by: chronomesh.yaml

## 1. Purpose

This rule establishes the foundational principles and structural guidelines for implementing a comprehensive task scheduling and event-triggering system within VANTA. It aims to integrate the robust concepts found in `chronomesh.yaml` into VANTA's agentic architecture, ensuring that cascades, rituals, and individual agent tasks can be invoked reliably based on time, events, or external signals.

## 2. Core Concepts Derived from `chronomesh.yaml`

### 2.1. Task Definition (`TaskObject`)

VANTA tasks, especially those intended for scheduling or complex event-driven invocation, should be conceptualized as `TaskObjects` with the following key attributes:

*   **`task_id`**: (String, Unique) A unique identifier for the task definition.
*   **`name`**: (String) Human-readable name.
*   **`description`**: (String) Detailed purpose of the task.
*   **`task_type`**: (Enum: `recurring`, `one_time`, `event_driven`) Nature of the task.
*   **`schedule_config`**: (Object) Configuration for time-based tasks.
    *   **`cron_expression`**: (String) For `recurring` tasks using cron syntax.
    *   **`interval_seconds`**: (Integer) For `recurring` tasks at fixed intervals.
    *   **`run_once_at`**: (String, ISO8601 DateTime) For `one_time` tasks.
*   **`action`**: (Object) Defines what the task executes.
    *   **`type`**: (Enum: `trigger_cascade`, `execute_ritual`, `run_agent_task`, `call_script`, `invoke_api_endpoint`)
    *   **`target_id`**: (String) ID of the cascade, ritual, agent, script path, or API URL.
    *   **`parameters`**: (Object) Static or dynamically resolved parameters for the action.
*   **`trigger_conditions`**: (Array of Objects, for `event_driven` tasks) See Section 2.2.
*   **`dependencies`**: (Array of `task_id` Strings) Tasks that must complete successfully before this task can run.
*   **`retry_policy`**: (Object)
    *   **`max_attempts`**: (Integer, default: 1)
    *   **`delay_seconds`**: (Integer, default: 60) Exponential backoff can be considered.
*   **`timeout_seconds`**: (Integer) Maximum execution time for the task.
*   **`notification_config`**: (Object) Settings for notifications on success, failure, or timeout.
    *   **`on_success`**: (Boolean/Object)
    *   **`on_failure`**: (Boolean/Object)
    *   **`on_timeout`**: (Boolean/Object)
    *   **`channels`**: (Array: `email`, `slack`, `log_event`)
*   **`enabled`**: (Boolean, default: true)

### 2.2. Advanced Trigger Definitions (`TriggerObject`)

For `event_driven` tasks, `trigger_conditions` should be an array of `TriggerObjects`:

*   **`trigger_id`**: (String, Unique) Identifier for the trigger definition.
*   **`name`**: (String) Human-readable name.
*   **`trigger_type`**: (Enum: `file_system_event`, `webhook_event`, `message_queue_event`, `api_call_event`, `custom_mcp_signal`)
*   **`config`**: (Object) Type-specific configuration.
    *   For `file_system_event`: `path_to_watch`, `event_types` (create, modify, delete).
    *   For `webhook_event`: `endpoint_path`, `http_method`, `expected_payload_schema_ref`.
    *   For `message_queue_event`: `queue_name`, `message_filter_schema_ref`.
    *   For `api_call_event`: (Similar to webhook, but perhaps for internal API calls).
    *   For `custom_mcp_signal`: `signal_name_pattern`, `payload_filter_schema_ref`.
*   **`action_to_take`**: (Object) Defines which `TaskObject` (by `task_id`) to invoke.

## 3. Mapping to VANTA Architecture

These concepts should be integrated into VANTA as follows:

*   **Configuration Store:**
    *   Scheduled task definitions (inspired by `TaskObject`) and advanced trigger definitions (inspired by `TriggerObject`) could reside in a dedicated YAML/JSON configuration file (e.g., `config/scheduler_tasks.yaml`, `config/event_triggers.yaml`) or be dynamically managed via an API.
    *   `agent_cascade_definitions.mdc` should be enhanced to support `schedule_config` for cascades that are primarily time-driven, or `trigger_conditions` for event-driven cascades.
*   **`SchedulerAgent` (or similar module within `VantaMasterCore`):**
    *   Responsible for loading task definitions.
    *   Managing the scheduling lifecycle (using libraries like APScheduler, Celery Beat).
    *   Monitoring for `event_driven` triggers.
    *   Invoking the defined `action` (e.g., calling `VantaMasterCore.trigger_cascade_by_id`, `VantaMasterCore.execute_ritual_by_name`).
    *   Implementing retry policies and timeout logic.
    *   Handling notifications.
*   **`VantaMasterCore`:**
    *   Needs to expose robust methods for the `SchedulerAgent` to trigger cascades, rituals, or agent tasks with parameters.
    *   Needs to handle incoming webhook calls or listen to message queues if these trigger types are implemented, then relay them to the `SchedulerAgent` or directly evaluate `TriggerObjects`.
*   **`CascadeExecutor`:**
    *   Continues to execute cascades, but those cascades can now be invoked by the `SchedulerAgent` or event triggers, not just direct MCP signals.
*   **Global Settings (from `chronomesh.yaml`'s `global_settings`):**
    *   Concepts like `max_concurrent_tasks`, `default_retry_policy`, and `default_notification_channels` should be incorporated into `blueprint.yaml` or a new `scheduler_config.yaml`.

## 4. Implementation Guidelines

*   **Modularity:** Keep scheduling logic separate from core agent execution logic where possible.
*   **Idempotency:** Design scheduled tasks to be idempotent if they might be retried.
*   **Observability:** Ensure detailed logging for all scheduled task executions, trigger evaluations, and scheduler actions, adhering to `922-agentic-replay-log-schema.mdc`.
*   **Security:** For webhook triggers, ensure proper authentication and validation.
*   **Dynamic Configuration:** Consider allowing dynamic updates to task schedules and trigger definitions via an API (Layer 3).

## 5. Relation to Other Rules

*   **`1001-coding_agent-scheduled_tasks.mdc`**: This rule provides the high-level "why" and structure; `1001` advises on the "how" (e.g., using proper scheduling libraries).
*   **`950-project-scheduler-bootstrap.mdc`**: This rule guides the AI in setting up the initial scheduler components.
*   **`922-agentic-replay-log-schema.mdc`**: All scheduler actions and task outcomes must be logged according to this schema.
*   **`agent_cascade_definitions.mdc`**: This file will be a key consumer of scheduling and trigger configurations.

This rule provides the strategic direction for building a powerful and flexible scheduling and event management system within VANTA.



---

## 999-global-rules-reminder

<!-- Source: .cursor\rules\999-global-rules-reminder.mdc -->
<!-- Format: mdc -->

# RULE TYPE: Always
# FILE PATTERNS: **/*

## Global Rules Activation Reminder

**IMPORTANT:** This project uses global rules that need to be activated in your IDE.

### Quick Setup for Cursor IDE:
1. Open the file `globalrules_synced.md` in this repository
2. Copy the entire rules content 
3. Go to Cursor Settings  Rules  Global Rules
4. Paste the content and save

### Alternative Method:
- Set your Cursor IDE to use global rules from: `globalrules.md`
- Or configure `CURSOR_RULE_ROOTS` environment variable

### Why This Matters:
- **Consistency:** Ensures all team members use the same coding standards
- **Quality:** Automated enforcement of best practices and patterns
- **Efficiency:** Reduces code review overhead and catches issues early

### Files to Check:
- `globalrules.md` - Canonical global rules
- `globalrules_synced.md` - Copy/paste ready version
- `.cursor/config.yaml` - Local rule roots configuration

**Please activate global rules before starting development!**

---

*This reminder will disappear once global rules are properly configured.*


---

## adhd-energy-features

<!-- Source: .cursor\rules\adhd-energy-features.mdc -->
<!-- Format: mdc -->

---
description: 
globs: EnergyTracker.tsx,useEnergyLevel.ts,src/lib/energy/**/*.ts
alwaysApply: false
---
---
description: ADHD-friendly energy level tracking and task management features
globs: 
  - src/components/ui/EnergyTracker.tsx
  - src/hooks/useEnergyLevel.ts
  - src/lib/energy/**/*.ts
---

# ADHD Energy Features

## Energy Level Tracking
- Track energy levels throughout the day
- Use visual indicators for energy states
- Provide gentle reminders for energy check-ins
- Store energy history for pattern analysis

## Task Management
- Match tasks to current energy level
- Suggest optimal times for different tasks
- Allow flexible task rescheduling
- Provide energy-aware task prioritization

## UI/UX Guidelines
- Use clear visual hierarchies
- Implement consistent color coding
- Provide immediate feedback
- Keep interactions simple and predictable

## Implementation Details
- Store energy levels in localStorage
- Update energy tracking every 2 hours
- Use smooth transitions for UI changes
- Implement error-safe data persistence

# ADHD Energy-Based Feature Guidelines

These guidelines should be followed when implementing energy-based features for the RZN ADHD-Optimized Task Management System.

## Core Principles

1. **Energy-Task Matching**: Always implement features that match tasks to user's current energy levels.
2. **Reduce Decision Fatigue**: Minimize choices required when energy is low.
3. **Test-Driven Development**: Always write tests first for energy-based features to ensure reliability.
4. **Executive Function Support**: Design features that reduce executive function demands.
5. **Transition Assistance**: Include support for energy state transitions.

## Implementation Guidelines

### Energy Level Specification

- Use the standardized `EnergyLevel` type from `@/lib/energyLevels.ts`
- Energy levels should always be one of: `'low' | 'medium' | 'high'`
- When storing energy data in task metadata, use the `energyLevel` key

```typescript
// Import the standard energy level type
import { EnergyLevel } from '@/lib/energyLevels';

// Correct usage for typed energy levels
function processTask(task: Task, userEnergyLevel: EnergyLevel) {
  // Implementation
}
```

### Scoring and Matching Algorithms

- Implement clear, weighted scoring systems for matching
- Consider both task and user energy levels
- Include executive function and focus requirements in scoring
- Document all scoring weights and thresholds

```typescript
// Sample scoring pattern
function calculateMatchScore(
  userEnergyLevel: EnergyLevel,
  taskEnergyLevel: EnergyLevel,
  executiveFunctionDemand: number,
  focusRequired: number
): number {
  // Base score from energy match
  let score = getBaseEnergyMatchScore(userEnergyLevel, taskEnergyLevel);
  
  // Adjust for executive function demands
  score = adjustForExecutiveFunction(score, userEnergyLevel, executiveFunctionDemand);
  
  // Adjust for focus requirements
  score = adjustForFocusRequirements(score, userEnergyLevel, focusRequired);
  
  return score;
}
```

### UI Implementation

- Clearly indicate energy levels using both color and text
- Use green for high energy, blue/purple for medium, and amber/orange for low
- Include visual cues that don't rely solely on color (for accessibility)
- Implement smooth transitions between energy states

```tsx
// React component example
function EnergyLevelIndicator({ level }: { level: EnergyLevel }) {
  const colorMap = {
    high: 'bg-green-500',
    medium: 'bg-blue-500',
    low: 'bg-amber-500'
  };
  
  const iconMap = {
    high: <BoltIcon className="h-4 w-4" />,
    medium: <HalfFilledBatteryIcon className="h-4 w-4" />,
    low: <LowBatteryIcon className="h-4 w-4" />
  };
  
  return (
    <div className={`flex items-center gap-1 px-2 py-1 rounded-full ${colorMap[level]}`}>
      {iconMap[level]}
      <span className="text-white text-xs font-medium capitalize">{level}</span>
    </div>
  );
}
```

### Testing Requirements

- Test each energy level individually
- Include test cases for transitions between energy levels
- Test edge cases like tasks without energy levels
- Verify scoring and categorization logic
- Include accessibility tests for energy-level UI components

```typescript
// Test pattern example
describe('Energy-based feature', () => {
  test('should correctly handle low energy state', () => {
    // Test implementation
  });
  
  test('should correctly handle medium energy state', () => {
    // Test implementation
  });
  
  test('should correctly handle high energy state', () => {
    // Test implementation
  });
  
  test('should handle transitions between energy states', () => {
    // Test implementation
  });
  
  test('should appropriately handle tasks without energy levels', () => {
    // Test implementation
  });
});
```

### Data Model Requirements

- Always include energy level metadata in task models
- Add executive function demand (scale 1-5)
- Include focus requirement (scale 1-5)
- Store energy preferences in user settings

```typescript
// Task model pattern
interface TaskEnergySensitiveMetadata {
  energyLevel?: EnergyLevel;
  executiveFunctionDemand?: number; // 1-5 scale
  focusRequired?: number; // 1-5 scale
  estimatedDuration?: number; // in minutes
}

// User preferences pattern
interface UserEnergyPreferences {
  defaultEnergyLevel: EnergyLevel;
  morningEnergyLevel?: EnergyLevel;
  afternoonEnergyLevel?: EnergyLevel;
  eveningEnergyLevel?: EnergyLevel;
  enableEnergyBasedSuggestions: boolean;
}
```

## Service Integration

- Use the `EnergyMatchingService` for all energy-based recommendations
- Integrate with the AI scheduling system for energy-aware scheduling
- Respect user energy preferences from settings
- Include energy considerations in the "Now and Next" view

```typescript
// Integration example
import { matchTasksToEnergyState } from '@/lib/services/EnergyMatchingService';

// In a component or service
const energyMatchResults = matchTasksToEnergyState(
  tasks,
  userCurrentEnergyLevel,
  { transitioningTo: userNextEnergyState }
);

// Use the results
const recommendedTasks = energyMatchResults.perfectMatches;
```

## User Experience Guidelines

- Don't force users to specify energy levels for every task
- Provide smart defaults based on task characteristics
- Allow users to override energy recommendations
- Include energy level tracking in the user interface
- Provide guidance on managing energy transitions

## Documentation Requirements

- Document all energy-related algorithms
- Include examples of energy-based recommendations
- Create user guides for energy management features
- Document integration points with other services

By following these guidelines, we ensure that all energy-based features are consistent, reliable, and truly supportive of ADHD needs. 

---

## agentic_replay_schema

<!-- Source: .cursor\rules\agentic_replay_schema.json -->
<!-- Format: json -->

{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "VantaAgenticReplayLogEntry",
  "description": "Schema for entries in the agentic_replay.log, used for Reinforcement Learning and auditing agent/cascade behavior within the VANTA framework.",
  "type": "object",
  "properties": {
    "event_id": {
      "type": "string",
      "format": "uuid",
      "description": "Unique ID for this log entry."
    },
    "timestamp_iso": {
      "type": "string",
      "format": "date-time",
      "description": "ISO 8601 timestamp of the event."
    },
    "session_id": {
      "type": ["string", "null"],
      "description": "Identifier for the user session or overarching task context. Helps group related events."
    },
    "correlation_id": {
      "type": ["string", "null"],
      "description": "Identifier used to trace a single logical operation across multiple agents or services."
    },
    "initiating_trigger": {
        "type": "object",
        "properties": {
            "type": {
                "type": "string",
                "enum": ["USER_PROMPT", "FILE_MODIFICATION", "MCP_SIGNAL", "SCHEDULED_TASK", "AGENT_INTERNAL_LOGIC"],
                "description": "The nature of the event that initiated this action or cascade."
            },
            "source_details": {
                "type": ["string", "object"],
                "description": "Details of the source, e.g., user prompt text, modified file path, originating signal_id or agent_id."
            }
        },
        "required": ["type"]
    },
    "cascade_instance_id": {
      "type": ["string", "null"],
      "description": "Unique identifier for the specific instance of an executed cascade. All events within the same cascade run share this ID."
    },
    "cascade_profile_id_executed": {
      "type": ["string", "null"],
      "description": "The profile_id from agent_cascade_definitions.mdc that was executed."
    },
    "cascade_step_index": {
        "type": ["integer", "null"],
        "minimum": 0,
        "description": "0-based index of the step within a cascade, if applicable."
    },
    "agent_id": {
      "type": "string",
      "description": "ID of the agent performing or primarily involved in the action."
    },
    "agent_action": {
      "type": "string",
      "description": "A descriptive name for the specific action or sub-task the agent performed (e.g., 'parse_api_schema', 'generate_python_code', 'validate_protocol_compliance')."
    },
    "input_context": {
      "type": ["object", "null"],
      "description": "Key input data or contextual parameters provided to the agent for this action. (Sanitize sensitive info)."
    },
    "output_result": {
      "type": ["object", "null"],
      "description": "Key output data or results produced by the agent for this action. (Sanitize sensitive info)."
    },
    "status": {
      "type": "string",
      "enum": ["SUCCESS", "FAILURE", "ERROR_UNHANDLED", "IN_PROGRESS", "PENDING_USER_INPUT", "SKIPPED_CONDITION_NOT_MET", "WARNING_FALLBACK_USED"],
      "description": "Outcome status of the action."
    },
    "duration_ms": {
      "type": ["number", "null"],
      "description": "Duration of the action in milliseconds."
    },
    "error_info": {
      "type": ["object", "null"],
      "properties": {
        "error_code": {"type": "string"},
        "message": {"type": "string"},
        "type": {"type": "string", "description": "e.g., Python exception type"},
        "is_recoverable": {"type": "boolean"}
      },
      "description": "Details of any error encountered. Stack traces should be logged separately in operational logs if needed, not usually here."
    },
    "confidence_score": {
      "type": ["number", "null"],
      "minimum": 0,
      "maximum": 1,
      "description": "Agent's confidence in its action or output, if applicable."
    },
    "rl_signals_observed": {
      "type": "object",
      "properties": {
        "user_feedback_positive": {"type": ["boolean", "null"], "description": "Explicit positive feedback from user, e.g., accepted suggestion."},
        "user_feedback_negative": {"type": ["boolean", "null"], "description": "Explicit negative feedback, e.g., rejected suggestion, correction provided."},
        "user_correction_details": {"type": ["string", "object", "null"], "description": "Details of user correction, if any."},
        "implicit_reward_metric": {"type": ["number", "null"], "description": "System-calculated reward based on outcome (e.g., test pass rate, task completion)."},
        "goal_achieved": {"type": ["boolean", "null"], "description": "Was the intended goal of this action/cascade achieved?"}
      },
      "description": "Feedback signals relevant for reinforcement learning."
    },
    "tags": {
        "type": ["array", "null"],
        "items": {"type": "string"},
        "description": "Descriptive tags for querying and categorization (e.g., 'api_generation', 'critical_error', 'user_test_phase')."
    },
    "metadata_custom": {
      "type": ["object", "null"],
      "description": "Any other agent-specific or action-specific relevant metadata not covered above."
    }
  },
  "required": [
    "event_id",
    "timestamp_iso",
    "agent_id",
    "agent_action",
    "status"
  ]
} 

---

## agent_cascade_definitions

<!-- Source: .cursor\rules\agent_cascade_definitions.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Agent Configuration / Orchestration Logic
# FILE PATTERNS: N/A (Loaded by system)

# Agent Cascade Definitions

## Principle:
# This document defines reusable "cascade profiles" that orchestrate sequences of agents
# triggered by specific conditions or by other agents. It enables the
# "Domino Agentic Execution Pattern."

# --- SCHEMA FOR CASCADE PROFILES ---
#
# profiles:
#   - profile_id: unique_string_identifier (e.g., "protocol_layer_change_cascade")
#     description: "Human-readable description of what this cascade does."
#     trigger_type: "AUTO_ON_CONDITION" | "AGENT_INITIATED" | "USER_CONFIRMED_WHISPER"
#     trigger_conditions: [] # See detailed examples below
#     parameters_expected: [] # For AGENT_INITIATED
#     agent_sequence: [] # Sequence of agent_id, input_mapping, on_success, on_failure, etc.
#     whisper_mode_details: {} # For USER_CONFIRMED_WHISPER
#     error_handling_cascade_profile_id: "string"
#     logging_level: "VERBOSE" | "STANDARD" | "MINIMAL"

# --- EXAMPLE CASCADE PROFILES ---
profiles:
  # --- Profile ID: core_protocol_modification_cascade (from previous discussion) ---
  - profile_id: "core_protocol_modification_cascade"
    description: "Full validation, RL labeling, and testing for critical protocol/trigger engine changes."
    trigger_type: "AGENT_INITIATED"
    parameters_expected:
      - name: "modified_files"
        type: "list[string]"
        required: true
      - name: "change_summary"
        type: "string"
        required: true
      - name: "initiating_agent_id"
        type: "string"
        required: true
    agent_sequence:
      - agent_id: "protocol_validator_agent"
        input_mapping:
          files_to_validate: "{{trigger.parameters.modified_files}}"
          validation_ruleset: "strict_protocol_rules"
        on_failure: "LOG_AND_HALT"
      - agent_id: "rl_label_agent"
        input_mapping:
          files_for_labeling: "{{trigger.parameters.modified_files}}"
          change_description: "{{trigger.parameters.change_summary}}"
          source_agent: "{{trigger.parameters.initiating_agent_id}}"
        on_failure: "LOG_AND_PROCEED"
      - agent_id: "testing_agent"
        input_mapping:
          test_scope: "integration"
          specific_files_to_target: "{{trigger.parameters.modified_files}}"
        on_failure: "LOG_AND_TRIGGER_CASCADE_PROFILE"
        on_failure_cascade_profile_id: "test_failure_investigation_cascade"
    logging_level: "VERBOSE"

  # --- Profile ID: agent_contract_change_validation_cascade (NEW) ---
  - profile_id: "agent_contract_change_validation_cascade"
    description: "Validates and documents changes related to core VANTA agent contracts (e.g., if agent_base.py or 101-vanta-agent-contract.mdc is modified)."
    trigger_type: "AUTO_ON_CONDITION"
    trigger_conditions:
      - condition_type: "FILE_MODIFICATION"
        details:
          file_patterns: [".cursor/rules/101-vanta-agent-contract.mdc"]
      - condition_type: "USER_INTENT_MATCH"
        details:
          intents: ["modify_agent_base", "update_agent_lifecycle", "refactor_core_agent_interface"]
    agent_sequence:
      - agent_id: "impact_analyzer_agent"
        input_mapping:
          changed_contract_rule_file: ".cursor/rules/101-vanta-agent-contract.mdc"
          original_prompt_for_change: "{{trigger.user_prompt || 'System detected change to agent contract rule.'}}"
        on_failure: "LOG_AND_HALT"
      - agent_id: "dev_documentation_agent"
        input_mapping:
          files_to_document_changes_for: [".cursor/rules/101-vanta-agent-contract.mdc", "conceptual_link_to_agent_base.py_docs"]
          change_summary: "{{impact_analyzer_agent.output.summary_of_impact}}"
          related_rules_to_cross_reference: ["501-vanta-memory-principles.mdc", "920-agent-resource-conventions.mdc", "201-vanta-logging-core-requirements.mdc"]
        on_failure: "LOG_AND_PROCEED"
      - agent_id: "rl_label_agent"
        input_mapping:
          architectural_event_description: "Agent contract modification (see {{impact_analyzer_agent.output.summary_of_impact}})"
          related_files: [".cursor/rules/101-vanta-agent-contract.mdc"]
          significance_level: "HIGH"
    logging_level: "VERBOSE"

  # --- Profile ID: general_code_commit_whisper_cascade (from previous discussion) ---
  - profile_id: "general_code_commit_whisper_cascade"
    description: "Suggests basic validation and RL labeling for general code changes."
    trigger_type: "USER_CONFIRMED_WHISPER"
    trigger_conditions:
      - condition_type: "FILE_MODIFICATION"
        details:
          file_patterns: ["**/*.py", "**/*.ts"]
    parameters_expected:
      - name: "modified_files_count"
        type: "integer"
        required: true
      - name: "primary_changed_module"
        type: "string"
        required: false
      - name: "modified_files_list"
        type: "list[string]"
        required: true # Added required for whisper to pass on
    agent_sequence:
      - agent_id: "rl_label_agent"
        input_mapping:
          files_for_labeling: "{{trigger.parameters.modified_files_list}}"
      - agent_id: "linting_and_static_analysis_agent"
        input_mapping:
          files_to_scan: "{{trigger.parameters.modified_files_list}}"
    whisper_mode_details:
      suggestion_prompt_template: "Detected {{trigger.parameters.modified_files_count}} code file(s) changed (e.g., in '{{trigger.parameters.primary_changed_module}}'). Would you like to run the 'general_code_commit_whisper_cascade' for quick labeling and static analysis?"
      default_action: "REJECT"
    logging_level: "STANDARD"

  # --- Profile ID: test_failure_investigation_cascade (from previous discussion) ---
  - profile_id: "test_failure_investigation_cascade"
    description: "Gathers context and attempts to diagnose test failures."
    trigger_type: "AGENT_INITIATED"
    parameters_expected:
      - name: "failed_test_reports"
        type: "object"
        required: true
      - name: "related_code_files"
        type: "list[string]"
        required: true
    agent_sequence:
      - agent_id: "log_analysis_agent"
        input_mapping:
          test_failure_context: "{{trigger.parameters.failed_test_reports}}"
      - agent_id: "code_context_gatherer_agent"
        input_mapping:
          files_of_interest: "{{trigger.parameters.related_code_files}}"
          failed_test_details: "{{trigger.parameters.failed_test_reports}}"
      - agent_id: "expert_coder"
        input_mapping:
          task_description: "Analyze test failures (see context) and suggest fixes or root cause."
          target_files: "{{trigger.parameters.related_code_files}}"
          error_context_from_logs: "{{log_analysis_agent.output.summary}}"
          code_context: "{{code_context_gatherer_agent.output.full_context}}"
    logging_level: "VERBOSE"

# --- VANTA! CODER SPECIFIC PROFILES --- #
  - profile_id: vanta_coder_major_edit
    description: "Cascade triggered after Vanta! Coder completes a major edit, feature, or architectural change."
    trigger_event_schema: # Defines expected keys in the trigger payload
      type: object
      properties:
        modified_files:
          type: array
          items: { type: string }
        change_summary:
          type: string
        agent_id_completed: # Agent that finished
          type: string 
      required: [modified_files, change_summary, agent_id_completed]
    
    agent_sequence:
      - agent_id: "validation_agent" # Conceptual
        input_mapping:
          files_to_validate: "{{ trigger.parameters.modified_files }}"
          validation_context: "post_vanta_coder_edit"
        on_failure: "LOG_AND_PROCEED" # Don't halt cascade if validation fails, just log
        
      - agent_id: "rl_label_agent" # Conceptual
        input_mapping:
          completed_action_log_ref: "{{ steps[0].output.validation_log_ref || trigger.parameters.change_summary }}" # Use validation log or summary
          agent_involved: "{{ trigger.parameters.agent_id_completed }}"
          code_context: "{{ steps[0].output.validated_code_snippets || 'N/A' }}"
          task_intent: "vanta_coder_major_edit_completion"
        on_failure: "LOG_AND_PROCEED"
        
      - agent_id: "protocol_consistency_agent" # Conceptual
        input_mapping:
          files_to_check: "{{ trigger.parameters.modified_files }}"
          relevant_protocols: ["api_standards", "logging_core"]
        on_failure: "LOG_AND_PROCEED"
        
      - agent_id: "testing_agent" # Conceptual
        input_mapping:
          test_scope: "integration"
          focus_areas: "{{ trigger.parameters.modified_files }}"
          triggering_change: "{{ trigger.parameters.change_summary }}"
        on_failure: "LOG_AND_PROCEED"
        
    # Add other steps as needed
    
    # Note: Assumes agents like validation_agent, rl_label_agent, etc., exist.
    #       The input_mapping uses Jinja2/asteval style placeholders.

# --- RITUAL INVOCATION CASCADE --- #
  - profile_id: ritual_invocation_submitted_cascade
    description: "Handles post-submission tasks after a ritual is invoked via the API."
    trigger_event_schema: # Matches payload sent by API
      type: object
      properties:
        ritual_id:
          type: string
        invocation_id:
          type: string
        parameters:
          type: object
        status:
          type: string # e.g., "SUCCESS", "FAILURE"
        result:
          type: object # Ritual execution result or error info
        timestamp:
          type: string
          format: date-time
      required: [ritual_id, invocation_id, parameters, status, result, timestamp]
    agent_sequence:
      - agent_id: "detailed_event_logger_agent" # This agent was conceptualized and created
        input_mapping:
          event_type: "RITUAL_INVOCATION_COMPLETED"
          event_data: "{{ trigger.parameters }}" # The whole payload
          severity: "{{ 'INFO' if trigger.parameters.status == 'SUCCESS' else 'ERROR' }}"
        on_failure: "LOG_ONLY" # Critical that this logging step itself doesn't halt everything
      # Potentially add more agents here, e.g., a notification agent or an RL agent for ritual success/failure
    logging_level: "STANDARD"

# --- SYSTEM LAYER INCOHERENCE CASCADE --- #
  - profile_id: "system_incoherence_detected_cascade"
    description: "Orchestrates actions when System Layer Incoherence (SLI) is detected by the IncoherenceDetectionAgent."
    trigger_type: "AGENT_INITIATED" # Triggered by IncoherenceDetectionAgent via MCP signal
    trigger_event_schema:
      type: "object"
      properties:
        findings:
          type: "array"
          items:
            type: "object"
            properties:
              type: { type: "string" } # e.g., "repeated_edit_failure", "checksum_mismatch"
              file: { type: "string" }
              description: { type: "string" }
              log_evidence: { type: "array", items: { type: "string" } }
            required: ["type", "file", "description"]
        resolution_protocol_version:
          type: "string" # e.g., "006_v1" referring to the MDC rule version
      required: ["findings", "resolution_protocol_version"]
    agent_sequence:
      - agent_id: "detailed_event_logger_agent"
        input_mapping:
          event_type: "SYSTEM_INCOHERENCE_DETECTED"
          event_data: "{{ trigger.parameters.findings }}"
          severity: "WARNING"
          metadata:
            protocol_version: "{{ trigger.parameters.resolution_protocol_version }}"
        on_failure: "LOG_ONLY"
      - agent_id: "user_notification_agent" # Conceptual agent
        input_mapping:
          message_type: "SLI_WARNING"
          title: "System Layer Incoherence Detected"
          details: "{{ trigger.parameters.findings }}"
          suggested_actions: [
            "Review findings and logs.",
            "Consider manual file inspection using 'mcp_desktop-commander_read_file'.",
            "If a known good version exists, consider 'mcp_desktop-commander_write_file' after backup."
          ]
        on_failure: "LOG_AND_PROCEED"
      # Add more agents for advanced resolution if developed, e.g.:
      # - agent_id: "system_integrity_repair_agent"
      #   input_mapping: { findings: "{{ trigger.parameters.findings }}" }
      #   on_failure: "ESCALATE_TO_COE_REVIEW"
    error_handling_cascade_profile_id: "sli_cascade_failure_handler" # Conceptual
    logging_level: "VERBOSE"

  # --- Profile ID: dataset_creation_domino_cascade (NEW) ---
  - profile_id: "dataset_creation_domino_cascade"
    description: "Handles post-dataset creation tasks like schema validation, project linking, lineage update, event emission, and auto-tagging."
    trigger_type: "AGENT_INITIATED" # Expected to be triggered by an MCP signal after successful dataset registration
    parameters_expected:
      - name: "dataset_id"
        type: "string"
        required: true
        description: "The ID of the newly created/updated dataset."
      - name: "dataset_name"
        type: "string"
        required: true
        description: "Name of the dataset."
      - name: "dataset_description"
        type: "string"
        required: false
        description: "Description of the dataset."
      - name: "schema_id" # This is the schema_id stored *with* the dataset record
        type: "string"
        required: false # A dataset might not have a schema initially
        description: "The schema ID associated with the dataset, if any."
      - name: "project_id" # Conceptual: This field would need to be part of your Dataset model/metadata
        type: "string"
        required: false # A dataset might not be linked to a project
        description: "The project ID to link this dataset to."
      - name: "tags_from_metadata" # Conceptual: Tags extracted during registration process
        type: "list[string]"
        required: false
        description: "Initial list of tags derived from dataset metadata by registration process."

    agent_sequence:
      - name: "Step 1: Validate Schema Reference"
        agent_id: "schema_validator_agent" # Placeholder agent ID
        input_mapping:
          dataset_id_to_validate: "{{ trigger.parameters.dataset_id }}"
          expected_schema_id: "{{ trigger.parameters.schema_id }}"
        on_failure: "LOG_AND_PROCEED" # Decide if failure here should halt the cascade or just log
        description: "Confirms schemaId (if provided) exists and optionally validates dataset conformance."

      - name: "Step 2: Link to Project"
        agent_id: "project_linker_agent" # Placeholder agent ID
        input_mapping:
          dataset_id_to_link: "{{ trigger.parameters.dataset_id }}"
          project_id_target: "{{ trigger.parameters.project_id }}"
        condition: "{{ trigger.parameters.project_id is not none }}" # Only run if project_id is provided
        on_failure: "LOG_AND_PROCEED"
        description: "Ensures projectId is valid and links dataset under that project."

      - name: "Step 3: Update Data Lineage"
        agent_id: "lineage_updater_agent" # Placeholder agent ID
        input_mapping:
          newly_created_dataset_id: "{{ trigger.parameters.dataset_id }}"
          dataset_name: "{{ trigger.parameters.dataset_name }}"
          # Potentially pass source information if available in dataset metadata
        on_failure: "LOG_AND_PROCEED"
        description: "Logs lineage graph connection (source, derivation, transforms)."

      - name: "Step 4: Emit Agentic Event"
        mcp_signal: # Using the mcp_signal action type
          signal_type: "BROADCAST_EVENT" # Or a more specific custom signal type
          target_entity:
            type: "BROADCAST_CHANNEL"
            id: "DATA_CATALOG_UPDATES" # Conceptual broadcast channel
          payload:
            event_type: "NEW_DATASET_REGISTERED"
            dataset_id: "{{ trigger.parameters.dataset_id }}"
            dataset_name: "{{ trigger.parameters.dataset_name }}"
            timestamp_iso: "{{ now_iso() }}" # Assuming a helper function or context variable for current time
            details: "Dataset {{ trigger.parameters.dataset_name }} (ID: {{ trigger.parameters.dataset_id }}) successfully registered."
          priority: 3
        description: "Pushes signal to VANTA agents about the new dataset."

      - name: "Step 5: Auto-tag Dataset"
        agent_id: "metadata_tagger_agent" # Placeholder agent ID
        input_mapping:
          dataset_id_for_tagging: "{{ trigger.parameters.dataset_id }}"
          text_for_nlp_tagging: "Name: {{ trigger.parameters.dataset_name }}. Description: {{ trigger.parameters.dataset_description }}"
          existing_tags: "{{ trigger.parameters.tags_from_metadata }}"
        on_failure: "LOG_AND_PROCEED"
        description: "NLP-driven tag suggestion/application from dataset name + description."

    logging_level: "STANDARD"

# --- SIMPLE TEST CASCADE --- #
- profile_id: "simple_test_cascade"
  description: "A simple cascade for testing executor functionality: Log -> TestAgent -> Log."
  trigger_type: "AGENT_INITIATED"
  parameters_expected:
    - name: "initial_message"
      type: "string"
      required: false
      default: "Cascade initiated"
    - name: "test_agent_param"
      type: "string"
      required: false
      default: "Test Agent Data"

  agent_sequence:
    - name: "Log Start"
      agent: "debug_logger_agent" 
      task_data:
        message: "{{ step_results.initial_data.initial_message }} - Step 1: Logging start of simple_test_cascade"
        level: "INFO"
      on_failure: "LOG_AND_HALT"

    - name: "Call Test Agent"
      agent: "test_processing_agent"
      task_data:
        input_data: "{{ step_results.initial_data.test_agent_param }}"
        previous_step_output: "{{ step_results.step_1_output.logged_message || 'No output from logger' }}"
      on_failure: "LOG_AND_HALT"

    - name: "Log End"
      agent: "debug_logger_agent"
      task_data:
        message: "Step 3: Logging end of simple_test_cascade. Test Agent output: {{ step_results.step_2_output.result_summary || 'No output from test_agent' }}"
        level: "INFO"
      on_failure: "LOG_AND_PROCEED"
  logging_level: "VERBOSE"

# --- END OF PROFILES --- #
# Ensure this file ends with a newline if more profiles are added below manually







---

## api-routes

<!-- Source: .cursor\rules\api-routes.mdc -->
<!-- Format: mdc -->

---
description: Guidelines for implementing Next.js API routes
globs: app/api/*, api/*.ts, lib/api/routes/*.ts
type: autoAttached
---
# API Routes Guidelines

## Next.js App Router
- Use the `route.ts` convention for Route Handlers
- Implement handlers for HTTP methods (GET, POST, etc.)
- Add appropriate type checking for request/response bodies
- Use consistent error handling

## Request Validation
- Validate request parameters and body using Zod
- Return appropriate HTTP status codes for validation errors
- Document expected request formats

## Error Handling
- Use try/catch blocks to handle errors
- Return standardized error responses
- Log errors with appropriate level and context
- Include helpful error messages for debugging
- See **@300-error-handling.mdc** for detailed error handling patterns

## Authentication
- Implement authentication middleware for protected routes
- Verify user permissions for sensitive operations
- Use appropriate session management
- Document authentication requirements

## Response Formatting
- Return consistent JSON response structures
- Set appropriate headers (Content-Type, Cache-Control, etc.)
- Include proper HTTP status codes
- Implement pagination for list endpoints

## Database Integration
- Use Prisma for database operations
- Implement proper error handling for database queries
- Use transactions for operations that modify multiple tables
- For database access guidelines, see **@prisma.mdc**

## Related MDC Rules
- **@prisma.mdc**: For database access patterns and schema
- **@logging.mdc**: For logging standards in API routes
- **@data-fetching.mdc**: For client-side data fetching from these routes
- **@300-error-handling.mdc**: For error handling patterns
- **@server-actions.mdc**: For server action alternatives to API routes

## Example Implementation

```typescript
// app/api/users/[id]/route.ts
import { NextResponse } from 'next/server';
import { z } from 'zod';
import { prisma } from '@/lib/db';
import { auth } from '@/lib/auth';

// Parameter validation schema
const paramsSchema = z.object({
  id: z.string().uuid(),
});

export async function GET(
  request: Request,
  { params }: { params: { id: string } }
) {
  try {
    // Validate parameters
    const result = paramsSchema.safeParse({ id: params.id });
    if (!result.success) {
      return NextResponse.json(
        { error: 'Invalid user ID format' },
        { status: 400 }
      );
    }

    // Authentication check
    const session = await auth();
    if (!session) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      );
    }

    // Fetch data
    const user = await prisma.user.findUnique({
      where: { id: params.id },
      select: {
        id: true,
        name: true,
        email: true,
        createdAt: true,
        // Don't include sensitive fields
      },
    });

    if (!user) {
      return NextResponse.json(
        { error: 'User not found' },
        { status: 404 }
      );
    }

    // Return successful response
    return NextResponse.json({ data: user });
  } catch (error) {
    console.error('Error fetching user:', error);
    return NextResponse.json(
      { error: 'Failed to fetch user' },
      { status: 500 }
    );
  }
}
```

## Standard Format

Use this format for API routes:

```ts
import { z } from "zod";
import { NextResponse } from "next/server";
import { auth } from "@/app/api/auth/[...nextauth]/auth";
import prisma from "@/utils/prisma";
import { withError } from "@/utils/middleware";

const apiNameBody = z.object({ id: z.string(), message: z.string() });
export type ApiNameBody = z.infer<typeof apiNameBody>;
export type UpdateApiNameResponse = Awaited<ReturnType<typeof updateApiName>>;

async function updateApiName(body: ApiNameBody, options: { email: string }) {
  const { email } = options;
  const result = await prisma.table.update({
    where: {
      id: body.id,
      email,
    },
    data: body,
  });

  return { result };
}

// For routes without params
export const POST = withError(async (request: Request) => {
  const session = await auth();
  if (!session?.user.email)
    return NextResponse.json({ error: "Not authenticated" });

  const json = await request.json();
  const body = apiNameBody.parse(json);

  const result = await updateApiName(body, { email: session.user.email });

  return NextResponse.json(result);
});

// For routes with params (note the params promise which is how Next.js 15+ works)
export const GET = withError(
  async (
    request: Request,
    { params }: { params: Promise<{ slug: string }> }
  ) => {
    const session = await auth();
    if (!session?.user.email)
      return NextResponse.json({ error: "Not authenticated" });

    const { slug } = await params;
    // Use the slug parameter...

    return NextResponse.json({ result });
  }
);
```

## Implementation Guidelines

- Use Zod for request body validation
- Create separate functions for business logic
- Wrap route handlers with error handling middleware
- Always validate authentication with `auth()`
- Export typed responses for client usage
- For routes with dynamic parameters, use the Next.js 15+ params format


---

## auto_attach_package_json

<!-- Source: .cursor\rules\auto_attach_package_json.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
profiles:
  - profile_id: auto_attach_package_json
    description: Trigger on package.json changes
    trigger_type: FILE_SAVED # This is a conceptual trigger, actual execution depends on system capabilities
    steps:
      - name: HandlePackageJson
        agent: pattern_matcher_agent # Conceptual agent
        task_data:
          patterns:
            - "package.json"
            - "**/package.json"


---

## cleaner

<!-- Source: .cursor\rules\cleaner.mdc -->
<!-- Format: mdc -->

---
description: Code cleanup and maintenance guidelines
globs: **/*.ts, **/*.tsx, **/*.js, **/*.jsx
type: autoAttached
---
# Code Cleanup Guidelines

## General Principles
- Keep code DRY (Don't Repeat Yourself)
- Follow SOLID principles for OOP
- Use meaningful variable and function names
- Remove commented-out code
- Delete unused imports

## Formatting
- Use consistent indentation (2 spaces)
- Follow line length guidelines (max 80 characters)
- Use consistent spacing around operators
- Keep line breaks consistent
- Group related code blocks

## Dead Code Removal
- Remove unused variables
- Delete unused functions and classes
- Clean up commented-out code blocks
- Remove console.log statements in production
- Delete duplicate code

## Import Optimization
- Group imports by type (React, third-party, local)
- Remove unused imports
- Use specific imports rather than importing entire modules
- Sort imports alphabetically

## Type Management
- Use explicit types rather than 'any' when possible
- Remove redundant type annotations
- Simplify complex type definitions
- Use consistent naming for interfaces and types

## Component Cleanup
- Remove unused props
- Simplify component logic
- Extract repeated JSX into separate components
- Remove unnecessary state variables
- Use proper memoization

## Documentation
- Update comments to match code changes
- Remove misleading or outdated comments
- Document complex algorithms and business logic
- Ensure JSDoc comments are accurate and complete

## Code Quality
- Remove unused code
- Fix linting issues
- Update dependencies
- Optimize imports

## Testing
- Fix broken tests
- Add missing tests
- Update test data
- Remove obsolete tests

## Performance
- Remove bottlenecks
- Optimize queries
- Clean up memory leaks
- Remove redundant code

## Maintenance
- Update dependencies
- Fix security issues
- Remove deprecated code
- Update configurations

## Inbox Cleaner

The inbox cleaner helps users do a deep clean of their inbox.
It helps them get from 10,000 items in their inbox to only a few.
It works by archiving/marking read low priority emails.
It uses a combination of static and AI rules to do the clean up.
It uses both Postgres (Prisma) and Redis.
We store short term memory in Redis that expires after a few hours. This is data like email subject so we can quickly show it to the user, but this isn't data we want stored long term to enhance privacy for the user while balancing this with a faster experience.
Once the cleaning process has started we show the emails streamed in with the action taken on the email (archive/keep).

The main files and directories for this are:

- apps/web/utils/actions/clean.ts
- apps/web/app/api/clean/
- apps/web/app/(app)/clean/page.tsx
- apps/web/app/(app)/clean/
- apps/web/prisma/schema.prisma
- apps/web/utils/redis/clean.ts

The database models to look at are:

- CleanupThread
- CleanupJob


---

## cursor-rules

<!-- Source: .cursor\rules\cursor-rules.mdc -->
<!-- Format: mdc -->

---
description: Guidelines for creating and managing Cursor MDC rules
globs: .mdc, .cursor/rules/.mdc
type: manual
---

# RULE TYPE: Manual
# FILE PATTERNS: .mdc, .cursor/rules/.mdc

# Cursor Rules Management

## Rule File Format

All MDC rule files should follow this format:

```markdown
---
description: Brief description of the rule's purpose
globs: file-pattern-1.ts, file-pattern-2.tsx, folder-name/
type: autoAttached|always|agentRequested|manual
---

# RULE TYPE: [Auto Attached|Always|Agent Requested|Manual]
# FILE PATTERNS: [Comma-separated list of file patterns]

# Rule Title

## Section 1
- Guideline 1
- Guideline 2
- Guideline 3

## Section 2
- Guideline 4
- Guideline 5

## Examples
```[language]
// Example code
```
```

## Rule Types

- **autoAttached**: Rule is automatically attached when files matching glob patterns are referenced
- **always**: Rule is always attached regardless of context
- **agentRequested**: Rule is available for agent to request as needed
- **manual**: Rule is only attached when manually referenced

## File Organization

- Core application rules: `000-[name].mdc`
- Component rules: `100-[name].mdc`
- Design pattern rules: `200-[name].mdc`
- Error handling rules: `300-[name].mdc`
- ADHD-related rules: `400-[name].mdc`
- Database rules: `500-[name].mdc`
- Learning rules: `600-[name].mdc`
- External/reference rules: `700-[name].mdc`
- Agent/configuration rules: `900-[name].mdc`

## Creating New Rules

1. Use the template file at `.cursor/rules/template.mdc`
2. Choose appropriate naming convention using the numbering scheme above
3. Define clear, specific glob patterns to match relevant files
4. Select the appropriate rule type
5. Organize content with clear sections and examples
6. Include code examples where relevant

## Rule Content Guidelines

- Keep rules focused on a single concern or pattern
- Use bullet points for clarity and readability
- Include both "do" and "don't" examples
- Provide code snippets for complex guidelines
- Explain the reasoning behind guidelines
- Cross-reference related rules when needed

## Testing Rules

When creating or updating rules:

1. Test glob patterns to ensure they match intended files
2. Verify rule appears in context for target files
3. Check that rule suggestions are applied correctly
4. Test with variations of file types and content

## Updating Rules

When updating existing rules:

1. Preserve the rule's core purpose and identity
2. Add new sections at the end for better diff tracking
3. Document significant changes in commits
4. Update glob patterns as file organization evolves
5. Review and update examples to match current codebase

## Index Management

The `.cursor/rules/index.mdc` file should:

1. List all available rules with brief descriptions
2. Group rules by category and purpose
3. Include information on when to use each rule
4. Provide guidance on rule combinations

## Referencing in Requests

When referencing rules in Cursor AI requests:

```
@index.mdc @000-base.mdc
Phase: [Analyze/Blueprint/Construct/Validate/Learn]
Energy: [High/Medium/Low]
Additional References: [rule-name.mdc]

[Your specific request]

---

## cursor

<!-- Source: .cursor\rules\cursor.mdc -->
<!-- Format: mdc -->

---
description: Cursor IDE configuration and usage guidelines
globs: .vscode, .cursor
alwaysApply: false
---

# RULE TYPE: Manual
# FILE PATTERNS: .vscode, .cursor

# Cursor IDE Configuration

## Setup

- Install Cursor from [cursor.sh](mdc:https:/cursor.sh)
- Configure with proper extensions
- Set up MDC rules in `.cursor/rules/`
- Configure user settings as needed

## Keyboard Shortcuts

- `Cmd+K`: Chat with AI assistant
- `Cmd+L`: Generate code from comment
- `Cmd+Shift+L`: Edit selected code with AI
- `Ctrl+G`: Go to line

## MDC Rules Integration

- Rules are stored in `.cursor/rules/`
- Rules follow specific naming conventions
- Use `@rule-name.mdc` to reference rules in chat
- Configure rule types for appropriate auto-loading

## Chat Best Practices

- Be specific in your requests
- Reference relevant files directly
- Include appropriate MDC rules as context
- Use code blocks for multi-line code examples

## Code Generation

- Add clear comments before generating code
- Verify generated code for correctness
- Test generated code thoroughly
- Adapt generated code to follow project patterns

## Configuration Files

- `.cursor/settings.json`: IDE settings
- `.cursor/rules/`: MDC rules storage
- `.cursor/references/`: Reference documentation
- `.vscode/launch.json`: Debugging configurations

## Extension Integration

- Cursor supports VS Code extensions
- Install extensions via command palette
- Configure extension settings as needed
- Verify extension compatibility


---

## data-fetching

<!-- Source: .cursor\rules\data-fetching.mdc -->
<!-- Format: mdc -->

---
description: Fetching data from the API using SWR
globs: hooks/use*.ts, lib/api/*.ts, components/*Data*.tsx
alwaysApply: false
---
# Data Fetching Guidelines

## SWR Setup
- Use SWR for client-side data fetching
- Create custom hooks for reusable data fetching
- Implement proper loading and error states
- Use appropriate cache configurations

## API Structure
- Create typed API functions in `lib/api/`
- Use consistent error handling patterns
- Implement proper request validation
- Return well-structured response objects

## Error Handling
- Handle fetch errors gracefully
- Provide fallback UI for error states
- Implement retry mechanisms where appropriate
- Log errors for debugging
- For comprehensive error handling, see **@300-error-handling.mdc**

## Loading States
- Show appropriate loading indicators
- Implement skeleton loaders for better UX
- Use optimistic UI updates when possible
- For UI component guidelines, see **@ui-components.mdc**

## Related MDC Rules
- **@api-routes.mdc**: For creating API routes to fetch from
- **@ui-components.mdc**: For UI components that display fetched data
- **@300-error-handling.mdc**: For error handling patterns
- **@logging.mdc**: For logging data fetching operations
- **@testing.mdc**: For testing data fetching hooks

## Best Practices
- Fetch data at the highest necessary component level
- Implement proper loading UI components
- Add error handling with fallbacks
- Use optimistic updates for mutations

## Example Implementation
```typescript
// Data fetching hook with SWR
import useSWR from 'swr';
import { fetchUser } from '@/lib/api/user';

export function useUser(id: string) {
  const { data, error, isLoading, mutate } = useSWR(
    id ? `/api/users/${id}` : null,
    () => fetchUser(id),
    {
      revalidateOnFocus: false,
      dedupingInterval: 60000, // 1 minute
    }
  );

  return {
    user: data,
    isLoading,
    isError: error,
    mutate,
  };
}
```

## Server Components
When using Next.js Server Components, consider these alternatives:
- Fetch data directly in Server Components
- Pass data down to Client Components
- Use React Cache for server-side data fetching
- For page structure guidelines, see **@page-structure.mdc** 

---

## environment-variables

<!-- Source: .cursor\rules\environment-variables.mdc -->
<!-- Format: mdc -->

---
description: Add environment variable
globs: .env*, next.config.js, config/*.ts
alwaysApply: false
---
# RULE TYPE: Agent Requested
# FILE PATTERNS: .env*, next.config.js, config/*.ts

# Environment Variables

## Structure
- Store environment variables in `.env.local` for local development
- Use `.env.example` as a template with dummy values
- Define types for environment variables
- Validate environment variables on application startup

## Usage
- Access environment variables through a centralized config file
- Use `process.env` only in the config file, not throughout the application
- Add validation for required environment variables
- Document the purpose of each environment variable

## Naming Convention
- Use uppercase with underscores (e.g., `DATABASE_URL`)
- Group related variables with common prefixes (e.g., `AUTH_SECRET`, `AUTH_URL`)
- Use clear, descriptive names that indicate purpose
- Include the environment in variable name when needed (e.g., `NEXT_PUBLIC_API_URL_PROD`)

## Security
- Never commit actual `.env` files to version control
- Use `NEXT_PUBLIC_` prefix only when the variable must be available in the browser
- Store sensitive values in secrets management tools
- Rotate sensitive environment variables regularly

## Example Configuration
```typescript
// config/env.ts
import { z } from 'zod';

const envSchema = z.object({
  // Database
  DATABASE_URL: z.string().url(),
  
  // Authentication
  AUTH_SECRET: z.string().min(16),
  
  // API Keys
  OPENAI_API_KEY: z.string().optional(),
  
  // Public variables
  NEXT_PUBLIC_API_URL: z.string().url(),
});

// Parse and validate environment variables
const env = envSchema.safeParse(process.env);

if (!env.success) {
  console.error(' Invalid environment variables:', env.error.format());
  throw new Error('Invalid environment variables');
}

// Export validated environment variables
export const config = env.data;
```

This is how we add environment variables to the project:

  1. Add to `.env.example`:
      ```bash
      NEW_VARIABLE=value_example
      ```

  2. Add to `apps/web/env.ts`:
      ```typescript
      // For server-only variables
      server: {
        NEW_VARIABLE: z.string(),
      }
      // For client-side variables
      client: {
        NEXT_PUBLIC_NEW_VARIABLE: z.string(),
      }
      experimental__runtimeEnv: {
        NEXT_PUBLIC_NEW_VARIABLE: process.env.NEXT_PUBLIC_NEW_VARIABLE,
      }
      ```

  3. For client-side variables:
      - Must be prefixed with `NEXT_PUBLIC_`
      - Add to both `client` and `experimental__runtimeEnv` sections

  4. Add to `turbo.json` under `globalDependencies`:
      ```json
      {
        "tasks": {
          "build": {
            "env": [
              "NEW_VARIABLE"
            ]
          }
        }
      }
      ```

examples:
  - input: |
      # Adding a server-side API key
      # .env.example
      API_KEY=your_api_key_here

      # env.ts
      server: {
        API_KEY: z.string(),
      }

      # turbo.json
      "build": {
        "env": ["API_KEY"]
      }
    output: "Server-side environment variable properly added"

  - input: |
      # Adding a client-side feature flag
      # .env.example
      NEXT_PUBLIC_FEATURE_ENABLED=false

      # env.ts
      client: {
        NEXT_PUBLIC_FEATURE_ENABLED: z.coerce.boolean().default(false),
      },
      experimental__runtimeEnv: {
        NEXT_PUBLIC_FEATURE_ENABLED: process.env.NEXT_PUBLIC_FEATURE_ENABLED,
      }

      # turbo.json
      "build": {
        "env": ["NEXT_PUBLIC_FEATURE_ENABLED"]
      }
    output: "Client-side environment variable properly added"

references:
  - apps/web/env.ts
  - apps/web/.env.example
  - turbo.json

---

## form-handling

<!-- Source: .cursor\rules\form-handling.mdc -->
<!-- Format: mdc -->

---
description: Form handling
globs: components/forms/.tsx, hooks/useForm*.ts
type: autoAttached
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: components/forms/.tsx, hooks/useForm*.ts

# Form Handling Guidelines

## Form Structure
- Use `react-hook-form` for form state management
- Define form schemas with Zod for validation
- Create reusable form components for common patterns
- Implement proper error handling and display

## Validation
- Define Zod schemas for all forms
- Include appropriate error messages
- Validate on blur and on submit
- Handle server-side validation errors

## Accessibility
- Use proper form semantics (label, fieldset, legend)
- Implement ARIA attributes for form fields
- Ensure keyboard navigation works properly
- Show validation errors in an accessible way
- For further accessibility guidelines, see **@ui-components.mdc**

## Server Integration
- Use server actions for form submission
- Handle loading and success states
- Provide clear error messages
- Implement proper client-side validation
- For server action guidelines, see **@server-actions.mdc**

## Error Handling
- Display validation errors clearly next to form fields
- Handle server-side errors with appropriate UI feedback
- Provide fallback UI for failed submissions
- For detailed error handling, see **@300-error-handling.mdc**

## Related MDC Rules
- **@ui-components.mdc**: For form component styling and UI patterns
- **@server-actions.mdc**: For form submission handling
- **@300-error-handling.mdc**: For error handling patterns
- **@400-adhd-patterns.mdc**: For ADHD-friendly form patterns
- **@api-routes.mdc**: For API-based form submissions

## Example Implementation

```tsx
// Define schema with Zod
const formSchema = z.object({
  name: z.string().min(2, {
    message: "Name must be at least 2 characters.",
  }),
  email: z.string().email({
    message: "Please enter a valid email address.",
  }),
});

// Form component with react-hook-form
export function ContactForm() {
  const form = useForm<z.infer<typeof formSchema>>({
    resolver: zodResolver(formSchema),
    defaultValues: {
      name: "",
      email: "",
    },
  });

  async function onSubmit(values: z.infer<typeof formSchema>) {
    try {
      await submitContactForm(values);
      toast({
        title: "Success",
        description: "Your message has been sent.",
      });
      form.reset();
    } catch (error) {
      toast({
        title: "Error",
        description: "Failed to send your message. Please try again.",
        variant: "destructive",
      });
    }
  }

  return (
    <Form {...form}>
      <form onSubmit={form.handleSubmit(onSubmit)} className="space-y-6">
        <FormField
          control={form.control}
          name="name"
          render={({ field }) => (
            <FormItem>
              <FormLabel>Name</FormLabel>
              <FormControl>
                <Input placeholder="Your name" {...field} />
              </FormControl>
              <FormMessage />
            </FormItem>
          )}
        />
        <FormField
          control={form.control}
          name="email"
          render={({ field }) => (
            <FormItem>
              <FormLabel>Email</FormLabel>
              <FormControl>
                <Input placeholder="email@example.com" {...field} />
              </FormControl>
              <FormMessage />
            </FormItem>
          )}
        />
        <Button type="submit" disabled={form.formState.isSubmitting}>
          {form.formState.isSubmitting ? "Sending..." : "Send Message"}
        </Button>
      </form>
    </Form>
  );
}
```


---

## golden-ratio-visuals

<!-- Source: .cursor\rules\golden-ratio-visuals.mdc -->
<!-- Format: mdc -->

---
description: Guidelines for applying the golden ratio in visual design
globs: 
  - "**/*.css"
  - "**/*.scss"
  - "src/components/**/*.tsx"
  - "src/styles/**/*.ts"
type: bestPractice
---

# Golden Ratio in Visual Design

## Overview
The golden ratio (  1.618) should be applied specifically to visual elements to create harmonious and aesthetically pleasing designs. This rule provides guidelines for using the golden ratio effectively in UI components, layouts, and animations.

## Visual Applications

### Layout Composition
- Use the golden ratio to divide space between primary and secondary content areas
- Apply to parent-child container relationships for visual harmony
- Determine margins and padding based on golden ratio relationships

```tsx
// Good example: Using golden ratio for layout composition
<div className="container">
  <main className="content" style={{ flex: 1.618 }}>
    {/* Primary content */}
  </main>
  <aside className="sidebar" style={{ flex: 1 }}>
    {/* Secondary content */}
  </aside>
</div>
```

### Component Proportions
- Size UI components using golden ratio relationships
- Apply to width/height ratios of cards, panels, and images
- Use for button dimensions and icon sizing

```tsx
// Good example: Card component with golden ratio proportions
<Card 
  className="golden-ratio-card"
  style={{ 
    width: '100%',
    height: `${width / 1.618}px` // Height is width divided by 
  }}
>
  {/* Card content */}
</Card>
```

### Typography
- Set font size relationships using the golden ratio
- Apply to heading hierarchies (h1, h2, h3, etc.)
- Use for line-height calculations

```tsx
// Good example: Typography scale based on golden ratio
const typographyScale = {
  small: '0.75rem',
  base: '1rem',
  large: '1.618rem',
  xlarge: '2.618rem', // 1.618 * 1.618
};
```

### Animation Timing
- Use the golden ratio for animation duration relationships
- Apply to transition timing and sequence durations
- Create smooth, natural-feeling motion sequences

```tsx
// Good example: Animation timing with golden ratio relationships
<motion.div
  animate={{ opacity: 1, y: 0 }}
  initial={{ opacity: 0, y: 20 }}
  transition={{ 
    duration: 0.5,
    staggerChildren: 0.5 / 1.618 // Stagger using golden ratio
  }}
>
  {/* Animated content */}
</motion.div>
```

### Spacing System
- Define a spacing scale based on the golden ratio
- Apply to margins, padding, and gaps between elements
- Use consistent spacing variables throughout the application

```typescript
// Good example: Spacing system based on the golden ratio
export const spacing = {
  xs: '0.5rem',
  sm: '0.809rem',  // 0.5 * 1.618
  md: '1.309rem',  // 0.809 * 1.618
  lg: '2.118rem',  // 1.309 * 1.618
  xl: '3.427rem',  // 2.118 * 1.618
};
```

##  Do Not Apply To

### Non-Visual Logic
Avoid using the golden ratio for:
- Algorithm complexity scoring
- Database query optimization
- Authentication/authorization rules
- Business logic calculations
- Tag suggestion algorithms or content ranking

### Backend Systems
The golden ratio should not be used for:
- API rate limiting
- Server response time targets
- Database connection pool sizing
- Cache invalidation timing
- Request timeout configurations

## Implementation Utility

```typescript
// src/lib/design/goldenRatio.ts
export const PHI = 1.618033988749895;

export const goldenRatio = {
  // Scale a base value by the golden ratio (multiply)
  scale: (value: number, steps = 1): number => {
    return value * Math.pow(PHI, steps);
  },
  
  // Divide a value by the golden ratio
  divide: (value: number, steps = 1): number => {
    return value / Math.pow(PHI, steps);
  },
  
  // Create a golden ratio-based spacing scale
  createScale: (baseValue: number, steps = 5): number[] => {
    return Array.from({ length: steps }).map((_, i) => 
      baseValue * Math.pow(PHI, i)
    );
  },
  
  // Calculate golden section of a length
  section: (length: number): { major: number, minor: number } => {
    const major = length * (PHI - 1) / PHI;
    const minor = length / PHI;
    return { major, minor };
  }
};
```

## Best Practices

1. **Consistency** - Use the golden ratio consistently across similar components
2. **Visual Elements Only** - Apply only to visually perceived elements
3. **No Overengineering** - Don't force the golden ratio where it doesn't naturally fit
4. **Limit Nesting** - Avoid applying the golden ratio recursively more than 2-3 levels deep
5. **Verify Visually** - Always verify that the application of the golden ratio actually improves the design 

---

## index

<!-- Source: .cursor\rules\index.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
---
description: Central index of all MDC rules 
type: always
alwaysApply: true
---

# RULE TYPE: Always
# FILE PATTERNS: Not applicable for Always rules

# InnerCircle MDC Rules Index

This document serves as the central index for all MDC rules in the InnerCircle project. MDC (Markdown Comments) rules provide guidance and standardization for development practices.

##  How to Use MDC Rules

When asking for assistance or writing code, reference relevant MDC rules:

```
@index.mdc @000-base.mdc [+ ADDITIONAL RULES]

Your question or request here...
```

##  Rule Categories

### Core & Architecture (000 & 100 Series)
- [**000-base.mdc**](mdc:VANTA/VANTA/VANTA/000-base.mdc) - Base architectural principles and patterns
- [**002-L1-L2-distinction-and-coevolution.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/002-L1-L2-distinction-and-coevolution.mdc) - Defines L1 (Cursor AI) / L2 (Project) interaction and co-evolution.
- [**003-L1-enforces-L2-scaffolding.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/003-L1-enforces-L2-scaffolding.mdc) - Outlines how L1 rules guide L2 project scaffolding and standards.
- [**004-L1-L2-dependency-check.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/004-L1-L2-dependency-check.mdc) - Ensures L2 project code remains independent of L1/Cursor-specific features.
- [**005-destructive-op-safety.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/005-destructive-op-safety.mdc) - Safety protocol for destructive file operations.
- [**005-L1-general-git-sync-guidelines.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/005-L1-general-git-sync-guidelines.mdc) - L1 guidelines for general Git operations, commit messages, and staging.
- [**006-system-incoherence-protocol.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/006-system-incoherence-protocol.mdc) - Protocol for detecting and resolving system layer incoherence.
- [**007-desktop-commander-best-practices.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/007-desktop-commander-best-practices.mdc) - Best practices for using mcp-desktop-commander tools.
- [**008-backup-and-commit-protocol.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/008-backup-and-commit-protocol.mdc) - Protocol for project backups and git commits.
- [**008-relative-import-preflight.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/008-relative-import-preflight.mdc) - Pre-flight check for relative imports, warns or suggests stubs.
- [**009-L1-promotion-of-L2-framework-rule-index-awareness.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/009-L2-framework-rule-index-awareness.mdc) - Instructs L1 AI to promote awareness and developer use of L2 project-specific rule indexes.
- [**010-mvp-phase-scoping.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/010-mvp-phase-scoping.mdc) - Strategy for prioritizing MVP features in early phases
- [**011-mdc-hygiene-protocol.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/011-mdc-hygiene-protocol.mdc) - Protocol for testing and formatting MDC rules.
- [**012-ai-mdc-authoring-formatting-standards.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/012-ai-mdc-authoring-formatting-standards.mdc) - AI guidelines for authoring and formatting MDC rule files.
- [**013-L1-guides-L2-architecture.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/013-L1-guides-L2-architecture.mdc) - Defines how L1 AI should guide L2 project architecture and component scaffolding.
- [**020-compatibility-check.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/020-compatibility-check.mdc) - Mandates pre-flight checks for core technology stack compatibility.
- [**100-next-components.mdc**](mdc:VANTA/VANTA/VANTA/100-next-components.mdc) - Next.js component standards
- [**100-vanta-coder-overlay.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/100-vanta-coder-overlay.mdc) - Defines the Vanta! Coder agent overlay and principles.
- [**101-vanta-agent-contract.mdc**](mdc:VANTA/VANTA/VANTA/101-vanta-agent-contract.mdc) - Canonical VANTA agent contract and lifecycle principles.
- [**101-event-governance.mdc**](mdc:VANTA/VANTA/.cursor/rules/101-event-governance.mdc) - Governance protocol for the Kernel Event Bus (KEB).
- [**110-feature-parity.mdc**](mdc:VANTA/VANTA/.cursor/rules/110-feature-parity.mdc) - Strategy for maintaining core feature parity across platforms

### UI & Design (100-200 Series)
- [**200-icons.mdc**](mdc:VANTA/VANTA/VANTA/200-icons.mdc) - Icon usage and management
- [**201-vanta-logging-core-requirements.mdc**](mdc:VANTA/VANTA/VANTA/201-vanta-logging-core-requirements.mdc) - Essential logging requirements for VANTA components.
- [**ui-components.mdc**](mdc:VANTA/VANTA/VANTA/ui-components.mdc) - UI component and styling guidelines
- [**golden-ratio-visuals.mdc**](mdc:VANTA/VANTA/VANTA/golden-ratio-visuals.mdc) - Visual design using golden ratio

### Error Handling & Testing (300 Series)
- [**300-error-handling.mdc**](mdc:VANTA/VANTA/VANTA/300-error-handling.mdc) - Error handling guidelines
- [**310-dependency-hygiene.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/310-dependency-hygiene.mdc) - Dependency vulnerability management
- [**311-cross-platform-deps.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/311-cross-platform-deps.mdc) - Cross-platform dependency management guideline
- [**312-static-analysis-checks.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/312-static-analysis-checks.mdc) - Recommend static analysis (lint, type check) configuration.
- [**320-dependency-conflict-resolution-strategy.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/320-dependency-conflict-resolution-strategy.mdc) - Strategy for resolving dependency conflicts.
- [**testing.mdc**](mdc:VANTA/VANTA/VANTA/testing.mdc) - Testing guidelines and practices
- [**llm-test.mdc**](mdc:VANTA/VANTA/VANTA/llm-test.mdc) - LLM testing guidelines

### ADHD Optimization (400 Series)
- [**400-adhd-patterns.mdc**](mdc:VANTA/VANTA/VANTA/400-adhd-patterns.mdc) - ADHD-friendly design patterns
- [**adhd-energy-features.mdc**](mdc:VANTA/VANTA/VANTA/adhd-energy-features.mdc) - Energy-aware UI features

### Data & API (500 Series)
- [**500-prisma.mdc**](mdc:VANTA/VANTA/VANTA/500-prisma.mdc) - Prisma database patterns
- [**501-vanta-memory-principles.mdc**](mdc:VANTA/VANTA/VANTA/501-vanta-memory-principles.mdc) - Canonical principles for VANTA agent memory and RL context.
- [**505-pydantic-schema-design.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/505-pydantic-schema-design.mdc) - Pydantic schema design best practices
- [**prisma.mdc**](mdc:VANTA/VANTA/VANTA/prisma.mdc) - Additional Prisma guidelines
- [**api-routes.mdc**](mdc:VANTA/VANTA/VANTA/api-routes.mdc) - API route implementation guidelines
- [**data-fetching.mdc**](mdc:VANTA/VANTA/VANTA/data-fetching.mdc) - Data fetching with SWR
- [**server-actions.mdc**](mdc:VANTA/VANTA/VANTA/server-actions.mdc) - Next.js server actions

### Documentation, Learning & System Principles (600, 900 Series, Foundational)

- [**600-ai-learnings.mdc**](mdc:VANTA/VANTA/VANTA/600-ai-learnings.mdc) - AI learning documentation
- [**904-core-documentation.mdc**](mdc:VANTA/VANTA/VANTA/904-core-documentation.mdc) - Documentation requirements
- [**904-documentation-index.mdc**](mdc:VANTA/VANTA/VANTA/904-documentation-index.mdc) - Documentation indexing

### External & Open Source (700 Series)
- [**700-opensource-mdc.mdc**](mdc:VANTA/VANTA/VANTA/700-opensource-mdc.mdc) - Open source MDC rules
- [**703-code-source-priority.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/703-code-source-priority.mdc) - Guideline for resolving conflicts between user-provided code and existing AI-managed code state.

### Agent & Automation (900 Series)
- [**900-agent-config.mdc**](mdc:VANTA/VANTA/VANTA/900-agent-config.mdc) - AI agent configuration
- [**auto_attach_package_json.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/auto_attach_package_json.mdc) - Auto-trigger for package.json changes.
- [**901-mdc-agent.mdc**](mdc:VANTA/VANTA/VANTA/901-mdc-agent.mdc) - MDC rules monitoring agent
- [**902-rl-agent.mdc**](mdc:VANTA/VANTA/VANTA/902-rl-agent.mdc) - Reinforcement learning agent
- [**902-visual-asset-linking.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/902-visual-asset-linking.mdc) - Rule for linking visual assets to plans/docs.
- [**903-rl-suggestion.mdc**](mdc:VANTA/VANTA/VANTA/903-rl-suggestion.mdc) - RL suggestion system
- [**904-core-documentation.mdc**](mdc:VANTA/VANTA/VANTA/904-core-documentation.mdc) - Documentation requirements
- [**904-documentation-index.mdc**](mdc:VANTA/VANTA/VANTA/904-documentation-index.mdc) - Documentation indexing
- [**905-orchestrator-agent.mdc**](mdc:VANTA/VANTA/VANTA/905-orchestrator-agent.mdc) - Task orchestration agent
- [**906-documentation-sync.mdc**](mdc:VANTA/VANTA/VANTA/906-documentation-sync.mdc) - Documentation synchronization
- [**906-symbolic-definition-linking.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/906-symbolic-definition-linking.mdc) - Enforces linking definition files (e.g., vanta_agi_definitions.md) to THEPLAN.md.
- [**907-project-snapshot.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/907-project-snapshot.mdc) - Defines project snapshot documentation standards.
- [**907-plan-todo-sync.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/907-plan-todo-sync.mdc) - Suggests reviewing TODO.md after major THEPLAN.md updates.
- [**909-mdc-rule-optimization-protocol.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/909-mdc-rule-optimization-protocol.mdc) - Protocol for MDC Rule Optimizer Agent.
- [**910-vanta-testing-protocol.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/910-vanta-testing-protocol.mdc) - Defines testing standards and required libraries for VANTA Kernel.
- [**910-assistant-autonomy.mdc**](mdc:VANTA/VANTA/VANTA/910-assistant-autonomy.mdc) - Guideline for AI to prioritize self-research
- [**911-ai-response-signature.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/911-ai-response-signature.mdc) - Defines AI response signature fields
- [**912-ai-prompt-assist.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/912-ai-prompt-assist.mdc) - AI prompt assistance and refinement.
- [**912-rule-scope-distinction.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/912-rule-scope-distinction.mdc) - Clarifies scope of .cursor/rules vs project rules
- [**913-compliance-script-output.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/913-compliance-script-output.mdc) - Standardizes output and exit codes for compliance/validation scripts
- [**913-frontend-init.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/913-frontend-init.mdc) - Guides initialization of new Next.js frontend project.
- [**914-pytest-scenario-alternative.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/914-pytest-scenario-alternative.mdc) - Outlines pytest-scenario as an alternative for scenario testing.
- [**915-agent-state-lifecycle.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/915-agent-state-lifecycle.mdc) - Agent state and lifecycle management guidelines
- [**916-ai-codebase-interaction-model.mdc**](mdc:VANTA/VANTA/VANTA/916-ai-codebase-interaction-model.mdc) - Clarifies AI's model for interacting with the codebase.
- [**920-agent-resource-conventions.mdc**](mdc:VANTA/VANTA/VANTA/920-agent-resource-conventions.mdc) - Canonical conventions for VANTA agent resource loading and pathing.
- [**920-mcp-tool-integration.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/920-mcp-tool-integration.mdc) - Defines MCP tool integration and trigger patterns.
- [**921-mcp-server-integration.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/921-mcp-server-integration.mdc) - Defines server-side MCP tool integration for agents.
- [**921-vanta-mcp-signal-schema.mdc**](mdc:VANTA/VANTA/VANTA/921-vanta-mcp-signal-schema.mdc) - Defines standard schema for MCP (Orchestrator) signals.
- [**922-agentic-replay-log-schema.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/922-agentic-replay-log-schema.mdc) - Defines the schema and guidelines for logging to agentic_replay.log.jsonl.
- [**923-agentic-build-validate.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/923-agentic-build-validate.mdc) - Standard for the automated Agentic Build and Validate Ritual (CI/CD).
- [**924-cascade-executor.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/924-cascade-executor.mdc) - Cascade Executor Implementation and Usage Standard
- [**925-cascade-agent-swarm-activation.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/925-cascade-agent-swarm-activation.mdc) - Protocol for Layer 2 Agent Swarm activation.
- [**926-vanta-external-mcp-integration.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/926-vanta-external-mcp-integration.mdc) - Standard for integrating external MCP tools into VANTA.
- [**930-layer3-cli-api-activation.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/930-layer3-cli-api-activation.mdc) - Protocol for Layer 3 CLI/API activation.
- [**950-project-scheduler-bootstrap.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/950-project-scheduler-bootstrap.mdc) - Protocol to guide AI in bootstrapping project schedulers.
- [**960-vanta-task-scheduling.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/960-vanta-task-scheduling.mdc) - Defines standards for task scheduling and advanced trigger definitions.
- [**agent_cascade_definitions.mdc**](mdc:VANTA/VANTA/VANTA/agent_cascade_definitions.mdc) - Defines agent cascade profiles, triggers, and sequences.

### Coding Agent Patterns (1000 Series)
- [**1000-coding_agent-feedback_instrumentation.mdc**](mdc:VANTA/VANTA/VANTA/1000-coding_agent-feedback_instrumentation.mdc) - Ensure RL-driven features log user feedback events
- [**1001-coding_agent-scheduled_tasks.mdc**](mdc:VANTA/VANTA/VANTA/1001-coding_agent-scheduled_tasks.mdc) - Enforce proper scheduling libraries for recurring tasks
- [**1002-coding_agent-subprocess_security.mdc**](mdc:VANTA/VANTA/VANTA/1002-coding_agent-subprocess_security.mdc) - Mandate secure subprocess usage with timeouts and backoff
- [**1003-coding_agent-external_api_resilience.mdc**](mdc:VANTA/VANTA/VANTA/1003-coding_agent-external_api_resilience.mdc) - Require environment-based credentials and resilient HTTP calls
- [**1004-coding_agent-hyperparam_tuning.mdc**](mdc:VANTA/VANTA/VANTA/1004-coding_agent-hyperparam_tuning.mdc) - Structure hyperparameter tuning with dataclass results and atomic persistence
- [**1005-coding_agent-ci_cd_integration.mdc**](mdc:VANTA/VANTA/VANTA/1005-coding_agent-ci_cd_integration.mdc) - CI/CD pipeline integration with env token handling
- [**1006-coding_agent-cli_tooling.mdc**](mdc:VANTA/VANTA/VANTA/1006-coding_agent-cli_tooling.mdc) - CLI tools with argparse/typer, JSON schema validation, and templating
- [**1007-coding_agent-admin_ui.mdc**](mdc:VANTA/VANTA/VANTA/1007-coding_agent-admin_ui.mdc) - Schema-driven admin UI forms and API routes
- [**1008-coding_agent-plan_sync.mdc**](mdc:VANTA/VANTA/VANTA/1008-coding_agent-plan_sync.mdc) - Synchronize code changes with project plan documentation
- [**1009-coding_agent-env_template.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/1009-coding_agent-env_template.mdc) - Validate `.env.template` presence and format
- [**1010-coding_agent-test_coverage.mdc**](mdc:VANTA/VANTA/VANTA/1010-coding_agent-test_coverage.mdc) - Require tests for new modules with coverage thresholds
- [**1011-coding_agent-framework.mdc**](mdc:VANTA/VANTA/VANTA/1011-coding_agent-framework.mdc) - Scaffold a generic multi-agent framework
- [**1012-coding_agent-ide_preprompt.mdc**](mdc:VANTA/VANTA/VANTA/1012-coding_agent-ide_preprompt.mdc) - Enforce IDE agent pre-prompt wrapping
- [**1013-coding_agent-moe_analysis.mdc**](mdc:VANTA/VANTA/VANTA/1013-coding_agent-moe_analysis.mdc) - Encourage MoE for complex analysis
- [**1014-coding_agent-best_of_n.mdc**](mdc:VANTA/VANTA/VANTA/1014-coding_agent-best_of_n.mdc) - Suggest Best-of-N for solution generation
- [**1015-coding_agent-coe_delegation.mdc**](mdc:VANTA/VANTA/VANTA/1015-coding_agent-coe_delegation.mdc) - Recommend CoE delegation for complex actions
- [**1016-coding_agent-coe_invocation.mdc**](mdc:VANTA/VANTA/VANTA/1016-coding_agent-coe_invocation.mdc) - Standardize CoE invocation and result handling
- [**1017-coding_agent-config_convention.mdc**](mdc:VANTA/VANTA/VANTA/1017-coding_agent-config_convention.mdc) - Suggest standard locations and naming for agent configuration files
- [**1018-coding_agent-task_schema.mdc**](mdc:VANTA/VANTA/VANTA/1018-coding_agent-task_schema.mdc) - Enforce standard task_data schema for agent communication
- [**1019-fastapi-streaming.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/1019-fastapi-streaming.mdc) - FastAPI SSE streaming best practices

### LangChain Integration (1100 Series)
- [**1100-L1-LangChainIntegrationGuidance.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/1100-L1-LangChainIntegrationGuidance.mdc) - Guidance for L1 AI assisting with L2 LangChain integration.

### Utility & Miscellaneous
- [**110-env-config.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/110-env-config.mdc) - Environment variable configuration and best practices.
- [**environment-variables.mdc**](mdc:VANTA/VANTA/VANTA/environment-variables.mdc) - Environment variable guidelines
- [**form-handling.mdc**](mdc:VANTA/VANTA/VANTA/form-handling.mdc) - Form handling guidelines
- [**utilities.mdc**](mdc:VANTA/VANTA/VANTA/utilities.mdc) - Utility function guidelines
- [**logging.mdc**](mdc:VANTA/VANTA/VANTA/logging.mdc) - Logging guidelines
- [**cleaner.mdc**](mdc:VANTA/VANTA/VANTA/cleaner.mdc) - Code cleanup and maintenance
- [**page-structure.mdc**](mdc:VANTA/VANTA/VANTA/page-structure.mdc) - Page structure guidelines
- [**project-structure.mdc**](mdc:VANTA/VANTA/VANTA/project-structure.mdc) - Project organization
- [**cursor-rules.mdc**](mdc:VANTA/VANTA/VANTA/cursor-rules.mdc) - Managing Cursor MDC rules
- [**cursor.mdc**](mdc:VANTA/VANTA/VANTA/cursor.mdc) - Cursor IDE configuration
- [**llm.mdc**](mdc:VANTA/VANTA/VANTA/llm.mdc) - LLM integration guidelines
- [**swarm-config.mdc**](mdc:VANTA/VANTA/VANTA/.cursor/rules/swarm-config.mdc) - Standards for swarm registry and configuration YAML files.

##  Common Rule Combinations

### Frontend Development
```
@index.mdc @000-base.mdc @100-next-components.mdc @ui-components.mdc
```

---

## llm-test

<!-- Source: .cursor\rules\llm-test.mdc -->
<!-- Format: mdc -->

---
description: Guidelines for writing tests for LLM-related functionality
globs: __tests__/*llm*.ts, __tests__/*ai*.ts, *.test.ts
alwaysApply: false
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: __tests__/*llm*.ts, __tests__/*ai*.ts, *.test.ts

# LLM Testing Guidelines

## Test Structure
- Use descriptive test names that explain behavior
- Group related tests with describe blocks
- Test both happy paths and error cases
- Follow the Arrange-Act-Assert pattern

## Mocking LLM Responses
- Use vitest mocks for OpenAI and other providers
- Create fixture files for complex responses
- Mock streaming responses properly
- Test different response formats

## Testing Prompts
- Verify that prompts contain required information
- Test prompt template rendering with different inputs
- Ensure prompt lengths stay within limits
- Check for potential prompt injection vulnerabilities

## Response Validation
- Test response parsing and error handling
- Verify schema validation works correctly
- Test fallback mechanisms for unexpected responses
- Check for proper handling of null or undefined values

## End-to-End Tests
- Test the complete LLM interaction flow
- Verify UI updates correctly with responses
- Test loading and error states
- Ensure streaming updates the UI appropriately

## Example Test Setup

```typescript
import { vi, describe, it, expect, beforeEach } from 'vitest';
import { mockOpenAI } from '../mocks/openai';
import { SummarizeService } from './summarize-service';

// Mock the OpenAI client
vi.mock('openai', () => ({
  OpenAI: vi.fn().mockImplementation(() => ({
    chat: {
      completions: {
        create: vi.fn().mockResolvedValue({
          choices: [{
            message: {
              content: 'Mocked summary text'
            }
          }]
        })
      }
    }
  }))
}));

describe('SummarizeService', () => {
  let service: SummarizeService;
  
  beforeEach(() => {
    service = new SummarizeService();
  });
  
  it('should summarize text correctly', async () => {
    // Arrange
    const text = 'This is a long text that needs summarizing...';
    
    // Act
    const result = await service.summarize(text);
    
    // Assert
    expect(result).toEqual('Mocked summary text');
  });
  
  it('should handle API errors gracefully', async () => {
    // Arrange
    const errorMessage = 'API rate limit exceeded';
    vi.mocked(openai.chat.completions.create).mockRejectedValueOnce(
      new Error(errorMessage)
    );
    
    // Act & Assert
    await expect(service.summarize('Some text')).rejects.toThrow(errorMessage);
  });
});


---

## llm

<!-- Source: .cursor\rules\llm.mdc -->
<!-- Format: mdc -->

---
description: Guidelines for implementing LLM (Language Model) functionality in the application
globs: lib/llm/*.ts, lib/ai/*.ts, utils/llm/*.ts, hooks/use*Llm*.ts
type: autoAttached
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: lib/llm/*.ts, lib/ai/*.ts, utils/llm/*.ts, hooks/use*Llm*.ts

# LLM Implementation Guidelines

## Client Setup
- Use the LLM client from `lib/llm/client.ts`
- Configure models in the environment variables
- Handle rate limiting and retries
- Implement proper error handling

## Prompt Engineering
- Store prompts in separate files
- Use template strings for dynamic prompts
- Include clear instructions in prompts
- Structure prompts for consistent outputs

## Response Handling
- Validate and sanitize LLM responses
- Parse structured data with defined schemas
- Handle edge cases and unexpected outputs
- Implement fallbacks for failed requests

## Streaming Responses
- Use streaming for better user experience
- Implement proper UI feedback during streaming
- Handle early termination of streams
- Buffer and process partial responses

## Best Practices
- Keep sensitive data out of prompts
- Implement content moderation
- Cache responses when appropriate
- Monitor and log usage for optimization
- Test LLM integrations with automated tests
- For testing guidelines, see **@llm-test.mdc**

## Reinforcement Learning Integration
- Use the RL framework for feedback collection
- Implement policy-based completions
- Track user interactions for learning
- For RL framework details, see **@902-rl-agent.mdc**

## Related MDC Rules
- **@llm-test.mdc**: For testing LLM functionality
- **@902-rl-agent.mdc**: For reinforcement learning integration
- **@api-routes.mdc**: For LLM-powered API endpoints
- **@300-error-handling.mdc**: For error handling patterns
- **@logging.mdc**: For proper logging in LLM components
- **@data-fetching.mdc**: For fetching data to use with LLMs

## Directory Structure

LLM-related code is organized in specific directories:

- `apps/web/utils/ai/` - Main LLM implementations
- `apps/web/utils/llms/` - Core LLM utilities and configurations
- `apps/web/__tests__/` - LLM-specific tests


## Key Files
- `utils/llms/index.ts` - Core LLM functionality
- `utils/llms/model.ts` - Model definitions and configurations
- `utils/usage.ts` - Usage tracking and monitoring

## Implementation Guidelines

1. Use type-safe LLM responses with `chatCompletionObject` or `chatCompletionTools`:

```typescript
const aiResponse = await chatCompletionObject({
  userAi: user,
  messages: [
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ],
  schema: z.object({
    // Define expected response shape
    field: z.string(),
  }),
  userEmail: user.email,
  usageLabel: "Operation Name",
});
```

2. Always implement logging:

```typescript
import { createScopedLogger } from "@/utils/logger";
const logger = createScopedLogger("scope-name");

logger.trace("Input", { system, prompt });
logger.warn("Warning message");
```

3. Structure AI functions with clear types:

```typescript
type Options = {
  input: InputType;
  user: UserEmailWithAI;
};

export async function aiFunction(options: Options) {
  const { input, user } = options;
  // Implementation
}
```

## Error Handling

1. Use proper error types and logging
2. Implement fallbacks for AI failures
3. Return structured error responses
4. Add retry logic for transient failures
5. For detailed error handling, see **@300-error-handling.mdc**

## Testing

1. Place AI-specific tests in `apps/web/__tests__/`
2. Test both success and failure cases
3. Use mock data for development testing
4. For comprehensive testing guidelines, see **@llm-test.mdc**


---

## logging

<!-- Source: .cursor\rules\logging.mdc -->
<!-- Format: mdc -->

---
description: How to do backend logging
globs: lib/logger/.ts, utils/logger/.ts, api/*.ts
alwaysApply: false
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: lib/logger/.ts, utils/logger/.ts, api/*.ts

# Logging Guidelines

## Logger Setup
- Import the logger from `lib/logger.ts`
- Use the appropriate log level based on severity
- Include relevant context data with each log
- Use structured logging format for better parsing

## Log Levels
- `logger.error()` - For errors and exceptions
- `logger.warn()` - For warnings and potential issues
- `logger.info()` - For general information and events
- `logger.debug()` - For detailed debugging information

## Best Practices
- Log all API requests and responses
- Include request IDs for tracing requests
- Log errors with stack traces
- Avoid logging sensitive information
- Use consistent log formats

We use `createScopedLogger` to do logging:

```typescript
import { createScopedLogger } from "@/utils/logger";

const logger = createScopedLogger("action/rules");

logger.log("Created rule", { userId });
```

Typically this will be added at the top of a file.
If we have a large function that reuses multiple variables we can do this within a function:

```typescript
const logger = createScopedLogger("action/rules").with({ userId: user.id });

// Can now call without passing userId:
logger.log("Created rule");
```

Don't use `.with()` for a global logger. Only use within a specific function.

---

## monorepo-dependency-troubleshooting

<!-- Source: .cursor\rules\monorepo-dependency-troubleshooting.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# Monorepo Dependency Troubleshooting

## Trigger

This rule applies when facing persistent `npm install` failures (e.g., `ERESOLVE`, `EUNSUPPORTEDPROTOCOL workspace:`) or inconsistent build errors related to module resolution in a workspace setup.

## Priority

Critical - Foundational dependency issues block all other development.

## Steps

1.  **Clean Slate:**
    *   Delete the root `node_modules` directory (`rm -rf node_modules` or `Remove-Item -Recurse -Force node_modules` on Windows).
    *   Delete the root `package-lock.json` (or `yarn.lock` / `pnpm-lock.yaml`).
    *   Optionally, clear the package manager cache (`npm cache clean --force`, `yarn cache clean`).

2.  **Validate Root `package.json`:**
    *   Ensure the `workspaces` field correctly lists all package/app directories (e.g., `"apps/*", "packages/*"`).
    *   Minimize direct dependencies here; prefer dependencies within specific workspaces unless truly shared.
    *   Verify syntax of `workspace:` references in other `package.json` files (should be `workspace:*` or `workspace:^version`).

3.  **Attempt Fresh Install:**
    *   Run `npm install` (or `yarn install` / `pnpm install`) from the root directory without flags.

4.  **Prune PNPM Store (If Using PNPM):**
    *   If using `pnpm` and the fresh install fails (especially with resolution errors), run `pnpm store prune` to remove unreferenced or potentially corrupt packages from pnpm's global content-addressable store. This is a more thorough cleaning than `npm cache clean`.
    *   Attempt `pnpm install` again after pruning.

5.  **Use Install Flags (If Necessary):**
    *   If `ERESOLVE` errors persist due to peer dependency conflicts, try installing with `--legacy-peer-deps` (npm) or accept peer dependency resolutions offered by yarn/pnpm.
    *   Use `--force` only as a last resort, as it can lead to broken installs.

6.  **Consider Alternative Package Manager:**
    *   If `npm` continues to fail, especially with workspace protocol errors, consider switching to `pnpm` or `yarn` which often have more robust workspace handling.

7.  **Normalize Tooling Configuration (If Applicable):**
    *   Ensure consistent TypeScript (`tsconfig.json`), Babel (`babel.config.js`), and other build tool configurations across workspaces, especially between React Native and Web setups.
    *   For Next.js + RN/shared packages: Configure `next.config.js` with `transpilePackages` and `react-native-web` alias.

## Outcome

A stable dependency graph where `npm install` (or equivalent) succeeds reliably, and modules between workspaces resolve correctly during builds.


---

## page-structure

<!-- Source: .cursor\rules\page-structure.mdc -->
<!-- Format: mdc -->

---
description: Page structure
globs: app/*.tsx, app/*/*.tsx, pages/*.tsx
type: autoAttached
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: app/*.tsx, app/*/*.tsx, pages/*.tsx

# Page Structure Guidelines

## Next.js App Router Page Structure
- Use `page.tsx` files for route components
- Implement metadata in each page for SEO optimization
- Use layout components for shared UI elements
- Handle loading states with Loading components
- Implement error handling with Error components

## Page Components
- Keep page components focused on data fetching and layout
- Extract complex UI into separate components
- Use server components when possible for performance
- Implement client components only when needed for interactivity

- Create new pages at: `apps/web/app/(app)/PAGE_NAME/page.tsx`
- Components for the page are either put in `page.tsx`, or in the `apps/web/app/(app)/PAGE_NAME` folder
- Pages are Server components so you can load data into them directly
- If we're in a deeply nested component we will use `swr` to fetch via API
- If you need to use `onClick` in a component, that component is a client component and file must start with `use client` 

---

## prisma

<!-- Source: .cursor\rules\prisma.mdc -->
<!-- Format: mdc -->

---
description: How to use Prisma
globs: prisma/, lib/db/, schema.prisma
type: autoAttached
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: prisma/, lib/db/, schema.prisma

# Prisma Database Guidelines

## Schema Definition
- Define models in `prisma/schema.prisma`
- Use clear, descriptive model and field names
- Include appropriate relations between models
- Add comments to document complex relations or fields

## Database Access
- Use the Prisma client from `lib/db/index.ts`
- Create service functions for database operations
- Handle errors with try/catch blocks
- Use transactions for operations that modify multiple tables

## Error Handling
- Wrap database operations in try/catch blocks
- Implement appropriate error logging
- Return meaningful error messages
- Handle common database errors (not found, validation, etc.)
- For detailed error handling patterns, see **@300-error-handling.mdc**

## API Integration
- Use Prisma with API routes and server actions
- Implement proper data validation before database operations
- Return appropriate responses from database operations
- For API implementation guidelines, see **@api-routes.mdc** and **@server-actions.mdc**

## Related MDC Rules
- **@api-routes.mdc**: For using Prisma in API routes
- **@server-actions.mdc**: For using Prisma in server actions
- **@300-error-handling.mdc**: For error handling patterns
- **@logging.mdc**: For logging database operations
- **@testing.mdc**: For testing database access

## Migration Workflow
- Generate migrations with `npx prisma migrate dev --name description`
- Apply migrations in production with `npx prisma migrate deploy`
- Use `npx prisma db seed` for seeding data

## Usage Example

```typescript
import prisma from "@/utils/prisma";

// Example database service function
async function getUserById(id: string) {
  try {
    const user = await prisma.user.findUnique({
      where: { id },
      select: {
        id: true,
        name: true,
        email: true,
        // Don't include sensitive fields
      },
    });
    
    if (!user) {
      throw new Error(`User with ID ${id} not found`);
    }
    
    return user;
  } catch (error) {
    console.error("Error fetching user:", error);
    throw error;
  }
}
```

This is how we import prisma in the project:

```typescript
import prisma from "@/utils/prisma";
```

The prisma file is located at: `apps/web/prisma/schema.prisma`.

---

## project-structure

<!-- Source: .cursor\rules\project-structure.mdc -->
<!-- Format: mdc -->

---
description: Project structure and file organization guidelines
globs: app/, components/, lib/, pages/
type: agentRequested
---
# RULE TYPE: Agent Requested
# FILE PATTERNS: app/, components/, lib/, pages/

# Project Structure Guidelines

## Next.js App Router Structure
- `app/` - App Router routes and layouts
  - `(auth)/` - Authentication-related routes (grouped)
  - `(dashboard)/` - Dashboard-related routes (grouped)
  - `api/` - API routes using Route Handlers
  - `layout.tsx` - Root layout with providers
  - `page.tsx` - Home page component
  
## Component Organization
- `components/` - UI components
  - `ui/` - Reusable UI components (shadcn/ui)
  - `layouts/` - Layout components
  - `forms/` - Form-specific components
  - `[feature]/` - Feature-specific components

## Utility Functions
- `lib/` - Shared utility functions
  - `db/` - Database-related utilities
  - `utils/` - General utility functions
  - `api/` - API-related functions
  - `hooks/` - Custom React hooks
  - `contexts/` - React context providers

## Data Access
- `prisma/` - Prisma schema and migrations
- `lib/db/` - Database access functions

## Configuration
- `config/` - Configuration files
- `.env.local` - Environment variables
- `tailwind.config.js` - Tailwind CSS configuration
- `next.config.js` - Next.js configuration

## Main Structure
- We use Turborepo with pnpm workspaces
- Main app is in `apps/web`
- Packages are in the `packages` folder
- Server actions are in `apps/web/utils/actions` folder

## File Naming and Organization
- Use kebab case for route directories (e.g., `api/hello-world/route`)
- Use PascalCase for components (e.g. `components/Button.tsx`)
- Shadcn components are in `components/ui`
- All other components are in `components/`
- Colocate files in the folder where they're used unless they can be used across the app
- If a component can be used in many places, place it in the `components` folder

## New Pages
- Create new pages at: `apps/web/app/(app)/PAGE_NAME/page.tsx`
- Components for the page are either in `page.tsx` or in the `apps/web/app/(app)/PAGE_NAME` folder
- Pages are Server components for direct data loading
- Use `swr` for data fetching in deeply nested components
- Components with `onClick` must be client components with `use client` directive
- Server action files must start with `use server`

## Utility Functions
- Create utility functions in `utils/` folder for reusable logic
- Use lodash utilities for common operations (arrays, objects, strings)
- Import specific lodash functions to minimize bundle size:
  ```ts
  import groupBy from "lodash/groupBy";
  ``` 

---

## sample-with-includes

<!-- Source: .cursor\rules\sample-with-includes.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---


---

## server-actions

<!-- Source: .cursor\rules\server-actions.mdc -->
<!-- Format: mdc -->

---
description: Guidelines for implementing Next.js server actions
globs: actions/.ts, utils/actions/.ts, lib/actions/.ts
type: autoAttached
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: actions/.ts, utils/actions/.ts, lib/actions/.ts

# Server Actions Guidelines

## Format and Structure
Server actions should follow this format:

Files:
- `apps/web/utils/actions/NAME.validation.ts`
- `apps/web/utils/actions/NAME.ts`

For `apps/web/utils/actions/NAME.validation.ts`:

```typescript
import { z } from "zod";

export const createApiKeyBody = z.object({ name: z.string().nullish() });
export type CreateApiKeyBody = z.infer<typeof createApiKeyBody>;

export const deactivateApiKeyBody = z.object({ id: z.string() });
export type DeactivateApiKeyBody = z.infer<typeof deactivateApiKeyBody>;
```

For `apps/web/utils/actions/NAME.ts`:

```typescript
'use server';

import { revalidatePath } from "next/cache";
import { auth } from "@/app/api/auth/[...nextauth]/auth";
import prisma from "@/utils/prisma";
import { withActionInstrumentation } from "@/utils/actions/middleware";
import {
  deactivateApiKeyBody,
  type DeactivateApiKeyBody,
} from "@/utils/actions/api-key.validation";

export const deactivateApiKeyAction = withActionInstrumentation(
  "deactivateApiKey",
  async (unsafeData: DeactivateApiKeyBody) => {
    const session = await auth();
    const userId = session?.user.id;
    if (!userId) return { error: "Not logged in" };

    const { data, success, error } =
      deactivateApiKeyBody.safeParse(unsafeData);
    if (!success) return { error: error.message };

    await prisma.apiKey.update({
      where: { id: data.id, userId },
      data: { isActive: false },
    });

    revalidatePath("/settings");
  }
);
```

## Implementation Guidelines
- Implement type-safe server actions with proper validation
- Define input schemas using Zod for robust type checking and validation
- Handle errors gracefully and return appropriate responses
- Ensure all server actions return the `Promise<ServerActionResponse>` type
- The zod schema will also be used on the client for form validation

## Error Handling
- Use standardized error response format
- Provide helpful error messages for debugging
- Log errors on the server side
- Return appropriate error status codes

## Security Best Practices
- Validate all input data before processing
- Implement proper authentication checks
- Use rate limiting for public endpoints
- Never expose sensitive information in responses
- Sanitize input to prevent SQL injection

---

## swarm-config

<!-- Source: .cursor\rules\swarm-config.mdc -->
<!-- Format: mdc -->

---
description: 
globs: 
alwaysApply: true
---
# RULE TYPE: Always
# FILE PATTERNS: vanta_seed/swarm/*.yaml, config/swarm/*.yaml

# Swarm Registry & Configuration Standards

## Purpose
Ensure consistency, quality, and automation-readiness for all YAML files defining swarm components (agents, tri-nodes, policies, etc.).

## Standard Structure & Keys

All top-level items within a registry list (e.g., `trinodes:`, `agents:`) should be dictionaries adhering to the following:

```yaml
- id: UNIQUE_STRING_ID # Required: Machine-readable, unique identifier (e.g., DATA_TRINODE_01, agent_unifier_prod)
  name: Human Readable Name # Required: User-friendly name (e.g., "Data Integrity Tri-Node 1", "Production Data Unifier")
  type: agent | trinode | policy | reward_policy | node_manifest # Required: Type of component defined.
  description: "Brief explanation of the component's purpose." # Required: String description.
  metadata: # Required: Dictionary for tracking provenance and status.
    version: 1.0
    created_at: "YYYY-MM-DDTHH:MM:SSZ"
    last_updated: "YYYY-MM-DDTHH:MM:SSZ"
    status: active | inactive | deprecated
    tags: ["data", "experimental"] # Optional list of tags

  # --- Type-Specific Optional Keys ---

  # For type: agent
  class_path: "vanta_seed.agents.specific_agent.SpecificAgent" # Path for dynamic loading
  config_path: "./config/agents/specific_agent_config.yaml" # Optional: Path to agent-specific config
  env_config: # Optional: Environment-specific overrides
    development:
      log_level: DEBUG
    production:
      log_level: INFO

  # For type: trinode
  members: # Required for trinode
    - agent_id_1
    - agent_id_2
    - agent_id_3
  ritual_alignment: "ritual_class_name" # Required for trinode
  collapse_target: "target_identifier" # Required for trinode
  parent: MASTER_TRINITY_NODE # Required for trinode
  policy_config: # Optional: Policies specific to this TriNode
    consensus_threshold: 0.7
    failure_mode: retry | escalate

  # For type: policy / reward_policy
  policy_logic_path: "vanta_seed.swarm.policies.specific_policy.SpecificPolicyLogic" # Path to implementation
  parameters: # Optional: Configurable parameters for the policy
    learning_rate: 0.01
    discount_factor: 0.99

  # Add structures for other types (node_manifest etc.) as needed
```

## Formatting Rules

- **Indentation:** Use 2 spaces for indentation. NO TABS.
- **Keys:** Use `snake_case` for all dictionary keys.
- **Lists:** Use standard YAML list format (`- item`).
- **Strings:** Use double quotes for strings containing special characters or requiring explicit string typing.
- **Comments:** Use `#` for comments to explain non-obvious configurations.

## Validation Requirements

- **Uniqueness:** The `id` field *must* be unique within its registry file (e.g., unique agent IDs in `agent_registry.yaml`, unique trinode names in `trinode_registry.yaml`).
- **Type Enum:** The `type` field *must* be one of the recognized swarm component types.
- **Required Keys:** All components *must* include `id`, `name`, `type`, `description`, and `metadata`.
- **Type-Specific Keys:** Components *must* include required keys specific to their `type` (e.g., `members`, `ritual_alignment`, `collapse_target`, `parent` are required for `type: trinode`).

## Automation & Tooling

Adhering to this standard enables:
- Automated validation of configuration files in CI/CD.
- Auto-generation of documentation for swarm components.
- Dynamic loading and registration of agents/nodes/policies.
- Potential auto-generation of monitoring dashboards or admin UIs based on registry contents.


---

## testing

<!-- Source: .cursor\rules\testing.mdc -->
<!-- Format: mdc -->

---
description: Guidelines for testing the application with Vitest
globs: .test.ts, .test.tsx, __tests__/.ts, __tests__/.tsx
type: autoAttached
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: .test.ts, .test.tsx, __tests__/.ts, __tests__/.tsx

# Testing Guidelines

## Test Structure
- Use describe blocks to group related tests
- Use test/it blocks for individual test cases
- Follow the Arrange-Act-Assert pattern
- Keep tests focused on a single behavior

## Component Testing
- Test both rendering and interactions
- Use React Testing Library for component tests
- Test accessibility concerns
- Test loading and error states

## Mocking
- Use vitest.mock for mocking modules
- Use vi.fn() for mocking functions
- Use MSW for mocking API requests
- Reset mocks between tests

## Best Practices
- Write tests before implementation (TDD)
- Test edge cases and error handling
- Avoid testing implementation details
- Keep tests independent and isolated
- Use meaningful assertion messages

## Coverage
- Aim for 80% code coverage minimum
- Focus on testing business logic thoroughly
- Ensure all user flows are tested
- Prioritize critical paths for testing

## Testing Framework
- `vitest` is used for testing
- Tests are colocated next to the tested file
  - Example: `dir/format.ts` and `dir/format.test.ts`
- AI tests are placed in the `__tests__` directory and are not run by default (they use a real LLM)

## Common Mocks

### Server-Only Mock
```ts
vi.mock("server-only", () => ({}));
```

### Prisma Mock
```ts
import { beforeEach } from "vitest";
import prisma from "@/utils/__mocks__/prisma";

vi.mock("@/utils/prisma");

describe("example", () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it("test", async () => {
    prisma.group.findMany.mockResolvedValue([]);
  });
});
```

---

## ui-components

<!-- Source: .cursor\rules\ui-components.mdc -->
<!-- Format: mdc -->

---
description: UI component and styling guidelines using Shadcn UI, Radix UI, and Tailwind
globs: components/.tsx, .css, .scss, ui/.tsx
type: autoAttached
---
# RULE TYPE: Auto Attached
# FILE PATTERNS: components/.tsx, .css, .scss, ui/.tsx

# UI Component Guidelines

## Component Library
- Use Shadcn UI components when available
- Follow Radix UI accessibility practices
- Customize components using the Tailwind config
- Create reusable components for repeated UI patterns

## Styling Principles
- Use Tailwind CSS for styling
- Follow the project's color scheme in `tailwind.config.js`
- Use CSS variables for theme values
- Maintain dark mode compatibility
- Follow responsive design principles

## Component Structure
- Keep components focused and single-purpose
- Use proper typing for component props
- Extract complex logic to custom hooks
- Implement proper loading and error states
- Follow responsive design principles

## Accessibility
- Ensure proper ARIA attributes
- Maintain keyboard navigation
- Support screen readers
- Use sufficient color contrast
- Test with assistive technologies

## Shadcn UI Usage
- Import components from `@/components/ui`
- Customize using Tailwind classes
- Follow the component documentation
- Update the components using the Shadcn CLI
- Maintain the component registry

## Icons
- Use the centralized Icons component
- Maintain consistent icon sizing
- Provide appropriate accessibility attributes
- Follow the icon guidelines in `icon-guidelines.md`

## Forms
- Use the Form components from Shadcn UI
- Implement proper validation using Zod
- Show clear error messages
- Maintain form state properly
- Provide appropriate feedback on submission
- For detailed form guidelines, see: **@form-handling.mdc**

## Best Practices
- Use semantic HTML elements
- Maintain consistent spacing using Tailwind's spacing scale
- Follow a mobile-first approach
- Implement proper focus management
- Use CSS Grid and Flexbox appropriately

## Data Fetching Integration
- Use SWR for data fetching in components
- Implement proper loading states
- Handle errors gracefully
- For detailed data fetching guidelines, see: **@data-fetching.mdc**

## Related MDC Rules
- **@form-handling.mdc**: For form validation and submission
- **@data-fetching.mdc**: For data fetching in UI components
- **@page-structure.mdc**: For page layout and composition
- **@testing.mdc**: For component testing guidelines
- **@400-adhd-patterns.mdc**: For ADHD-friendly UI patterns

## UI Framework
- Use Shadcn UI and Tailwind for components and styling
- Implement responsive design with Tailwind CSS using a mobile-first approach
- Use `next/image` package for images 

## Install new Shadcn components

```sh
pnpm dlx shadcn@latest add COMPONENT
```

Example:

```sh
pnpm dlx shadcn@latest add progress
```

## Data Fetching with SWR
For API get requests to server use the `swr` package:

```typescript
const searchParams = useSearchParams();
const page = searchParams.get("page") || "1";
const { data, isLoading, error } = useSWR<PlanHistoryResponse>(
  `/api/user/planned/history?page=${page}`
);
```

## Loading Components
Use the `LoadingContent` component to handle loading states:

```tsx
<Card>
  <LoadingContent loading={isLoading} error={error}>
    {data && <MyComponent data={data} />}
  </LoadingContent>
</Card>
```

## Form Components
### Text Inputs
```tsx
<Input
  type="email"
  name="email"
  label="Email"
  registerProps={register("email", { required: true })}
  error={errors.email}
/>
```

### Text Area
```tsx
<Input
  type="text"
  autosizeTextarea
  rows={3}
  name="message"
  placeholder="Paste in email content"
  registerProps={register("message", { required: true })}
  error={errors.message}
/>
``` 

---

## utilities

<!-- Source: .cursor\rules\utilities.mdc -->
<!-- Format: mdc -->

---
description: Util functions
globs: 
alwaysApply: false
---
# Utility Functions

- Use lodash utilities for common operations (arrays, objects, strings)
- Import specific lodash functions to minimize bundle size:
  ```typescript
  import groupBy from "lodash/groupBy";
  ```
- Create utility functions in `utils/` folder for reusable logic
- The `utils` folder also contains core app logic such as Next.js Server Actions and Gmail API requests.

---

## 000-common-base

<!-- Source: .cursor\rules\common_mcp_rules\000-common-base.mdc -->
<!-- Format: mdc -->

---
description:
globs:
alwaysApply: false
---
# Common Base Rules (Placeholder)

---
description: Placeholder for common base rules shared across projects.
globs: "**/*"
alwaysApply: false
---

# Universal Principles

- Strive for clarity and simplicity.
- Document non-obvious decisions.
- Ensure configurations are environment-aware (dev vs. prod).


---
