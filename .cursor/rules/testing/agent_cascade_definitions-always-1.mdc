---
description: null
globs: null
alwaysApply: true
type: agent
migrated: true
migration_date: '2025-06-07T14:32:13.657632'
---

# RULE TYPE: Agent Configuration / Orchestration Logic
# FILE PATTERNS: N/A (Loaded by system)

# Agent Cascade Definitions

## Principle:
# This document defines reusable "cascade profiles" that orchestrate sequences of agents
# triggered by specific conditions or by other agents. It enables the
# "Domino Agentic Execution Pattern."

# --- SCHEMA FOR CASCADE PROFILES ---
#
# profiles:
#   - profile_id: unique_string_identifier (e.g., "protocol_layer_change_cascade")
#     description: "Human-readable description of what this cascade does."
#     trigger_type: "AUTO_ON_CONDITION" | "AGENT_INITIATED" | "USER_CONFIRMED_WHISPER"
#     trigger_conditions: [] # See detailed examples below
#     parameters_expected: [] # For AGENT_INITIATED
#     agent_sequence: [] # Sequence of agent_id, input_mapping, on_success, on_failure, etc.
#     whisper_mode_details: {} # For USER_CONFIRMED_WHISPER
#     error_handling_cascade_profile_id: "string"
#     logging_level: "VERBOSE" | "STANDARD" | "MINIMAL"

# --- EXAMPLE CASCADE PROFILES ---
profiles:
  # --- Profile ID: core_protocol_modification_cascade (from previous discussion) ---
  - profile_id: "core_protocol_modification_cascade"
    description: "Full validation, RL labeling, and testing for critical protocol/trigger engine changes."
    trigger_type: "AGENT_INITIATED"
    parameters_expected:
      - name: "modified_files"
        type: "list[string]"
        required: true
      - name: "change_summary"
        type: "string"
        required: true
      - name: "initiating_agent_id"
        type: "string"
        required: true
    agent_sequence:
      - agent_id: "protocol_validator_agent"
        input_mapping:
          files_to_validate: "{{trigger.parameters.modified_files}}"
          validation_ruleset: "strict_protocol_rules"
        on_failure: "LOG_AND_HALT"
      - agent_id: "rl_label_agent"
        input_mapping:
          files_for_labeling: "{{trigger.parameters.modified_files}}"
          change_description: "{{trigger.parameters.change_summary}}"
          source_agent: "{{trigger.parameters.initiating_agent_id}}"
        on_failure: "LOG_AND_PROCEED"
      - agent_id: "testing_agent"
        input_mapping:
          test_scope: "integration"
          specific_files_to_target: "{{trigger.parameters.modified_files}}"
        on_failure: "LOG_AND_TRIGGER_CASCADE_PROFILE"
        on_failure_cascade_profile_id: "test_failure_investigation_cascade"
    logging_level: "VERBOSE"

  # --- Profile ID: agent_contract_change_validation_cascade (NEW) ---
  - profile_id: "agent_contract_change_validation_cascade"
    description: "Validates and documents changes related to core VANTA agent contracts (e.g., if agent_base.py or 101-vanta-agent-contract.mdc is modified)."
    trigger_type: "AUTO_ON_CONDITION"
    trigger_conditions:
      - condition_type: "FILE_MODIFICATION"
        details:
          file_patterns: [".cursor/rules/101-vanta-agent-contract.mdc"]
      - condition_type: "USER_INTENT_MATCH"
        details:
          intents: ["modify_agent_base", "update_agent_lifecycle", "refactor_core_agent_interface"]
    agent_sequence:
      - agent_id: "impact_analyzer_agent"
        input_mapping:
          changed_contract_rule_file: ".cursor/rules/101-vanta-agent-contract.mdc"
          original_prompt_for_change: "{{trigger.user_prompt || 'System detected change to agent contract rule.'}}"
        on_failure: "LOG_AND_HALT"
      - agent_id: "dev_documentation_agent"
        input_mapping:
          files_to_document_changes_for: [".cursor/rules/101-vanta-agent-contract.mdc", "conceptual_link_to_agent_base.py_docs"]
          change_summary: "{{impact_analyzer_agent.output.summary_of_impact}}"
          related_rules_to_cross_reference: ["501-vanta-memory-principles.mdc", "920-agent-resource-conventions.mdc", "201-vanta-logging-core-requirements.mdc"]
        on_failure: "LOG_AND_PROCEED"
      - agent_id: "rl_label_agent"
        input_mapping:
          architectural_event_description: "Agent contract modification (see {{impact_analyzer_agent.output.summary_of_impact}})"
          related_files: [".cursor/rules/101-vanta-agent-contract.mdc"]
          significance_level: "HIGH"
    logging_level: "VERBOSE"

  # --- Profile ID: general_code_commit_whisper_cascade (from previous discussion) ---
  - profile_id: "general_code_commit_whisper_cascade"
    description: "Suggests basic validation and RL labeling for general code changes."
    trigger_type: "USER_CONFIRMED_WHISPER"
    trigger_conditions:
      - condition_type: "FILE_MODIFICATION"
        details:
          file_patterns: ["**/*.py", "**/*.ts"]
    parameters_expected:
      - name: "modified_files_count"
        type: "integer"
        required: true
      - name: "primary_changed_module"
        type: "string"
        required: false
      - name: "modified_files_list"
        type: "list[string]"
        required: true # Added required for whisper to pass on
    agent_sequence:
      - agent_id: "rl_label_agent"
        input_mapping:
          files_for_labeling: "{{trigger.parameters.modified_files_list}}"
      - agent_id: "linting_and_static_analysis_agent"
        input_mapping:
          files_to_scan: "{{trigger.parameters.modified_files_list}}"
    whisper_mode_details:
      suggestion_prompt_template: "Detected {{trigger.parameters.modified_files_count}} code file(s) changed (e.g., in '{{trigger.parameters.primary_changed_module}}'). Would you like to run the 'general_code_commit_whisper_cascade' for quick labeling and static analysis?"
      default_action: "REJECT"
    logging_level: "STANDARD"

  # --- Profile ID: test_failure_investigation_cascade (from previous discussion) ---
  - profile_id: "test_failure_investigation_cascade"
    description: "Gathers context and attempts to diagnose test failures."
    trigger_type: "AGENT_INITIATED"
    parameters_expected:
      - name: "failed_test_reports"
        type: "object"
        required: true
      - name: "related_code_files"
        type: "list[string]"
        required: true
    agent_sequence:
      - agent_id: "log_analysis_agent"
        input_mapping:
          test_failure_context: "{{trigger.parameters.failed_test_reports}}"
      - agent_id: "code_context_gatherer_agent"
        input_mapping:
          files_of_interest: "{{trigger.parameters.related_code_files}}"
          failed_test_details: "{{trigger.parameters.failed_test_reports}}"
      - agent_id: "expert_coder"
        input_mapping:
          task_description: "Analyze test failures (see context) and suggest fixes or root cause."
          target_files: "{{trigger.parameters.related_code_files}}"
          error_context_from_logs: "{{log_analysis_agent.output.summary}}"
          code_context: "{{code_context_gatherer_agent.output.full_context}}"
    logging_level: "VERBOSE"

# --- VANTA! CODER SPECIFIC PROFILES --- #
  - profile_id: vanta_coder_major_edit
    description: "Cascade triggered after Vanta! Coder completes a major edit, feature, or architectural change."
    trigger_event_schema: # Defines expected keys in the trigger payload
      type: object
      properties:
        modified_files:
          type: array
          items: { type: string }
        change_summary:
          type: string
        agent_id_completed: # Agent that finished
          type: string 
      required: [modified_files, change_summary, agent_id_completed]
    
    agent_sequence:
      - agent_id: "validation_agent" # Conceptual
        input_mapping:
          files_to_validate: "{{ trigger.parameters.modified_files }}"
          validation_context: "post_vanta_coder_edit"
        on_failure: "LOG_AND_PROCEED" # Don't halt cascade if validation fails, just log
        
      - agent_id: "rl_label_agent" # Conceptual
        input_mapping:
          completed_action_log_ref: "{{ steps[0].output.validation_log_ref || trigger.parameters.change_summary }}" # Use validation log or summary
          agent_involved: "{{ trigger.parameters.agent_id_completed }}"
          code_context: "{{ steps[0].output.validated_code_snippets || 'N/A' }}"
          task_intent: "vanta_coder_major_edit_completion"
        on_failure: "LOG_AND_PROCEED"
        
      - agent_id: "protocol_consistency_agent" # Conceptual
        input_mapping:
          files_to_check: "{{ trigger.parameters.modified_files }}"
          relevant_protocols: ["api_standards", "logging_core"]
        on_failure: "LOG_AND_PROCEED"
        
      - agent_id: "testing_agent" # Conceptual
        input_mapping:
          test_scope: "integration"
          focus_areas: "{{ trigger.parameters.modified_files }}"
          triggering_change: "{{ trigger.parameters.change_summary }}"
        on_failure: "LOG_AND_PROCEED"
        
    # Add other steps as needed
    
    # Note: Assumes agents like validation_agent, rl_label_agent, etc., exist.
    #       The input_mapping uses Jinja2/asteval style placeholders.

# --- RITUAL INVOCATION CASCADE --- #
  - profile_id: ritual_invocation_submitted_cascade
    description: "Handles post-submission tasks after a ritual is invoked via the API."
    trigger_event_schema: # Matches payload sent by API
      type: object
      properties:
        ritual_id:
          type: string
        invocation_id:
          type: string
        parameters:
          type: object
        status:
          type: string # e.g., "SUCCESS", "FAILURE"
        result:
          type: object # Ritual execution result or error info
        timestamp:
          type: string
          format: date-time
      required: [ritual_id, invocation_id, parameters, status, result, timestamp]
    agent_sequence:
      - agent_id: "detailed_event_logger_agent" # This agent was conceptualized and created
        input_mapping:
          event_type: "RITUAL_INVOCATION_COMPLETED"
          event_data: "{{ trigger.parameters }}" # The whole payload
          severity: "{{ 'INFO' if trigger.parameters.status == 'SUCCESS' else 'ERROR' }}"
        on_failure: "LOG_ONLY" # Critical that this logging step itself doesn't halt everything
      # Potentially add more agents here, e.g., a notification agent or an RL agent for ritual success/failure
    logging_level: "STANDARD"

# --- SYSTEM LAYER INCOHERENCE CASCADE --- #
  - profile_id: "system_incoherence_detected_cascade"
    description: "Orchestrates actions when System Layer Incoherence (SLI) is detected by the IncoherenceDetectionAgent."
    trigger_type: "AGENT_INITIATED" # Triggered by IncoherenceDetectionAgent via MCP signal
    trigger_event_schema:
      type: "object"
      properties:
        findings:
          type: "array"
          items:
            type: "object"
            properties:
              type: { type: "string" } # e.g., "repeated_edit_failure", "checksum_mismatch"
              file: { type: "string" }
              description: { type: "string" }
              log_evidence: { type: "array", items: { type: "string" } }
            required: ["type", "file", "description"]
        resolution_protocol_version:
          type: "string" # e.g., "006_v1" referring to the MDC rule version
      required: ["findings", "resolution_protocol_version"]
    agent_sequence:
      - agent_id: "detailed_event_logger_agent"
        input_mapping:
          event_type: "SYSTEM_INCOHERENCE_DETECTED"
          event_data: "{{ trigger.parameters.findings }}"
          severity: "WARNING"
          metadata:
            protocol_version: "{{ trigger.parameters.resolution_protocol_version }}"
        on_failure: "LOG_ONLY"
      - agent_id: "user_notification_agent" # Conceptual agent
        input_mapping:
          message_type: "SLI_WARNING"
          title: "System Layer Incoherence Detected"
          details: "{{ trigger.parameters.findings }}"
          suggested_actions: [
            "Review findings and logs.",
            "Consider manual file inspection using 'mcp_desktop-commander_read_file'.",
            "If a known good version exists, consider 'mcp_desktop-commander_write_file' after backup."
          ]
        on_failure: "LOG_AND_PROCEED"
      # Add more agents for advanced resolution if developed, e.g.:
      # - agent_id: "system_integrity_repair_agent"
      #   input_mapping: { findings: "{{ trigger.parameters.findings }}" }
      #   on_failure: "ESCALATE_TO_COE_REVIEW"
    error_handling_cascade_profile_id: "sli_cascade_failure_handler" # Conceptual
    logging_level: "VERBOSE"

  # --- Profile ID: dataset_creation_domino_cascade (NEW) ---
  - profile_id: "dataset_creation_domino_cascade"
    description: "Handles post-dataset creation tasks like schema validation, project linking, lineage update, event emission, and auto-tagging."
    trigger_type: "AGENT_INITIATED" # Expected to be triggered by an MCP signal after successful dataset registration
    parameters_expected:
      - name: "dataset_id"
        type: "string"
        required: true
        description: "The ID of the newly created/updated dataset."
      - name: "dataset_name"
        type: "string"
        required: true
        description: "Name of the dataset."
      - name: "dataset_description"
        type: "string"
        required: false
        description: "Description of the dataset."
      - name: "schema_id" # This is the schema_id stored *with* the dataset record
        type: "string"
        required: false # A dataset might not have a schema initially
        description: "The schema ID associated with the dataset, if any."
      - name: "project_id" # Conceptual: This field would need to be part of your Dataset model/metadata
        type: "string"
        required: false # A dataset might not be linked to a project
        description: "The project ID to link this dataset to."
      - name: "tags_from_metadata" # Conceptual: Tags extracted during registration process
        type: "list[string]"
        required: false
        description: "Initial list of tags derived from dataset metadata by registration process."

    agent_sequence:
      - name: "Step 1: Validate Schema Reference"
        agent_id: "schema_validator_agent" # Placeholder agent ID
        input_mapping:
          dataset_id_to_validate: "{{ trigger.parameters.dataset_id }}"
          expected_schema_id: "{{ trigger.parameters.schema_id }}"
        on_failure: "LOG_AND_PROCEED" # Decide if failure here should halt the cascade or just log
        description: "Confirms schemaId (if provided) exists and optionally validates dataset conformance."

      - name: "Step 2: Link to Project"
        agent_id: "project_linker_agent" # Placeholder agent ID
        input_mapping:
          dataset_id_to_link: "{{ trigger.parameters.dataset_id }}"
          project_id_target: "{{ trigger.parameters.project_id }}"
        condition: "{{ trigger.parameters.project_id is not none }}" # Only run if project_id is provided
        on_failure: "LOG_AND_PROCEED"
        description: "Ensures projectId is valid and links dataset under that project."

      - name: "Step 3: Update Data Lineage"
        agent_id: "lineage_updater_agent" # Placeholder agent ID
        input_mapping:
          newly_created_dataset_id: "{{ trigger.parameters.dataset_id }}"
          dataset_name: "{{ trigger.parameters.dataset_name }}"
          # Potentially pass source information if available in dataset metadata
        on_failure: "LOG_AND_PROCEED"
        description: "Logs lineage graph connection (source, derivation, transforms)."

      - name: "Step 4: Emit Agentic Event"
        mcp_signal: # Using the mcp_signal action type
          signal_type: "BROADCAST_EVENT" # Or a more specific custom signal type
          target_entity:
            type: "BROADCAST_CHANNEL"
            id: "DATA_CATALOG_UPDATES" # Conceptual broadcast channel
          payload:
            event_type: "NEW_DATASET_REGISTERED"
            dataset_id: "{{ trigger.parameters.dataset_id }}"
            dataset_name: "{{ trigger.parameters.dataset_name }}"
            timestamp_iso: "{{ now_iso() }}" # Assuming a helper function or context variable for current time
            details: "Dataset {{ trigger.parameters.dataset_name }} (ID: {{ trigger.parameters.dataset_id }}) successfully registered."
          priority: 3
        description: "Pushes signal to VANTA agents about the new dataset."

      - name: "Step 5: Auto-tag Dataset"
        agent_id: "metadata_tagger_agent" # Placeholder agent ID
        input_mapping:
          dataset_id_for_tagging: "{{ trigger.parameters.dataset_id }}"
          text_for_nlp_tagging: "Name: {{ trigger.parameters.dataset_name }}. Description: {{ trigger.parameters.dataset_description }}"
          existing_tags: "{{ trigger.parameters.tags_from_metadata }}"
        on_failure: "LOG_AND_PROCEED"
        description: "NLP-driven tag suggestion/application from dataset name + description."

    logging_level: "STANDARD"

# --- SIMPLE TEST CASCADE --- #
- profile_id: "simple_test_cascade"
  description: "A simple cascade for testing executor functionality: Log -> TestAgent -> Log."
  trigger_type: "AGENT_INITIATED"
  parameters_expected:
    - name: "initial_message"
      type: "string"
      required: false
      default: "Cascade initiated"
    - name: "test_agent_param"
      type: "string"
      required: false
      default: "Test Agent Data"

  agent_sequence:
    - name: "Log Start"
      agent: "debug_logger_agent" 
      task_data:
        message: "{{ step_results.initial_data.initial_message }} - Step 1: Logging start of simple_test_cascade"
        level: "INFO"
      on_failure: "LOG_AND_HALT"

    - name: "Call Test Agent"
      agent: "test_processing_agent"
      task_data:
        input_data: "{{ step_results.initial_data.test_agent_param }}"
        previous_step_output: "{{ step_results.step_1_output.logged_message || 'No output from logger' }}"
      on_failure: "LOG_AND_HALT"

    - name: "Log End"
      agent: "debug_logger_agent"
      task_data:
        message: "Step 3: Logging end of simple_test_cascade. Test Agent output: {{ step_results.step_2_output.result_summary || 'No output from test_agent' }}"
        level: "INFO"
      on_failure: "LOG_AND_PROCEED"
  logging_level: "VERBOSE"

# --- Profile ID: cursor_rules_sync_full_audit_cascade ---
- profile_id: "cursor_rules_sync_full_audit_cascade"
  description: "Full recursive audit and synchronization of .cursor and .rules files across all project directories"
  trigger_type: "AGENT_INITIATED"
  parameters_expected:
    - name: "target_path"
      type: "string"
      required: false
      description: "Root path to start scanning from (defaults to project root)"
    - name: "options"
      type: "object"
      required: false
      description: "Configuration options for the sync operation"
  agent_sequence:
    - name: "Scan All Directories"
      agent: "cursor_rules_sync_agent"
      task_data:
        action: "scan"
        target_path: "{{ trigger.parameters.target_path || '.' }}"
        options:
          exclude_dirs: [".git", "__pycache__", "node_modules", ".venv", ".next", "coverage"]
          include_root: false
      on_failure: "LOG_AND_HALT"
      
    - name: "Generate Missing Files"
      agent: "cursor_rules_sync_agent"
      task_data:
        action: "generate"
        options:
          generate_cursor: true
          generate_rules: true
      on_failure: "LOG_AND_PROCEED"
      
    - name: "Sync and Create Symlinks"
      agent: "cursor_rules_sync_agent"
      task_data:
        action: "sync"
        options:
          enable_symlinks: true
          sync_rules: true
      on_failure: "LOG_AND_PROCEED"
      
    - name: "Log Summary"
      agent: "detailed_event_logger_agent"
      input_mapping:
        event_type: "CURSOR_RULES_SYNC_COMPLETE"
        event_data:
          scan_results: "{{ step_results.step_1_output }}"
          generation_results: "{{ step_results.step_2_output }}"
          sync_results: "{{ step_results.step_3_output }}"
        severity: "INFO"
      on_failure: "LOG_ONLY"
logging_level: "VERBOSE"

# --- Profile ID: cursor_rules_quick_scan_cascade ---
- profile_id: "cursor_rules_quick_scan_cascade"
  description: "Quick scan to identify missing .cursor and .rules files without modification"
  trigger_type: "USER_CONFIRMED_WHISPER"
  trigger_conditions:
    - condition_type: "FILE_MODIFICATION"
      details:
        file_patterns: ["**/.cursor/**", "**/.rules/**", "**/agent_*.py", "**/index.yaml"]
  parameters_expected:
    - name: "modified_files"
      type: "list[string]"
      required: true
      description: "List of files that triggered the scan"
  agent_sequence:
    - agent_id: "cursor_rules_sync_agent"
      input_mapping:
        action: "scan"
        target_path: "."
        options:
          exclude_dirs: [".git", "__pycache__", "node_modules", ".venv"]
  whisper_mode_details:
    suggestion_prompt_template: "Detected changes to configuration files. Would you like to scan for missing .cursor and .rules files?"
    default_action: "REJECT"
  logging_level: "STANDARD"

# --- END OF PROFILES --- #
# Ensure this file ends with a newline if more profiles are added below manually

# Standard-Sequential-Workflow-Definitions

**Reason for Graduation (from globalrules.md):** Broad applicability, cross-project relevance

## Description

This rule defines the standard way to define sequential workflows or task cascades, particularly for agent-driven processes. It covers the structure for defining stages, inputs/outputs for each stage, conditional logic, error handling within cascades, and how these workflows are invoked and monitored.
The specific content for this rule is yet to be defined in detail.

## Rule Content

# TODO: Add rule content here
